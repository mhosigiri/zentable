file: ./content/docs/about-assistantui.mdx
# About assistant-ui


        
import { Sparkles, PanelsTopLeft, Database, Terminal } from "lucide-react";

assistant-ui helps you create beautiful, enterprise-grade AI chat interfaces in minutes. Whether you're building a chatGPT clone, a customer support chatbot, an AI assistant, or a complex multi agent application, assistant-ui provides the frontend primative components and state management layers to focus on what makes your application unique.

## Key Features

<Cards>
  <Card icon={<PanelsTopLeft className="text-purple-300" />} title="Instant Chat UI">
    Pre-built beautiful, customizable chat interfaces out of the box. Easy to quickly iterate on your idea.
  </Card>

  <Card icon={<PanelsTopLeft className="text-blue-300" />} title="Chat State Management">
    Powerful state management for chat interactions, optimized for streaming responses and efficient rendering.
  </Card>

  <Card icon={<Database className="text-green-300" />} title="High Performance">
    Optimized for speed and efficiency with minimal bundle size, ensuring your AI chat interfaces remain responsive.
  </Card>

  <Card icon={<Terminal className="text-orange-300" />} title="Framework Agnostic">
    Easily integrate with any backend system, whether using Vercel AI SDK, direct LLM connections, or custom solutions.
    Works with any React-based framework.
  </Card>
</Cards>

<Callout title="Want to try it out?">
  [Get Started in 30 Seconds](/docs/getting-started).
</Callout>


file: ./content/docs/architecture.mdx
# Architecture


        
import { Sparkles, PanelsTopLeft, Database, Terminal } from "lucide-react";

## assistant-ui is built on these main pillars:

<div className="grid grid-cols-1 md:grid-cols-3 gap-4 my-8">
  <Card title="1. Frontend components">
    Shadcn UI chat components with built-in state management
  </Card>

  <Card title="2. Runtime">
    State management layer connecting UI to LLMs and backend services
  </Card>

  <Card title="3. Assistant Cloud">
    Hosted service for thread persistence, history, and user management
  </Card>
</div>

### 1. Frontend components

Stylized and functional chat components built on top of Shadcn components that have context state management provided by the assistantUI runtime provider. These pre-built React components come with intelligent state management. [View our components](/docs/ui/Thread)

### 2. Runtime

A React state management context for assistant chat. The runtime handles data conversions between the local state and calls to backends and LLMs. We offer different runtime solutions that work with various frameworks like Vercel AI SDK, LangGraph, LangChain, Helicone, local runtime, and an ExternalStore when you need full control of the frontend message state. [You can view the runtimes we support](/docs/runtimes/pick-a-runtime)

### 3. Assistant Cloud

A hosted service that enhances your assistant experience with comprehensive thread management and message history. Assistant Cloud stores complete message history, automatically persists threads, supports human-in-the-loop workflows, and integrates with common auth providers to seamlessly allow users to resume conversations at any point. [Cloud Docs](/docs/cloud/overview)

### There are three common ways to architect your assistant-ui application:

#### **1. Direct Integration with External Providers**

```mermaid
graph TD
    A[Frontend Components] --> B[Runtime]
    B --> D[External Providers or LLM APIs]
    
    
    classDef default color:#f8fafc,text-align:center
    
    style A fill:#e879f9,stroke:#2e1065,stroke-width:2px,color:#2e1065,font-weight:bold
    style B fill:#93c5fd,stroke:#1e3a8a,stroke-width:2px,color:#1e3a8a,font-weight:bold
    style D fill:#fca5a5,stroke:#7f1d1d,stroke-width:2px,color:#7f1d1d,font-weight:bold
    
    class A,B,C,D,E default
```

#### **2. Using your own API endpoint**

```mermaid
graph TD
    A[Frontend Components] --> B[Runtime]
    B --> E[Your API Backend]
    E --> D[External Providers or LLM APIs]
    
    
    classDef default color:#f8fafc,text-align:center
    
    style A fill:#e879f9,stroke:#2e1065,stroke-width:2px,color:#2e1065,font-weight:bold
    style B fill:#93c5fd,stroke:#1e3a8a,stroke-width:2px,color:#1e3a8a,font-weight:bold
    style D fill:#fca5a5,stroke:#7f1d1d,stroke-width:2px,color:#7f1d1d,font-weight:bold
    style E fill:#fca5a5,stroke:#7f1d1d,stroke-width:2px,color:#7f1d1d,font-weight:bold
    
    class A,B,C,D,E default
```

#### **3. With Assistant Cloud**

```mermaid
graph TD
    A[Frontend Components] --> B[Runtime]
    B --> C[Cloud]
    E --> C
    C --> D[External Providers or LLM APIs]
    B --> E[Your API Backend]
    
    classDef default color:#f8fafc,text-align:center
    
    style A fill:#e879f9,stroke:#2e1065,stroke-width:2px,color:#2e1065,font-weight:bold
    style B fill:#93c5fd,stroke:#1e3a8a,stroke-width:2px,color:#1e3a8a,font-weight:bold
    style C fill:#86efac,stroke:#064e3b,stroke-width:2px,color:#064e3b,font-weight:bold
    style D fill:#fca5a5,stroke:#7f1d1d,stroke-width:2px,color:#7f1d1d,font-weight:bold
    style E fill:#fca5a5,stroke:#7f1d1d,stroke-width:2px,color:#7f1d1d,font-weight:bold
    
    class A,B,C,D,E default
```


file: ./content/docs/getting-started.mdx
# Getting Started


        
import { Step, Steps } from "fumadocs-ui/components/steps";
import { Tab, Tabs } from "fumadocs-ui/components/tabs";
import { Callout } from "fumadocs-ui/components/callout";
import { Card, Cards } from "fumadocs-ui/components/card";

## Start with a new project

![animated gif showing the steps to create a new project](../../../../.github/assets/assistant-ui-starter.gif)

<Steps>
  <Step>
    ### Initialize assistant-ui

    **Create a new project:**

    ```sh
    # Create a new project with the default template
    npx assistant-ui@latest create

    # Or start with a template:
    # LangGraph
    npx assistant-ui@latest create -t langgraph

    # MCP support
    npx assistant-ui@latest create -t mcp
    ```

    **Add assistant-ui to an existing React project:**

    ```sh
    # Add assistant-ui to an existing React project
    npx assistant-ui@latest init
    ```
  </Step>

  <Step>
    ### Add API key

    Add a new `.env` file to your project with your OpenAI API key:

    ```
    OPENAI_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

    # chat history -- sign up for free on https://cloud.assistant-ui.com
    # NEXT_PUBLIC_ASSISTANT_BASE_URL="https://..."
    ```
  </Step>

  <Step>
    ### Start the app

    ```sh
    npm run dev
    ```
  </Step>
</Steps>

## Manual installation

<Callout>
  We recommend `npx assistant-ui init` to setup existing projects.
</Callout>

<Steps>
  <Step>
    ### Add assistant-ui

    <Tabs items={["With Tailwind (Recommended)", "Without Tailwind"]}>
      <Tab>
        ```sh npm2yarn
        npx assistant-ui add thread thread-list
        ```
      </Tab>

      <Tab>
        <Steps>
          <Step>
            Add the following packages:

            ```sh
            npm install \
              @assistant-ui/react \
              @assistant-ui/react-markdown \
              @assistant-ui/styles \
              @radix-ui/react-tooltip \
              @radix-ui/react-slot \
              lucide-react \
              remark-gfm \
              class-variance-authority \
              clsx
            ```
          </Step>

          <Step>
            Copy the following components into your project:

            ```tsx title="components/ui/button.tsx"
            import * as React from "react";
            import { Slot } from "@radix-ui/react-slot";
            import { cva, type VariantProps } from "class-variance-authority";

            import { cn } from "@/lib/utils";

            const buttonVariants = cva("aui-button", {
              variants: {
                variant: {
                  default: "aui-button-primary",
                  outline: "aui-button-outline",
                  ghost: "aui-button-ghost",
                },
                size: {
                  default: "aui-button-medium",
                  icon: "aui-button-icon",
                },
              },
              defaultVariants: {
                variant: "default",
                size: "default",
              },
            });

            function Button({
              className,
              variant,
              size,
              asChild = false,
              ...props
            }: React.ComponentProps<"button"> &
              VariantProps<typeof buttonVariants> & {
                asChild?: boolean;
              }) {
              const Comp = asChild ? Slot : "button";

              return (
                <Comp
                  data-slot="button"
                  className={cn(buttonVariants({ variant, size, className }))}
                  {...props}
                />
              );
            }

            export { Button, buttonVariants };
            ```

            ```tsx title="components/ui/tooltip.tsx"
            "use client";

            import * as React from "react";
            import * as TooltipPrimitive from "@radix-ui/react-tooltip";

            import { cn } from "@/lib/utils";

            const TooltipProvider = TooltipPrimitive.Provider;

            const Tooltip = TooltipPrimitive.Root;

            const TooltipTrigger = TooltipPrimitive.Trigger;

            const TooltipContent = React.forwardRef<
              React.ElementRef<typeof TooltipPrimitive.Content>,
              React.ComponentPropsWithoutRef<typeof TooltipPrimitive.Content>
            >(({ className, sideOffset = 4, ...props }, ref) => (
              <TooltipPrimitive.Portal>
                <TooltipPrimitive.Content
                  ref={ref}
                  sideOffset={sideOffset}
                  className={cn("aui-tooltip-content", className)}
                  {...props}
                />
              </TooltipPrimitive.Portal>
            ));
            TooltipContent.displayName = TooltipPrimitive.Content.displayName;

            export { Tooltip, TooltipTrigger, TooltipContent, TooltipProvider };
            ```

            ```tsx title="components/assistant-ui/thread.tsx"
            import {
              ActionBarPrimitive,
              BranchPickerPrimitive,
              ComposerPrimitive,
              MessagePrimitive,
              ThreadPrimitive,
            } from "@assistant-ui/react";
            import type { FC } from "react";
            import {
              ArrowDownIcon,
              CheckIcon,
              ChevronLeftIcon,
              ChevronRightIcon,
              CopyIcon,
              PencilIcon,
              RefreshCwIcon,
              SendHorizontalIcon,
            } from "lucide-react";
            import { cn } from "@/lib/utils";

            import { Button } from "@/components/ui/button";
            import { MarkdownText } from "@/components/assistant-ui/markdown-text";
            import { TooltipIconButton } from "@/components/assistant-ui/tooltip-icon-button";

            export const Thread: FC = () => {
              return (
                <ThreadPrimitive.Root
                  className="aui-root aui-thread-root"
                  style={{
                    ["--thread-max-width" as string]: "42rem",
                  }}
                >
                  <ThreadPrimitive.Viewport className="aui-thread-viewport">
                    <ThreadWelcome />

                    <ThreadPrimitive.Messages
                      components={{
                        UserMessage: UserMessage,
                        EditComposer: EditComposer,
                        AssistantMessage: AssistantMessage,
                      }}
                    />

                    <ThreadPrimitive.If empty={false}>
                      <div className="aui-thread-viewport-spacer" />
                    </ThreadPrimitive.If>

                    <div className="aui-thread-viewport-footer">
                      <ThreadScrollToBottom />
                      <Composer />
                    </div>
                  </ThreadPrimitive.Viewport>
                </ThreadPrimitive.Root>
              );
            };

            const ThreadScrollToBottom: FC = () => {
              return (
                <ThreadPrimitive.ScrollToBottom asChild>
                  <TooltipIconButton
                    tooltip="Scroll to bottom"
                    variant="outline"
                    className="aui-thread-scroll-to-bottom"
                  >
                    <ArrowDownIcon />
                  </TooltipIconButton>
                </ThreadPrimitive.ScrollToBottom>
              );
            };

            const ThreadWelcome: FC = () => {
              return (
                <ThreadPrimitive.Empty>
                  <div className="aui-thread-welcome-root">
                    <div className="aui-thread-welcome-center">
                      <p className="aui-thread-welcome-message">
                        How can I help you today?
                      </p>
                    </div>
                    <ThreadWelcomeSuggestions />
                  </div>
                </ThreadPrimitive.Empty>
              );
            };

            const ThreadWelcomeSuggestions: FC = () => {
              return (
                <div className="aui-thread-welcome-suggestions">
                  <ThreadPrimitive.Suggestion
                    className="aui-thread-welcome-suggestion"
                    prompt="What is the weather in Tokyo?"
                    method="replace"
                    autoSend
                  >
                    <span className="aui-thread-welcome-suggestion-text">
                      What is the weather in Tokyo?
                    </span>
                  </ThreadPrimitive.Suggestion>
                  <ThreadPrimitive.Suggestion
                    className="aui-thread-welcome-suggestion"
                    prompt="What is assistant-ui?"
                    method="replace"
                    autoSend
                  >
                    <span className="aui-thread-welcome-suggestion-text">
                      What is assistant-ui?
                    </span>
                  </ThreadPrimitive.Suggestion>
                </div>
              );
            };

            const Composer: FC = () => {
              return (
                <ComposerPrimitive.Root className="aui-composer-root">
                  <ComposerPrimitive.Input
                    rows={1}
                    autoFocus
                    placeholder="Write a message..."
                    className="aui-composer-input"
                  />
                  <ComposerAction />
                </ComposerPrimitive.Root>
              );
            };

            const ComposerAction: FC = () => {
              return (
                <>
                  <ThreadPrimitive.If running={false}>
                    <ComposerPrimitive.Send asChild>
                      <TooltipIconButton
                        tooltip="Send"
                        variant="default"
                        className="aui-composer-send"
                      >
                        <SendHorizontalIcon />
                      </TooltipIconButton>
                    </ComposerPrimitive.Send>
                  </ThreadPrimitive.If>
                  <ThreadPrimitive.If running>
                    <ComposerPrimitive.Cancel asChild>
                      <TooltipIconButton
                        tooltip="Cancel"
                        variant="default"
                        className="aui-composer-cancel"
                      >
                        <CircleStopIcon />
                      </TooltipIconButton>
                    </ComposerPrimitive.Cancel>
                  </ThreadPrimitive.If>
                </>
              );
            };

            const UserMessage: FC = () => {
              return (
                <MessagePrimitive.Root className="aui-user-message-root">
                  <UserActionBar />

                  <div className="aui-user-message-content">
                    <MessagePrimitive.Content />
                  </div>

                  <BranchPicker className="aui-user-branch-picker" />
                </MessagePrimitive.Root>
              );
            };

            const UserActionBar: FC = () => {
              return (
                <ActionBarPrimitive.Root
                  hideWhenRunning
                  autohide="not-last"
                  className="aui-user-action-bar-root"
                >
                  <ActionBarPrimitive.Edit asChild>
                    <TooltipIconButton tooltip="Edit">
                      <PencilIcon />
                    </TooltipIconButton>
                  </ActionBarPrimitive.Edit>
                </ActionBarPrimitive.Root>
              );
            };

            const EditComposer: FC = () => {
              return (
                <ComposerPrimitive.Root className="aui-edit-composer-root">
                  <ComposerPrimitive.Input className="aui-edit-composer-input" />

                  <div className="aui-edit-composer-footer">
                    <ComposerPrimitive.Cancel asChild>
                      <Button variant="ghost">Cancel</Button>
                    </ComposerPrimitive.Cancel>
                    <ComposerPrimitive.Send asChild>
                      <Button>Send</Button>
                    </ComposerPrimitive.Send>
                  </div>
                </ComposerPrimitive.Root>
              );
            };

            const AssistantMessage: FC = () => {
              return (
                <MessagePrimitive.Root className="aui-assistant-message-root">
                  <div className="aui-assistant-message-content">
                    <MessagePrimitive.Content components={{ Text: MarkdownText }} />
                  </div>

                  <AssistantActionBar />

                  <BranchPicker className="aui-assistant-branch-picker" />
                </MessagePrimitive.Root>
              );
            };

            const AssistantActionBar: FC = () => {
              return (
                <ActionBarPrimitive.Root
                  hideWhenRunning
                  autohide="not-last"
                  autohideFloat="single-branch"
                  className="aui-assistant-action-bar-root"
                >
                  <ActionBarPrimitive.Copy asChild>
                    <TooltipIconButton tooltip="Copy">
                      <MessagePrimitive.If copied>
                        <CheckIcon />
                      </MessagePrimitive.If>
                      <MessagePrimitive.If copied={false}>
                        <CopyIcon />
                      </MessagePrimitive.If>
                    </TooltipIconButton>
                  </ActionBarPrimitive.Copy>
                  <ActionBarPrimitive.Reload asChild>
                    <TooltipIconButton tooltip="Refresh">
                      <RefreshCwIcon />
                    </TooltipIconButton>
                  </ActionBarPrimitive.Reload>
                </ActionBarPrimitive.Root>
              );
            };

            const BranchPicker: FC<BranchPickerPrimitive.Root.Props> = ({
              className,
              ...rest
            }) => {
              return (
                <BranchPickerPrimitive.Root
                  hideWhenSingleBranch
                  className={cn("aui-branch-picker-root", className)}
                  {...rest}
                >
                  <BranchPickerPrimitive.Previous asChild>
                    <TooltipIconButton tooltip="Previous">
                      <ChevronLeftIcon />
                    </TooltipIconButton>
                  </BranchPickerPrimitive.Previous>
                  <span className="aui-branch-picker-state">
                    <BranchPickerPrimitive.Number /> / <BranchPickerPrimitive.Count />
                  </span>
                  <BranchPickerPrimitive.Next asChild>
                    <TooltipIconButton tooltip="Next">
                      <ChevronRightIcon />
                    </TooltipIconButton>
                  </BranchPickerPrimitive.Next>
                </BranchPickerPrimitive.Root>
              );
            };

            const CircleStopIcon = () => {
              return (
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  viewBox="0 0 16 16"
                  fill="currentColor"
                  width="16"
                  height="16"
                >
                  <rect width="10" height="10" x="3" y="3" rx="2" />
                </svg>
              );
            };
            ```

            ```tsx title="components/assistant-ui/thread-list.tsx"
            import type { FC } from "react";
            import {
              ThreadListItemPrimitive,
              ThreadListPrimitive,
            } from "@assistant-ui/react";
            import { ArchiveIcon, PlusIcon } from "lucide-react";

            import { Button } from "@/components/ui/button";
            import { TooltipIconButton } from "@/components/assistant-ui/tooltip-icon-button";

            export const ThreadList: FC = () => {
              return (
                <ThreadListPrimitive.Root className="aui-root aui-thread-list-root">
                  <ThreadListNew />
                  <ThreadListItems />
                </ThreadListPrimitive.Root>
              );
            };

            const ThreadListNew: FC = () => {
              return (
                <ThreadListPrimitive.New asChild>
                  <Button className="aui-thread-list-new" variant="ghost">
                    <PlusIcon />
                    New Thread
                  </Button>
                </ThreadListPrimitive.New>
              );
            };

            const ThreadListItems: FC = () => {
              return <ThreadListPrimitive.Items components={{ ThreadListItem }} />;
            };

            const ThreadListItem: FC = () => {
              return (
                <ThreadListItemPrimitive.Root className="aui-thread-list-item">
                  <ThreadListItemPrimitive.Trigger className="aui-thread-list-item-trigger">
                    <ThreadListItemTitle />
                  </ThreadListItemPrimitive.Trigger>
                  <ThreadListItemArchive />
                </ThreadListItemPrimitive.Root>
              );
            };

            const ThreadListItemTitle: FC = () => {
              return (
                <p className="aui-thread-list-item-title">
                  <ThreadListItemPrimitive.Title fallback="New Chat" />
                </p>
              );
            };

            const ThreadListItemArchive: FC = () => {
              return (
                <ThreadListItemPrimitive.Archive asChild>
                  <TooltipIconButton
                    className="aui-thread-list-item-archive"
                    variant="ghost"
                    tooltip="Archive thread"
                  >
                    <ArchiveIcon />
                  </TooltipIconButton>
                </ThreadListItemPrimitive.Archive>
              );
            };
            ```

            ```tsx title="components/assistant-ui/markdown-text.tsx"
            "use client";

            import "@assistant-ui/react-markdown/styles/dot.css";

            import {
              CodeHeaderProps,
              MarkdownTextPrimitive,
              unstable_memoizeMarkdownComponents as memoizeMarkdownComponents,
              useIsMarkdownCodeBlock,
            } from "@assistant-ui/react-markdown";
            import remarkGfm from "remark-gfm";
            import { FC, memo, useState } from "react";
            import { CheckIcon, CopyIcon } from "lucide-react";

            import { TooltipIconButton } from "@/components/assistant-ui/tooltip-icon-button";
            import { cn } from "@/lib/utils";

            const MarkdownTextImpl = () => {
              return (
                <MarkdownTextPrimitive
                  remarkPlugins={[remarkGfm]}
                  className="aui-md"
                  components={defaultComponents}
                />
              );
            };

            export const MarkdownText = memo(MarkdownTextImpl);

            const CodeHeader: FC<CodeHeaderProps> = ({ language, code }) => {
              const { isCopied, copyToClipboard } = useCopyToClipboard();
              const onCopy = () => {
                if (!code || isCopied) return;
                copyToClipboard(code);
              };

              return (
                <div className="aui-code-header-root">
                  <span className="aui-code-header-language">{language}</span>
                  <TooltipIconButton tooltip="Copy" onClick={onCopy}>
                    {!isCopied && <CopyIcon />}
                    {isCopied && <CheckIcon />}
                  </TooltipIconButton>
                </div>
              );
            };

            const useCopyToClipboard = ({
              copiedDuration = 3000,
            }: {
              copiedDuration?: number;
            } = {}) => {
              const [isCopied, setIsCopied] = useState<boolean>(false);

              const copyToClipboard = (value: string) => {
                if (!value) return;

                navigator.clipboard.writeText(value).then(() => {
                  setIsCopied(true);
                  setTimeout(() => setIsCopied(false), copiedDuration);
                });
              };

              return { isCopied, copyToClipboard };
            };

            const defaultComponents = memoizeMarkdownComponents({
              h1: ({ className, ...props }) => (
                <h1 className={cn("aui-md-h1", className)} {...props} />
              ),
              h2: ({ className, ...props }) => (
                <h2 className={cn("aui-md-h2", className)} {...props} />
              ),
              h3: ({ className, ...props }) => (
                <h3 className={cn("aui-md-h3", className)} {...props} />
              ),
              h4: ({ className, ...props }) => (
                <h4 className={cn("aui-md-h4", className)} {...props} />
              ),
              h5: ({ className, ...props }) => (
                <h5 className={cn("aui-md-h5", className)} {...props} />
              ),
              h6: ({ className, ...props }) => (
                <h6 className={cn("aui-md-h6", className)} {...props} />
              ),
              p: ({ className, ...props }) => (
                <p className={cn("aui-md-p", className)} {...props} />
              ),
              a: ({ className, ...props }) => (
                <a className={cn("aui-md-a", className)} {...props} />
              ),
              blockquote: ({ className, ...props }) => (
                <blockquote className={cn("aui-md-blockquote", className)} {...props} />
              ),
              ul: ({ className, ...props }) => (
                <ul className={cn("aui-md-ul", className)} {...props} />
              ),
              ol: ({ className, ...props }) => (
                <ol className={cn("aui-md-ol", className)} {...props} />
              ),
              hr: ({ className, ...props }) => (
                <hr className={cn("aui-md-hr", className)} {...props} />
              ),
              table: ({ className, ...props }) => (
                <table className={cn("aui-md-table", className)} {...props} />
              ),
              th: ({ className, ...props }) => (
                <th className={cn("aui-md-th", className)} {...props} />
              ),
              td: ({ className, ...props }) => (
                <td className={cn("aui-md-td", className)} {...props} />
              ),
              tr: ({ className, ...props }) => (
                <tr className={cn("aui-md-tr", className)} {...props} />
              ),
              sup: ({ className, ...props }) => (
                <sup className={cn("aui-md-sup", className)} {...props} />
              ),
              pre: ({ className, ...props }) => (
                <pre className={cn("aui-md-pre", className)} {...props} />
              ),
              code: function Code({ className, ...props }) {
                const isCodeBlock = useIsMarkdownCodeBlock();
                return (
                  <code
                    className={cn(!isCodeBlock && "aui-md-inline-code", className)}
                    {...props}
                  />
                );
              },
              CodeHeader,
            });
            ```

            ```tsx title="components/assistant-ui/tooltip-icon-button.tsx"
            "use client";

            import { ComponentPropsWithoutRef, forwardRef } from "react";

            import {
              Tooltip,
              TooltipContent,
              TooltipProvider,
              TooltipTrigger,
            } from "@/components/ui/tooltip";
            import { Button } from "@/components/ui/button";
            import { cn } from "@/lib/utils";

            export type TooltipIconButtonProps = ComponentPropsWithoutRef<typeof Button> & {
              tooltip: string;
              side?: "top" | "bottom" | "left" | "right";
            };

            export const TooltipIconButton = forwardRef<
              HTMLButtonElement,
              TooltipIconButtonProps
            >(({ children, tooltip, side = "bottom", className, ...rest }, ref) => {
              return (
                <TooltipProvider>
                  <Tooltip>
                    <TooltipTrigger asChild>
                      <Button
                        variant="ghost"
                        size="icon"
                        {...rest}
                        className={cn("", className)}
                        ref={ref}
                      >
                        {children}
                        <span className="aui-sr-only">{tooltip}</span>
                      </Button>
                    </TooltipTrigger>
                    <TooltipContent side={side}>{tooltip}</TooltipContent>
                  </Tooltip>
                </TooltipProvider>
              );
            });

            TooltipIconButton.displayName = "TooltipIconButton";
            ```

            ```ts title="lib/utils.ts"
            import { type ClassValue, clsx } from "clsx";

            export function cn(...inputs: ClassValue[]) {
              return clsx(inputs);
            }
            ```
          </Step>

          <Step>
            The components above reference CSS class names like `aui-thread-root`, `aui-composer-input`, etc. These are normally replaced by our CLI with Tailwind class names, but in this case you'll use our pre-compiled CSS files without a need for Tailwind:

            ```ts
            import "@assistant-ui/styles/index.css";
            import "@assistant-ui/styles/markdown.css";
            // import "@assistant-ui/styles/modal.css";  // for future reference, only if you use our modal component
            ```
          </Step>
        </Steps>
      </Tab>
    </Tabs>
  </Step>

  <Step>
    ### Setup Backend Endpoint

    Install provider SDK:

    <Tabs id="provider" items={["OpenAI", "Anthropic", "Azure", "AWS", "Gemini", "GCP", "Groq", "Fireworks", "Cohere", "Ollama", "Chrome AI"]}>
      ```sh title="Terminal" tab="OpenAI"
      npm install ai @assistant-ui/react-ai-sdk @ai-sdk/openai
      ```

      ```sh title="Terminal" tab="Anthropic"
      npm install ai @assistant-ui/react-ai-sdk @ai-sdk/anthropic
      ```

      ```sh title="Terminal" tab="Azure"
      npm install ai @assistant-ui/react-ai-sdk @ai-sdk/azure
      ```

      ```sh title="Terminal" tab="AWS"
      npm install ai @assistant-ui/react-ai-sdk @ai-sdk/amazon-bedrock
      ```

      ```sh title="Terminal" tab="Gemini"
      npm install ai @assistant-ui/react-ai-sdk @ai-sdk/google
      ```

      ```sh title="Terminal" tab="GCP"
      npm install ai @assistant-ui/react-ai-sdk @ai-sdk/google-vertex
      ```

      ```sh title="Terminal" tab="Groq"
      npm install ai @assistant-ui/react-ai-sdk @ai-sdk/openai
      ```

      ```sh title="Terminal" tab="Fireworks"
      npm install ai @assistant-ui/react-ai-sdk @ai-sdk/openai
      ```

      ```sh title="Terminal" tab="Cohere"
      npm install ai @assistant-ui/react-ai-sdk @ai-sdk/cohere
      ```

      ```sh title="Terminal" tab="Ollama"
      npm install ai @assistant-ui/react-ai-sdk ollama-ai-provider
      ```

      ```sh title="Terminal" tab="Chrome AI"
      npm install ai @assistant-ui/react-ai-sdk chrome-ai
      ```
    </Tabs>

    Add an API endpoint:

    <Tabs id="provider" items={["OpenAI", "Anthropic", "Azure", "AWS", "Gemini", "GCP", "Groq", "Fireworks", "Cohere", "Ollama", "Chrome AI"]}>
      ```ts title="/app/api/chat/route.ts" tab="OpenAI"
      import { openai } from "@ai-sdk/openai";
      import { streamText } from "ai";

      export const maxDuration = 30;

      export async function POST(req: Request) {
        const { messages } = await req.json();
        const result = streamText({
          model: openai("gpt-4o-mini"),
          messages,
        });
        return result.toDataStreamResponse();
      }
      ```

      ```ts title="/app/api/chat/route.ts" tab="Anthropic"
      import { anthropic } from "@ai-sdk/anthropic";
      import { streamText } from "ai";

      export const maxDuration = 30;

      export async function POST(req: Request) {
        const { messages } = await req.json();
        const result = streamText({
          model: anthropic("claude-3-5-sonnet-20240620"),
          messages,
        });
        return result.toDataStreamResponse();
      }
      ```

      ```ts title="/app/api/chat/route.ts" tab="Azure"
      import { azure } from "@ai-sdk/azure";
      import { streamText } from "ai";

      export const maxDuration = 30;

      export async function POST(req: Request) {
        const { messages } = await req.json();
        const result = streamText({
          model: azure("your-deployment-name"),
          messages,
        });
        return result.toDataStreamResponse();
      }
      ```

      ```ts title="/app/api/chat/route.ts" tab="AWS"
      import { bedrock } from "@ai-sdk/amazon-bedrock";
      import { streamText } from "ai";

      export const maxDuration = 30;

      export async function POST(req: Request) {
        const { messages } = await req.json();
        const result = streamText({
          model: bedrock("anthropic.claude-3-5-sonnet-20240620-v1:0"),
          messages,
        });
        return result.toDataStreamResponse();
      }
      ```

      ```ts title="/app/api/chat/route.ts" tab="Gemini"
      import { google } from "@ai-sdk/google";
      import { streamText } from "ai";

      export const maxDuration = 30;

      export async function POST(req: Request) {
        const { messages } = await req.json();
        const result = streamText({
          model: google("gemini-2.0-flash"),
          messages,
        });
        return result.toDataStreamResponse();
      }
      ```

      ```ts title="/app/api/chat/route.ts" tab="GCP"
      import { vertex } from "@ai-sdk/google-vertex";
      import { streamText } from "ai";

      export const maxDuration = 30;

      export async function POST(req: Request) {
        const { messages } = await req.json();
        const result = streamText({
          model: vertex("gemini-1.5-pro"),
          messages,
        });
        return result.toDataStreamResponse();
      }
      ```

      ```ts title="/app/api/chat/route.ts" tab="Groq"
      import { createOpenAI } from "@ai-sdk/openai";
      import { streamText } from "ai";

      export const maxDuration = 30;

      const groq = createOpenAI({
        apiKey: process.env.GROQ_API_KEY ?? "",
        baseURL: "https://api.groq.com/openai/v1",
      });

      export async function POST(req: Request) {
        const { messages } = await req.json();
        const result = streamText({
          model: groq("llama3-70b-8192"),
          messages,
        });
        return result.toDataStreamResponse();
      }
      ```

      ```ts title="/app/api/chat/route.ts" tab="Fireworks"
      import { createOpenAI } from "@ai-sdk/openai";
      import { streamText } from "ai";

      export const maxDuration = 30;

      const fireworks = createOpenAI({
        apiKey: process.env.FIREWORKS_API_KEY ?? "",
        baseURL: "https://api.fireworks.ai/inference/v1",
      });

      export async function POST(req: Request) {
        const { messages } = await req.json();
        const result = streamText({
          model: fireworks("accounts/fireworks/models/firefunction-v2"),
          messages,
        });
        return result.toDataStreamResponse();
      }
      ```

      ```ts title="/app/api/chat/route.ts" tab="Cohere"
      import { cohere } from "@ai-sdk/cohere";
      import { streamText } from "ai";

      export const maxDuration = 30;

      export async function POST(req: Request) {
        const { messages } = await req.json();
        const result = streamText({
          model: cohere("command-r-plus"),
          messages,
        });
        return result.toDataStreamResponse();
      }
      ```

      ```ts title="/app/api/chat/route.ts" tab="Ollama"
      import { ollama } from "ollama-ai-provider";
      import { streamText } from "ai";

      export const maxDuration = 30;

      export async function POST(req: Request) {
        const { messages } = await req.json();
        const result = streamText({
          model: ollama("llama3"),
          messages,
        });
        return result.toDataStreamResponse();
      }
      ```

      ```ts title="/app/api/chat/route.ts" tab="Chrome AI"
      import { chromeai } from "chrome-ai";
      import { streamText } from "ai";

      export const maxDuration = 30;

      export async function POST(req: Request) {
        const { messages } = await req.json();
        const result = streamText({
          model: chromeai(),
          messages,
        });
        return result.toDataStreamResponse();
      }
      ```
    </Tabs>

    Define environment variables:

    <Tabs id="provider" items={["OpenAI", "Anthropic", "Azure", "AWS", "Gemini", "GCP", "Groq", "Fireworks", "Cohere", "Ollama", "Chrome AI"]}>
      ```sh title="/.env.local" tab="OpenAI"
      OPENAI_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ```

      ```sh title="/.env.local" tab="Anthropic"
      ANTHROPIC_API_KEY="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ```

      ```sh title="/.env.local" tab="Azure"
      AZURE_RESOURCE_NAME="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      AZURE_API_KEY="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ```

      ```sh title="/.env.local" tab="AWS"
      AWS_ACCESS_KEY_ID="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      AWS_SECRET_ACCESS_KEY="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      AWS_REGION="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ```

      ```sh title="/.env.local" tab="Gemini"
      GOOGLE_GENERATIVE_AI_API_KEY="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ```

      ```sh title="/.env.local" tab="GCP"
      GOOGLE_VERTEX_PROJECT="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      GOOGLE_VERTEX_LOCATION="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      GOOGLE_APPLICATION_CREDENTIALS="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ```

      ```sh title="/.env.local" tab="Groq"
      GROQ_API_KEY="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ```

      ```sh title="/.env.local" tab="Fireworks"
      FIREWORKS_API_KEY="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ```

      ```sh title="/.env.local" tab="Cohere"
      COHERE_API_KEY="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ```

      ```sh tab="Ollama"
      <none>
      ```

      ```sh tab="Chrome AI"
      <none>
      ```
    </Tabs>

    If you aren't using Next.js, you can also deploy this endpoint to Cloudflare Workers, or any other serverless platform.
  </Step>

  <Step>
    ### Use it in your app

    <Tabs items={["Thread", "AssistantModal"]}>
      ```tsx title="/app/page.tsx" tab="Thread"
      import { AssistantRuntimeProvider } from "@assistant-ui/react";
      import { useChatRuntime } from "@assistant-ui/react-ai-sdk";
      import { ThreadList } from "@/components/assistant-ui/thread-list";
      import { Thread } from "@/components/assistant-ui/thread";

      const MyApp = () => {
        const runtime = useChatRuntime({
          api: "/api/chat",
        });

        return (
          <AssistantRuntimeProvider runtime={runtime}>
            <div className="grid h-dvh grid-cols-[200px_1fr] gap-x-2 px-4 py-4">
              <ThreadList />
              <Thread />
            </div>
          </AssistantRuntimeProvider>
        );
      };
      ```

      ```tsx title="/app/page.tsx" tab="AssistantModal"
      // run `npx shadcn@latest add "https://r.assistant-ui.com/assistant-modal"`

      import { AssistantRuntimeProvider } from "@assistant-ui/react";
      import { useChatRuntime } from "@assistant-ui/react-ai-sdk";
      import { AssistantModal } from "@/components/assistant-ui/assistant-modal";

      const MyApp = () => {
        const runtime = useChatRuntime({
          api: "/api/chat",
        });

        return (
          <AssistantRuntimeProvider runtime={runtime}>
            <AssistantModal />
          </AssistantRuntimeProvider>
        );
      };
      ```
    </Tabs>
  </Step>
</Steps>

## What's Next?

<Cards>
  <Card title="Pick a Runtime" description="Choose the right runtime for your needs" href="/docs/runtimes/pick-a-runtime" />

  <Card title="Generative UI" description="Create rich UI components for tool executions" href="/docs/guides/ToolUI" />

  <Card title="Add Persistence" description="Save and restore chat conversations" href="/docs/cloud/overview" />

  <Card title="Examples" description="Explore full implementations and demos" href="https://github.com/assistant-ui/assistant-ui/tree/main/examples" />
</Cards>


file: ./content/docs/index.mdx
# Documentation


        
import { redirect } from "next/navigation";

<>
  {redirect("/docs/getting-started")}
</>


file: ./content/docs/mcp-docs-server.mdx
# MCP Docs Server

Learn how to use the assistant-ui MCP documentation server in your IDE to access documentation and examples directly.
        
import { Tabs, Tab } from "fumadocs-ui/components/tabs";

`@assistant-ui/mcp-docs-server` provides direct access to assistant-ui's documentation and examples in Cursor, Windsurf, VSCode, Zed, Claude Code, or any other IDE or tool that supports MCP.

The MCP server tools have been designed to allow an agent to query the specific information it needs to complete an assistant-ui related task - for example: implementing chat components, integrating with different runtimes, understanding component architecture, and troubleshooting issues.

## How it works

Once it's installed in your IDE you can write prompts and assume the agent will understand everything about assistant-ui.

### Add features

* "Add a chat interface with streaming support to my app"
* "Implement branching conversations with the BranchPicker component"
* "Add attachment support to my assistant using the Attachment primitive"

### Ask about integrations

* "How do I integrate assistant-ui with the Vercel AI SDK?
  Show me a working example for my Next.js app"
* "Does assistant-ui support React Server Components? How do I use it?"
* "Can I use assistant-ui with LangGraph? Show me how to set up the runtime"

### Debug or update existing code

* "My Thread component isn't updating when new messages arrive, what could be wrong?"
* "How do I customize the styling of the AssistantModal component?"
* "I need to add tool UI rendering to my assistant, show me how to implement it"

**And more** - if you have a question, try asking your IDE and let it look it up for you.

## Installation

Choose your IDE or tool to get started with the assistant-ui MCP docs server.

### Claude Code

Add the MCP server using the Claude Code CLI:

```bash
# Add to current project only
claude mcp add assistant-ui -- npx -y @assistant-ui/mcp-docs-server

# Or add globally for all projects
claude mcp add --scope user assistant-ui -- npx -y @assistant-ui/mcp-docs-server
```

To manage the server:

```bash
# View configured servers
claude mcp list

# Get server details
claude mcp get assistant-ui

# Remove the server
claude mcp remove assistant-ui
```

### Claude Desktop

Add to your Claude Desktop configuration:

* macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`
* Windows: `%APPDATA%\Claude\claude_desktop_config.json`

```json
{
  "mcpServers": {
    "assistant-ui": {
      "command": "npx",
      "args": ["-y", "@assistant-ui/mcp-docs-server"]
    }
  }
}
```

### IDEs

For Cursor, Windsurf, VSCode, and Zed, manually add the following configuration:

* **Cursor**: Edit `.cursor/mcp.json` in your project root, or `~/.cursor/mcp.json` for global configuration
* **Windsurf**: Edit `~/.codeium/windsurf/mcp_config.json` (only supports global configuration)
* **VSCode**: Edit `~/.vscode/mcp.json` in your project root
* **Zed**: Edit `settings.json` (open via `cmd+,` or `zed: open settings`)

### MacOS/Linux

{/*
  LLM CONTEXT: This Tabs component shows MCP server configuration for different IDEs on MacOS/Linux.
  Each tab displays the JSON configuration needed to set up the assistant-ui MCP docs server in that specific IDE.
  The tabs help users find the correct configuration format for their IDE (Cursor, Windsurf, VSCode, or Zed).
  Each tab shows the exact JSON structure and file paths needed for that IDE's MCP configuration.
  */}

<Tabs items={["cursor", "windsurf", "vscode", "zed"]}>
  <Tab>
    ```json
    {
      "mcpServers": {
        "assistant-ui": {
          "command": "npx",
          "args": ["-y", "@assistant-ui/mcp-docs-server"]
        }
      }
    }
    ```
  </Tab>

  <Tab>
    ```json
    {
      "mcpServers": {
        "assistant-ui": {
          "command": "npx",
          "args": ["-y", "@assistant-ui/mcp-docs-server"]
        }
      }
    }
    ```
  </Tab>

  <Tab>
    ```json
    {
      "servers": {
        "assistant-ui": {
          "command": "npx",
          "args": ["-y", "@assistant-ui/mcp-docs-server"],
          "type": "stdio"
        }
      }
    }
    ```
  </Tab>

  <Tab>
    ```json
    {
      "context_servers": {
        "assistant-ui": {
          "command": {
            "path": "npx",
            "args": ["-y", "@assistant-ui/mcp-docs-server"],
            "env": {}
          },
          "settings": {}
        }
      }
    }
    ```
  </Tab>
</Tabs>

### Windows

{/*
  LLM CONTEXT: This Tabs component shows MCP server configuration for different IDEs on Windows.
  Each tab displays the Windows-specific JSON configuration needed to set up the assistant-ui MCP docs server.
  The tabs help Windows users find the correct configuration format for their IDE, using cmd instead of direct npx.
  Each tab shows the Windows-specific command structure needed for that IDE's MCP configuration.
  On latest Windsurf and Cursor the direct npx command works, while it's still unconfirmed if this has been fixed for VSCode.
  */}

<Tabs items={["cursor", "windsurf", "vscode", "zed"]}>
  <Tab>
    ```json
    {
      "mcpServers": {
        "assistant-ui": {
          "command": "npx",
          "args": ["-y", "@assistant-ui/mcp-docs-server"]
        }
      }
    }
    ```
  </Tab>

  <Tab>
    ```json
    {
      "mcpServers": {
        "assistant-ui": {
          "command": "npx",
          "args": ["-y", "@assistant-ui/mcp-docs-server"]
        }
      }
    }
    ```
  </Tab>

  <Tab>
    ```json
    {
      "servers": {
        "assistant-ui": {
          "command": "cmd",
          "args": ["/c", "npx", "-y", "@assistant-ui/mcp-docs-server"],
          "type": "stdio"
        }
      }
    }
    ```
  </Tab>

  <Tab>
    ```json
    {
      "context_servers": {
        "assistant-ui": {
          "command": {
            "path": "cmd",
            "args": ["/c", "npx", "-y", "@assistant-ui/mcp-docs-server"],
            "env": {}
          },
          "settings": {}
        }
      }
    }
    ```
  </Tab>
</Tabs>

## After Configuration

### Claude Code

The MCP server starts automatically once added. You can verify it's working by mentioning assistant-ui in your prompts - Claude will have direct access to the documentation and examples.

### Claude Desktop

1. Restart Claude Desktop after updating the configuration
2. The MCP server will start automatically when Claude Desktop launches
3. You can verify it's working by asking about assistant-ui - Claude will have direct access to the documentation and examples

### Cursor

1. Open Cursor settings by pressing `Cmd/Ctrl + ,`
2. Navigate to the MCP settings section
3. Find "assistant-ui" in the list of MCP servers and click "enable"
4. The server should start automatically. You'll see a status indicator showing it's running
5. If you have an agent chat open, you'll need to re-open it or start a new chat to use the MCP server

The MCP server will automatically start whenever you open Cursor. You can verify it's working by mentioning assistant-ui documentation or examples in your prompts - the agent should now have direct access to this information.

### Windsurf

1. Fully quit and re-open Windsurf
2. The MCP server should start automatically. You can verify this in the MCP settings panel
3. If tool calls start failing, go to Windsurf's MCP settings and re-start the MCP server. This is a common Windsurf MCP issue and isn't specific to this server. Currently, Cursor's MCP implementation tends to be more stable than Windsurf's

In both IDEs it may take a minute for the MCP server to start the first time as it needs to download the package from npm.

### VSCode

1. Open VSCode settings by pressing `Cmd/Ctrl + ,`
2. Search for "MCP" in the settings search bar
3. Enable the "Chat > MCP" option by checking the checkbox
4. Open GitHub Copilot Chat and switch to "Agent" mode (MCP only works in Agent mode)
5. Open the `mcp.json` file and click the "start" button that appears in the editor
6. Once started, you can click the tools button in the Copilot pane to see available tools

The tools button should show "assistantUIDocs" and "assistantUIExamples" as available tools when the server is running correctly.

### Zed

1. Open Zed settings by pressing `Cmd/Ctrl + ,` or using `zed: open settings`
2. The MCP server configuration should be in your `settings.json` under the `context_servers` key
3. The server will start automatically when you use the Assistant Panel
4. You can also add servers through the Agent Panel's Settings view (accessible via `agent: open configuration`)
5. In the Assistant Panel, you can verify the server is available by checking the tools dropdown

Zed will automatically start the MCP server when needed. The assistant-ui documentation and examples will be available to the AI assistant in your conversations.

### Claude Desktop

1. Restart Claude Desktop after updating the configuration
2. The MCP server will start automatically when Claude Desktop launches
3. You can verify it's working by asking about assistant-ui - Claude will have direct access to the documentation and examples

## Available Agent Tools

### assistantUIDocs

Access assistant-ui's complete documentation:

* Getting started guides and installation instructions
* Component API references (Thread, AssistantModal, Composer, etc.)
* Runtime documentation (AI SDK, LangGraph, OpenAI Assistants)
* Integration guides and best practices
* Architecture and concept explanations

### assistantUIExamples

Browse complete code examples:

* Integration with Vercel AI SDK
* React Server Components implementation
* LangGraph runtime setup
* OpenAI Assistants integration
* Local Ollama usage
* External store management
* React Hook Form integration
* Tool UI implementation patterns

Each example includes full source code, configuration files, and implementation details that can be directly referenced or adapted for your project.

## Common Issues

1. **Server Not Starting**

   * Ensure npx is installed and working
   * Check for conflicting MCP servers
   * Verify your configuration file syntax
   * On Windows, make sure to use the Windows-specific configuration

2. **Tool Calls Failing**
   * Restart the MCP server and/or your IDE
   * Update to the latest version of your IDE

{/*
  Attribution:
  This docs page, and `@assistant-ui/mcp-docs-server`, is inspired by and based on Mastra's excellent mcp docs server and docs page: https://github.com/mastra/mcp-docs-server/blob/main/docs/mcp-docs-server.mdx
  */}


file: ./content/docs/react-compatibility.mdx
# Using old React versions

Guide for using assistant-ui with older React versions (18, 17, 16)
        
import { Callout } from "fumadocs-ui/components/callout";

<Callout type="warning" title="Older React Versions">
  Older React versions are not continuously tested. If you encounter any issues
  with integration, please contact us for help by joining our
  [Discord](https://discord.gg/S9dwgCNEFs).
</Callout>

This guide provides instructions for configuring assistant-ui to work with React 18 or older versions.

## React 18

If you're using React 18, you need to update the shadcn/ui components to work with `forwardRef`. Specifically, you need to modify the Button component.

### Updating the Button Component

Navigate to your button component file (typically `/components/ui/button.tsx`) and wrap the Button component with `forwardRef`:

```tsx
// Before
function Button({
  className,
  variant,
  size,
  asChild = false,
  ...props
}: React.ComponentProps<"button"> &
  VariantProps<typeof buttonVariants> & {
    asChild?: boolean;
  }) {
  const Comp = asChild ? Slot : "button";

  return (
    <Comp
      data-slot="button"
      className={cn(buttonVariants({ variant, size, className }))}
      {...props}
    />
  );
}

// After
const Button = React.forwardRef<
  HTMLButtonElement,
  React.ComponentProps<"button"> &
    VariantProps<typeof buttonVariants> & {
      asChild?: boolean;
    }
>(({ className, variant, size, asChild = false, ...props }, ref) => {
  const Comp = asChild ? Slot : "button";

  return (
    <Comp
      data-slot="button"
      className={cn(buttonVariants({ variant, size, className }))}
      ref={ref}
      {...props}
    />
  );
});
Button.displayName = "Button";
```

**Note:** If you're using a lower React version (17 or 16), you'll also need to follow the instructions for that version.

## React 17

For React 17 compatibility, in addition to the modifications outlined for React 18, you must also include a polyfill for the `useSyncExternalStore` hook (utilized by zustand).

### Patching Zustand with patch-package

Since the assistant-ui uses zustand internally, which depends on `useSyncExternalStore`, you'll need to patch the zustand package directly:

1. Install the required packages:

```bash
npm install use-sync-external-store patch-package
# or
yarn add use-sync-external-store patch-package
```

2. Add a postinstall script to your package.json:

```json
{
  "scripts": {
    "postinstall": "patch-package"
  }
}
```

3. You'll want to follow the instructions in [patch-package](https://github.com/ds300/patch-package), by first making changes to the files of a particular package in your node\_modules folder, then running either `yarn patch-package package-name` or `npx patch-package package-name`. You'll need a patch for zustand - within `node_modules/zustand`, open `zustand/react.js` and make the following code changes:

````diff
diff --git a/node_modules/zustand/react.js b/node_modules/zustand/react.js
index 7599cfb..64530a8 100644
--- a/node_modules/zustand/react.js
+++ b/node_modules/zustand/react.js
@@ -1,6 +1,6 @@
 'use strict';

-var React = require('react');
+var React = require('use-sync-external-store/shim');
 var vanilla = require('zustand/vanilla');

 const identity = (arg) => arg;
@@ -10,7 +10,7 @@ function useStore(api, selector = identity) {
     () => selector(api.getState()),
     () => selector(api.getInitialState())
   );
-  React.useDebugValue(slice);
+  //React.useDebugValue(slice);
   return slice;
 }
 const createImpl = (createState) => {

This patch replaces the React import in zustand with the polyfill from `use-sync-external-store/shim` and comments out the `useDebugValue` call which isn't needed.

You should then run the patch-package command `yarn patch-package zustand` or `npx patch-package zustand` which should create a `patches` folder with a zustand patch file similar looking to this:

```diff
diff --git a/node_modules/zustand/react.js b/node_modules/zustand/react.js
index 7599cfb..64530a8 100644
--- a/node_modules/zustand/react.js
+++ b/node_modules/zustand/react.js
@@ -1,6 +1,6 @@
 'use strict';

-var React = require('react');
+var React = require('use-sync-external-store/shim');
 var vanilla = require('zustand/vanilla');

 const identity = (arg) => arg;
@@ -10,7 +10,7 @@ function useStore(api, selector = identity) {
     () => selector(api.getState()),
     () => selector(api.getInitialState())
   );
-  React.useDebugValue(slice);
+  //React.useDebugValue(slice);
   return slice;
 }
 const createImpl = (createState) => {
````

4. You may also need to apply the same patches within `node_modules/@assistant-ui/react/` and possibly a nested dependency patch for `node_modules/@assistant-ui/react/node_modules/zustand`. Look for instances of `React.useSyncExternalStore` and replace with `{ useSyncExternalStore } from "use-sync-external-store/shim";` and comment out any `useDebugValue` calls. Finally, you may need to patch `useId` from React, so within `node_modules/@assistant-ui/react/dist/runtimes/remote-thread-list/RemoteThreadListThreadListRuntimeCore.js`, change the following:

```diff
-import { Fragment, useEffect, useId } from "react";
+import { Fragment, useEffect, useRef } from "react";
 import { create } from "zustand";
 import { AssistantMessageStream } from "assistant-stream";
 import { RuntimeAdapterProvider } from "../adapters/RuntimeAdapterProvider.js";
 import { jsx } from "react/jsx-runtime";
+
+// PATCH-PACKAGE: Polyfill for useId if not available in React 16
+let useId;
+try {
+  // Try to use React's useId if available
+  useId = require("react").useId;
+} catch (e) {}
+if (!useId) {
+  // Fallback polyfill
+  let globalId = 0;
+  useId = function() {
+    const idRef = useRef();
+    if (!idRef.current) {
+      globalId++;
+      idRef.current = `uid-${globalId}`;
+    }
+    return idRef.current;
+  };
+}
```

5. Run the postinstall script to apply the patches:

```bash
npm run postinstall
# or
yarn postinstall
```

This patch replaces the React import in zustand with the polyfill from `use-sync-external-store/shim` and comments out the `useDebugValue` call which isn't needed.

**Note:** If you're using React 16, you'll also need to follow the instructions for that version.

## React 16

<Callout type="info" title="Incomplete Section">
  This section is incomplete and contributions are welcome. If you're using
  React 16 and have successfully integrated assistant-ui, please consider
  contributing to this documentation.
</Callout>

For React 16 compatibility, you need to apply all the steps for **React 18** and **React 17** above.

## Additional Resources

If you encounter any issues with React compatibility, please:

1. Check that all required dependencies are installed
2. Ensure your component modifications are correctly implemented
3. Join our [Discord](https://discord.gg/S9dwgCNEFs) community for direct support


file: ./content/docs/api-reference/overview.mdx
# Overview


        
import { Callout } from "fumadocs-ui/components/callout";

import { Component, ContextLevel, RuntimeHooks } from "./context";

export const contextColors = {
  "Assistant Context": "#4a86e8",
  "Thread Context": "#45a049",
  "Composer Context": "#ff9933",
  "Message Context": "#bb2244",
  "ContentPart Context": "#268bd2",
  "Attachment Context": "#FFB6C1",
  "ThreadListItem Context": "#c678dd",
};

<Callout title="Work in progress" type="warn">
  This page is under construction. Most links will not work yet.
</Callout>

## Cloud

* [`AssistantCloud`](#assistant-cloud)

## Runtime API

### AI SDK

* [`useChatRuntime`](#use-chat-runtime)
* [`useVercelUseChatRuntime`](#use-vercel-use-chat-runtime) (legacy)
* [`useVercelUseAssistantRuntime`](#use-vercel-use-assistant-runtime)
* [`useVercelRSCRuntime`](#use-vercel-rsc-runtime)
* [`useDangerousInBrowserRuntime`](#use-dangerous-in-browser-runtime)

### LangGraph

* [`useLangGraphRuntime`](#use-lang-graph-runtime)

### Local Runtime

* [`useLocalRuntime`](#use-local-runtime)

### External Store Runtime

* [`useExternalStoreRuntime`](#use-external-store-runtime)
* [`createMessageConverter`](#create-message-converter)

### Thread List Runtime

* [`useRemoteThreadListRuntime`](#use-remote-thread-list-runtime)
* [`useCloudThreadListRuntime`](#use-cloud-thread-list-runtime)

## Runtime Adapters

### Attachment

* [`AttachmentAdapter`](#attachment-adapter)
* [`SimpleImageAttachmentAdapter`](#simple-image-attachment-adapter)
* [`SimpleTextAttachmentAdapter`](#simple-text-attachment-adapter)
* [`CompositeAttachmentAdapter`](#composite-attachment-adapter)

### Feedback

* [`FeedbackAdapter`](#feedback-adapter)

### Speech

* [`SpeechSynthesisAdapter`](#speech-synthesis-adapter)
* [`WebSpeechSynthesisAdapter`](#web-speech-synthesis-adapter)

## Highest Level Context Providers

<Component
  name="AssistantRuntimeProvider"
  isContextProvider={true}
  providedContexts={[
  { name: "Assistant Context", color: contextColors["Assistant Context"] },
  { name: "Thread Context", color: contextColors["Thread Context"] },
  {
    name: "Thread Composer Context",
    color: contextColors["Composer Context"],
    link: "#composer-context",
  },
]}
  docsLink="./context-providers/AssistantRuntimeProvider"
  tooltip="Provides the highest level context for the assistant-ui"
  props="runtime={runtime}"
>
  <Component name="Thread" isLink={true} />

  <Component name="ThreadList" isLink={true} />
</Component>

<Component
  name="TextContentPartProvider"
  isContextProvider={true}
  providedContexts={[
  {
    name: "Text ContentPart Context",
    color: contextColors["ContentPart Context"],
    link: "#contentpart-context",
  },
]}
  docsLink="./context-providers/TextContentPartProvider"
  tooltip="Provides context for text content parts"
  props="text={text}"
>
  <Component name="ContentPart" isLink={true} />
</Component>

<ContextLevel color={contextColors["Assistant Context"]}>
  ## Assistant Context

  The context available to components inside `<AssistantRuntimeProvider />`. You usually wrap your entire application in this context.

  ### AssistantRuntime

  Programmatically access the assistant's state and actions.

  * [`useAssistantRuntime`](#use-assistant-runtime)

  ### Instructions

  Add system prompt instructions

  * [`useAssistantInstructions`](#use-assistant-instructions)

  ### Tool UI

  Register tool UIs

  * [`makeAssistantTool`](#make-assistant-tool)
  * [`makeAssistantToolUI`](#make-assistant-tool-ui)
  * [`useAssistantTool`](#use-assistant-tool)
  * [`useAssistantToolUI`](#use-assistant-tool-ui)

  Programmatically access the list of registered tool UIs (Experimental)

  * [`useToolUIs`](#use-tool-uis)
  * [`useToolUIsStore`](#use-tool-uis-store)

  ### ThreadListPrimitive

  Shows a list of threads and allows the user to switch between them.

  <Component name="ThreadListPrimitive.Root" docsLink="#thread-list-primitive-root" tooltip="Root component for the thread list">
    <Component name="ThreadListPrimitive.New" docsLink="#thread-list-primitive-new" tooltip="Component for creating a new thread" />

    <Component
      name="ThreadListPrimitive.Items"
      isContextProvider={true}
      providedContexts={[
    {
      name: "ThreadListItem Context",
      color: contextColors["ThreadListItem Context"],
    },
  ]}
      docsLink="#thread-list-primitive-items"
      tooltip="Container for thread list items, provides context for individual items"
      props="components={...}"
    />
  </Component>
</ContextLevel>

<ContextLevel color={contextColors["Thread Context"]}>
  ## Thread Context

  The context for a single thread. Currently always corresponds to the runtime's main thread.

  ### ThreadRuntime

  Programmatically access the thread's state and actions.

  * [`useThread`](#use-thread)
  * [`useThreadComposer`](#use-thread-composer)
  * [`useThreadRuntime`](#use-thread-runtime)

  ### ModelContext

  * [`useThreadModelContext`](#use-thread-model-context)

  ### ThreadViewportStore

  * [`useThreadViewport`](#use-thread-viewport)
  * [`useThreadViewportStore`](#use-thread-viewport-store)

  ### ThreadPrimitive

  A conversation thread.

  <Component name="ThreadPrimitive.Root" docsLink="#thread-primitive-root" tooltip="Root component for a thread">
    <Component name="ThreadPrimitive.Viewport" docsLink="#thread-primitive-viewport" tooltip="Viewport for the thread content">
      <Component
        name="ThreadPrimitive.Messages"
        isContextProvider={true}
        providedContexts={[
      { name: "Message Context", color: contextColors["Message Context"] },
      {
        name: "Edit Composer Context",
        color: contextColors["Composer Context"],
        link: "#composer-context",
      },
    ]}
        docsLink="#thread-primitive-messages"
        tooltip="Container for thread messages, provides context for messages and edit composer"
      >
        <Component name="Message" isLink={true} />
      </Component>

      <Component name="ThreadPrimitive.ScrollToBottom" docsLink="#thread-primitive-scroll-to-bottom" tooltip="Scrolls to the bottom of the thread" />

      <Component name="ThreadPrimitive.Empty" docsLink="#thread-primitive-empty" tooltip="Displayed when the thread is empty" />

      <Component name="ThreadPrimitive.If" docsLink="#thread-primitive-if" tooltip="Conditional rendering within the thread" />

      <Component name="ThreadPrimitive.Suggestion" docsLink="#thread-primitive-suggestion" tooltip="Displays suggestions in the thread" />

      <Component name="Composer" isLink={true} />
    </Component>
  </Component>

  ### AssistantModalPrimitive

  A floating modal that usually appears in the lower right corner of the screen. Common for support use cases.

  <Component name="AssistantModalPrimitive.Root" docsLink="#assistant-modal-primitive-root" tooltip="Root component for the assistant modal">
    <Component name="AssistantModalPrimitive.Trigger" docsLink="#assistant-modal-primitive-trigger" tooltip="Trigger to open the assistant modal" />

    <Component name="AssistantModalPrimitive.Anchor" docsLink="#assistant-modal-primitive-anchor" tooltip="Anchor point for the assistant modal" />

    <Component name="AssistantModalPrimitive.Content" docsLink="#assistant-modal-primitive-content" tooltip="Content of the assistant modal" />
  </Component>
</ContextLevel>

<ContextLevel color={contextColors["Composer Context"]}>
  ## Composer Context

  Manages the state and actions for the message composer

  ### ComposerRuntime

  * [`useComposer`](#use-composer)
  * [`useComposerRuntime`](#use-composer-runtime)

  ### ComposerPrimitive

  <Component name="ComposerPrimitive.Root" docsLink="#composer-primitive-root" tooltip="Root component for the composer">
    <Component name="ComposerPrimitive.Input" docsLink="#composer-primitive-input" tooltip="Input field for composing messages" />

    <Component name="ComposerPrimitive.Send" docsLink="#composer-primitive-send" tooltip="Button to send the composed message" />

    <Component name="ComposerPrimitive.Cancel" docsLink="#composer-primitive-cancel" tooltip="Button to cancel composing" />

    <Component
      name="ComposerPrimitive.Attachments"
      isContextProvider={true}
      providedContexts={[
    {
      name: "Attachment Context",
      color: contextColors["Attachment Context"],
    },
  ]}
      docsLink="#composer-primitive-attachments"
      tooltip="Manages attachments in the composer"
    />

    <Component name="ComposerPrimitive.AddAttachment" docsLink="#composer-primitive-add-attachment" tooltip="Button to add an attachment" />
  </Component>
</ContextLevel>

<ContextLevel color={contextColors["Message Context"]}>
  ## Message Context

  Manages the state and actions for individual messages

  ### MessageRuntime

  * [`useMessage`](#use-message)
  * [`useEditComposer`](#use-edit-composer)
  * [`useMessageRuntime`](#use-message-runtime)

  ### MessageUtilsStore

  * [`useMessageUtils`](#use-message-utils)
  * [`useMessageUtilsStore`](#use-message-utils-store)

  ### MessagePrimitive

  <Component name="MessagePrimitive.Root" docsLink="#message-primitive-root" tooltip="Root component for a message">
    <Component
      name="MessagePrimitive.Content"
      isContextProvider={true}
      providedContexts={[
    {
      name: "ContentPart Context",
      color: contextColors["ContentPart Context"],
    },
  ]}
      docsLink="#message-primitive-content"
      tooltip="Displays the content of the message"
    />

    <Component
      name="MessagePrimitive.Attachments"
      isContextProvider={true}
      providedContexts={[
    {
      name: "Attachment Context",
      color: contextColors["Attachment Context"],
    },
  ]}
      docsLink="#message-primitive-attachments"
      tooltip="Displays attachments in the message"
    />

    <Component name="MessagePrimitive.If" docsLink="#message-primitive-if" tooltip="Conditional rendering within the message" />
  </Component>

  ### ActionBarPrimitive

  <Component name="ActionBarPrimitive.Root" docsLink="#action-bar-primitive-root" tooltip="Root component for the action bar">
    <Component name="ActionBarPrimitive.Copy" docsLink="#action-bar-primitive-copy" tooltip="Copies the message content" />

    <Component name="ActionBarPrimitive.Edit" docsLink="#action-bar-primitive-edit" tooltip="Edits the message" />

    <Component name="ActionBarPrimitive.Reload" docsLink="#action-bar-primitive-reload" tooltip="Reloads the message" />

    <Component name="ActionBarPrimitive.Speak" docsLink="#action-bar-primitive-speak" tooltip="Speaks the message content" />

    <Component name="ActionBarPrimitive.StopSpeaking" docsLink="#action-bar-primitive-stop-speaking" tooltip="Stops speaking the message" />

    <Component name="ActionBarPrimitive.FeedbackPositive" docsLink="#action-bar-primitive-feedback-positive" tooltip="Provides positive feedback" />

    <Component name="ActionBarPrimitive.FeedbackNegative" docsLink="#action-bar-primitive-feedback-negative" tooltip="Provides negative feedback" />
  </Component>

  ### BranchPickerPrimitive

  <Component name="BranchPickerPrimitive.Root" docsLink="#branch-picker-primitive-root" tooltip="Root component for the branch picker">
    <Component name="BranchPickerPrimitive.Previous" docsLink="#branch-picker-primitive-previous" tooltip="Navigates to the previous branch" />

    <Component name="BranchPickerPrimitive.Number" docsLink="#branch-picker-primitive-number" tooltip="Displays the current branch number" />

    <Component name="BranchPickerPrimitive.Next" docsLink="#branch-picker-primitive-next" tooltip="Navigates to the next branch" />
  </Component>
</ContextLevel>

<ContextLevel color={contextColors["ContentPart Context"]}>
  ## ContentPart Context

  Manages the state and actions for content parts within messages

  ### ContentPartRuntime

  * [`useContentPart`](#use-content-part)
  * [`useContentPartText`](#use-content-part-text)
  * [`useContentPartReasoning`](#use-content-part-reasoning)
  * [`useContentPartRuntime`](#use-content-part-runtime)

  ### ContentPartPrimitive

  <Component name="ContentPartPrimitive.Text" docsLink="#content-part-text" tooltip="Represents a text part of the message content" />

  ### MarkdownText

  <Component name="MarkdownText" docsLink="#markdown-text" tooltip="Renders markdown text in the message" />
</ContextLevel>

<ContextLevel color={contextColors["Attachment Context"]}>
  ## Attachment Context

  Manages the state and actions for attachments in messages and composer

  ### AttachmentRuntime

  * [`useAttachment`](#use-attachment)
  * [`useAttachmentRuntime`](#use-attachment-runtime)

  ### AttachmentPrimitive

  <Component name="AttachmentPrimitive.Root" docsLink="#attachment-primitive-root" tooltip="Root component for an attachment">
    <Component name="AttachmentPrimitive.Name" docsLink="#attachment-primitive-name" tooltip="Displays the name of the attachment" />

    <Component name="AttachmentPrimitive.Delete" docsLink="#attachment-primitive-delete" tooltip="Deletes the attachment" />

    <Component name="AttachmentPrimitive.Thumb" docsLink="#attachment-primitive-thumb" tooltip="Displays a thumbnail of the attachment" />
  </Component>
</ContextLevel>

<ContextLevel color={contextColors["ThreadListItem Context"]}>
  ## ThreadListItem Context

  Manages the state and actions for individual thread list items

  ### ThreadListItemRuntime

  * [`useThreadListItem`](#use-thread-list-item)
  * [`useThreadListItemRuntime`](#use-thread-list-item-runtime)

  ### ThreadListItem

  <Component name="ThreadListItemPrimitive.Root" docsLink="#thread-list-item-primitive-root" tooltip="Root component for a thread list item">
    <Component name="ThreadListItemPrimitive.Trigger" docsLink="#thread-list-item-primitive-trigger" tooltip="Trigger for thread list item actions">
      <Component name="ThreadListItemPrimitive.Name" docsLink="#thread-list-item-primitive-name" tooltip="Displays the name of the thread" />
    </Component>

    <Component name="ThreadListItemPrimitive.Archive" docsLink="#thread-list-item-primitive-archive" tooltip="Archives the thread" />

    <Component name="ThreadListItemPrimitive.Unarchive" docsLink="#thread-list-item-primitive-unarchive" tooltip="Unarchives the thread" />

    <Component name="ThreadListItemPrimitive.Delete" docsLink="#thread-list-item-primitive-delete" tooltip="Deletes the thread" />

    <Component name="ThreadListItemPrimitive.Rename" docsLink="#thread-list-item-primitive-rename" tooltip="Renames the thread" />
  </Component>
</ContextLevel>

## Utilities

* [`useThreadViewportAutoscroll`](#use-thread-viewport-autoscroll)
* [`useInlineRender`](#use-inline-render)


file: ./content/docs/cloud/authorization.mdx
# User Authorization


        
The assistant-ui API can be directly accessed by your frontend. This elliminates the need for a backend server from your side, except for authorization of your users.

This document explains how you can setup your server to authorize users to access the assistant-ui API.

## Workspaces

Authorization is granted to a workspace. Depending on the structure of your app, you might want to use user\_ids as the workspace\_id, or you might want to use a more complex structure.
For example, if your app supports multiple "projects", you might want to use the project\_id + user\_id as the workspace id (thread history scoped to user+project pairs).

## Workspace Auth Tokens

assistant-ui issues workspace auth tokens. These tokens give access to the assistant-ui API for a specific workspace.
Tokens are short lived (5 minutes), so the client needs to periodically request a new token (handled by assistant-ui).

There are two supported approaches to obtain a workspace auth token:

* Direct integration with your auth provider
* From a backend server / serverless function

### Choosing the right approach

Direct integration with your auth provider:

* simpler to setup and maintain
* assigns a workspace\_id to every user (by using the user\_id as the workspace\_id)
* requires a supported auth provider (Clerk, Auth0, Supabase, Firebase, Stytch, Kinde, ...)

Backend server:

* more complex to setup
* more flexible workspace structure (multi-user workspaces, workspaces per project, etc.)
* supports self hosted auth solutions, e.g. Auth.js
* requires a backend server / serverless function

You can always switch between the two approaches without any downtime or necessary database migrations.
Choose direct integration with your auth provider if you can. Otherwise, use a backend server.

### Auth Provider Integration

In the AssistantUI dashboard, go to the "Auth Integrations" tab and add a new integration.
Follow the steps to add your auth provider. (See the auth providers we have guides for at the bottom of this page.)

Then, pass in a function to `authToken` that returns an ID token from your auth provider.

```ts
import { AssistantCloud } from "@assistant-ui/react";

const assistantCloud = new AssistantCloud({
  authToken: () => JWT_TOKEN
});
```

### Integration with an Auth Provider

#### Backend API Endpoint

The following is an api route example to create an auth token based on an authenticated user's orgId and userId.

In the Assistant Cloud dashboard, go to the "API Keys" tab and add a new API key, add the key the environment variable `ASSISTANT_API_KEY=[KEY]`

```ts title="/app/api/assistant-ui-token/route.ts"
import { AssistantCloud } from "@assistant-ui/react";
import { auth } from "@clerk/nextjs/server";
 
export const POST = async (req: Request) => {
  const { userId, orgId } = await auth();
 
  if (!userId) throw new Error("User not authenticated");
 
  const workspaceId = orgId ? `${orgId}:${userId}` : userId;
  const assistantCloud = new AssistantCloud({
    apiKey: process.env["ASSISTANT_API_KEY"]!,
    userId,
    workspaceId,
  });
  const {token} = await assistantCloud.auth.tokens.create();

  return new Response(token);
};
```

#### Frontend Implementation

The following is an api route example to create an auth token based on an authenticated user's orgId and userId.

```ts title="client.ts"
const cloud = new AssistantCloud({
  baseUrl: process.env["NEXT_PUBLIC_ASSISTANT_BASE_URL"]!,
  authToken: () =>
    fetch("/api/assistant-ui-token", { method: "POST" }).then((r) =>
      r.json().then((data) => data.token)
    ),
});

const runtime = useChatRuntime({
  api: "/api/chat",
  cloud,
});
```

### Anonymous (without auth provider) Frontend Implementation

The following is a example to get auth tokens for Clerk based on the org\_id and user\_id:

```ts title="/app/api/assistant-ui-token/route.ts"
import { AssistantCloud } from "@assistant-ui/react";

const cloud = new AssistantCloud({
  baseUrl: process.env["NEXT_PUBLIC_ASSISTANT_BASE_URL"]!,
  anonymous: true,
});

const runtime = useChatRuntime({
  api: "/api/chat",
  cloud,
});

return (
  <AssistantRuntimeProvider runtime={runtime}>
    <div className="grid h-dvh grid-cols-[200px_1fr] gap-x-2 px-4 py-4">
      <ThreadList />
      <MyThread />
    </div>
  </AssistantRuntimeProvider>
);

```

### Setting up the Clerk Auth Provider

First, go to the Clerk dashboard and under "Configure" tab, "JWT Templates" section, create a new template. Choose a blank template and name it "assistant-ui".

As the "Claims" field, enter the following:

```json
{
  "aud": "assistant-ui"
}
```

<Callout emoji="">
  <b>Note:</b> The aud claim ensures that the JWT is only valid for the
  assistant-ui API.
</Callout>

You can leave everything else as default. Take note of the "Issuer" and "JWKS Endpoint" fields.

Then, In the assistant-cloud dashboard, navigate to the "Auth Rules" tab and create a new rule. Choose "Clerk" and enter the Issuer and JWKS Endpoint from the previous step. As the "Audience" field, enter "assistant-ui".


file: ./content/docs/cloud/overview.mdx
# Overview


        
Assistant Cloud is a hosted service built for assistant-ui frontends that offers comprehensive thread management and message history. It automatically persists threads, supports human-in-the-loop workflows, and integrates with common auth providers to seamlessly allow users to resume conversations at any point.

## Features

### Thread management

Using our `<ThreadList />` component, show the users a list of conversations. Allow the users to seamlessly switch between conversations and even let long running tasks run in the background.

Assistant Cloud automatically persists a list of threads and corresponding metadata. It also automatically generates a title for conversations based on the initial messages.

Supported backends:

* AI SDK
* LangGraph
* Custom

### Chat history

For every conversation, Assistant Cloud can store the history of messages, allowing the user to resume the conversation at any point in time.
This supports human in the loop workflows, where the execution of an agent is interrupted until user feedback is collected.

Supported backends:

* AI SDK
* LangGraph
* Custom (currently only Local Runtime)

### Authorization

Assistant Cloud integrates with your auth provider (Clerk, Auth0, Supabase, Firebase, ...) to identify your users and authorize them to access just the conversations they are allowed to see.

Supported auth providers:

* Clerk
* Auth0
* Supabase
* Firebase
* Your own

## Getting Started

To get started, create an account at [Assistant Cloud Dashboard](https://cloud.assistant-ui.com/) and follow one of the walkthroughs for your preferred backend:

* [AI SDK](/docs/cloud/persistence/ai-sdk)
* [LangGraph](/docs/cloud/persistence/langgraph)

You can also check out our example repositories to see how to integrate Assistant Cloud with your frontend:

* [With AI SDK](https://github.com/assistant-ui/assistant-ui/tree/main/examples/with-cloud)
* [With LangGraph](https://github.com/assistant-ui/assistant-ui/tree/main/examples/with-langgraph)


file: ./content/docs/concepts/architecture.mdx
# Architecture


        
import Image from "next/image";
import architecture from "@/assets/docs/architecture.png";

### Architecture

`assistant-ui` consists of two parts, ***Runtime*** and ***UI Components***.

<Image src={architecture} alt="Architecture diagram, UI components connected to the runtime layer and the runtime layer connected to LLM and tools" height={300} className="mx-auto my-2 dark:hue-rotate-180 dark:invert" />

The Runtime and UI Components each require independent setup and both must be set up.


file: ./content/docs/concepts/runtime-layer.mdx
# Runtime Layer


        
assistant-ui components are full stack components. This means that they include both the UI presentation, but also logic to communicate with an external system. This logic is handled by the runtime layer and APIs.

You interact with the runtime layer in two ways:

* defining a runtime for your app
* using the runtime APIs to interact with the runtime

## Defining a runtime

assistant-ui ships with two low-level runtimes:

* `useLocalRuntime`
* `useExternalStoreRuntime`

Both of these runtimes let you implement your own runtime. The conceptual difference between the two is that `useLocalRuntime` takes ownership of the data layer, while `useExternalStoreRuntime` does not.

If you have a stateful API to integrate, use `useExternalStoreRuntime`, if you have a stateless API to integrate, use `useLocalRuntime`.

### Higher level runtimes

For many services and APIs, assistant-ui provides deeper integrations. These are built with the two low-level runtimes mentioned above.

* `useChatRuntime`: Connect to Vercel AI SDK backends
* `useVercelUseChatRuntime`: Integrate with Vercel AI SDK's `useChat` hook
* `useVercelUseAssistantRuntime`: Integrate with Vercel AI SDK's `useAssistant` hook (OpenAI Assistants API)
* `useVercelRSCRuntime`: Integrate with Vercel AI SDK React Server Components
* `useLangGraphRuntime`: Connect to LangGraph Cloud
* ...

### Runtime Providers

The following components accept a `runtime` prop:

* `AssistantRuntimeProvider`
* `Thread`

These components put the Runtime in the React Context, so that all child components can access the runtime.

### Runtime Adapters

Most runtimes accept additional adapters to configure extra integrations:

* ChatModelAdapter: Configures the backend API
* AttachmentAdapter: Configures the file/media attachment API
* SpeechSynthesisAdapter: Configures the speech API
* FeedbackAdapter: Configures the feedback API
* SuggestionAdapter: Configures dynamic suggestion generation based on conversation context

## Using the runtime APIs

The same API used by the assistant-ui components is also available to you. This allows you to build your own UI components and integrate them with the runtime layer.

### Runtime Hierarchy

The runtime API is nested as such:

import { File, Folder, Files } from "fumadocs-ui/components/files";

<Files>
  <Folder name="AssistantRuntime" defaultOpen>
    <Folder name="ThreadListRuntime" defaultOpen>
      <Folder name="ThreadRuntime" defaultOpen>
        <Folder name="MessageRuntime" defaultOpen>
          <Folder name="ContentPartRuntime (Text / Reasoning / Image / Audio / Tool-Call / UI)" defaultOpen />

          <Folder name="MessageAttachmentRuntime" defaultOpen />

          <Folder name="EditComposerRuntime" defaultOpen>
            <Folder name="EditComposerAttachmentRuntime" defaultOpen />
          </Folder>
        </Folder>

        <Folder name="ThreadComposerRuntime" defaultOpen>
          <Folder name="ThreadComposerAttachmentRuntime" defaultOpen />
        </Folder>
      </Folder>
    </Folder>
  </Folder>
</Files>

The AssistantRuntime (which encompasses everything), is sometimes simply called `Runtime`.

### Runtime Context Provider Components

The following components provide the runtime APIs:

```tsx
// provides AssistantRuntime, ThreadListRuntime, ThreadRuntime, ComposerRuntime (ThreadComposer)
<AssistantRuntimeProvider runtime={runtime} />

// renders every message, provides MessageRuntime, ComposerRuntime (EditComposer)
<ThreadPrimitive.Messages components={{ Message, ... }} />

// renders every content part, provides ContentPartRuntime
<MessagePrimitive.Content components={{ Text, Reasoning, Image, Audio, UI, tools }} />

// renders every attachment, provides AttachmentRuntime (Thread or EditComposer)
<ComposerPrimitive.Attachments components={{ Attachment, ... }} />

// renders every attachment, provides AtatchmentRuntime (Message)
<MessagePrimitive.Attachments components={{ Attachment, ... }} />

// provides a custom TextContentPartRuntime
<TextContentPartProvider text="Hello!" />
```

### Accessing runtime APIs

You can access the runtime APIs with react hooks:

```tsx
const runtime = useAssistantRuntime();
const threadRuntime = useThreadRuntime();
const messageRuntime = useMessageRuntime();
const contentPartRuntime = useContentPartRuntime();

// thread manager has no separate hook (1:1 relationship with assistant runtime)
const ThreadListRuntime = useAssistantRuntime().threads;

// composer runtime is multi-use
const composerRuntime = useComposerRuntime(); // refers to edit composer if available, otherwise thread composer

// thread manager has no separate hook (1:1 relationship with assistant runtime)
const threadComposer = useThreadRuntime().composer;

// thread manager has no separate hook (1:1 relationship with assistant runtime)
const editComposerRuntime = useMessageRuntime().composer;

// attachment runtime is multi-use
const attachmentRuntime = useAttachmentRuntime(); // refers to the closest attachment runtime
const threadComposerAttachmentRuntime = useThreadComposerAttachmentRuntime();
const editComposerAttachmentRuntime = useEditComposerAttachmentRuntime();
const messageAttachmentRuntime = useMessageAttachmentRuntime();
```

### Accessing runtime state

Most runtimes also expose a state through two methods `getState` and `subscribe`. The following helper hooks subscribe to the state, so that your component is updated when the state changes:

```tsx
useThreadList(); // get thread manager state
useThread(); // get thread state
useMessage(); // get message state
useContentPart(); // get content part state
useComposer(); // get composer state
useThreadComposer(); // get thread composer state
useEditComposer(); // get edit composer state
useAttachment(); // get attachment state
useThreadComposerAttachment(); // get thread composer attachment state
useEditComposerAttachment(); // get edit composer attachment state
useMessageAttachment(); // get message attachment state
```

You might not want to subscribe to evey update. In that case, pass a callback selector to the hook:

```tsx
// only subscribe to role changes
const role = useMessage((state) => message.role);
```


file: ./content/docs/concepts/why.mdx
# Why assistant-ui?


        
assistant-ui is a collection of powerful, modular primitives to build AI chat interfaces.

The modular approach means that you can incrementally adopt assistant-ui (e.g. use the backend connectors and bring your own components, or use the frontend compoents and bring your own backend).
You can also partially opt out of assistant-ui whenever you hit any limitation in the library.


file: ./content/docs/copilots/make-assistant-readable.mdx
# makeAssistantVisible


        
`makeAssistantVisible` is a higher-order component (HOC) that makes React components "visible" by the assistant, allowing it to understand and interact with the component's HTML structure.

## Usage

```tsx
import { makeAssistantVisible } from "@assistant-ui/react";

const Button = ({ onClick, children }) => (
  <button onClick={onClick}>{children}</button>
);

// Basic usage - makes component HTML readable
const ReadableButton = makeAssistantVisible(Button);

// With clickable configuration
const ClickableButton = makeAssistantVisible(Button, {
  clickable: true, // Enables the click tool
});
```

## API Reference

### Parameters

* `Component`: The base React component to enhance
* `config`: Optional configuration object
  * `clickable`: When true, enables the assistant to programmatically click the component

### Behavior

The HOC will:

1. Make the component's HTML structure available to the assistant via the system context
2. Optionally provide a `click` tool if `clickable` is true
3. Handle nested readable components (only the outermost component's HTML is provided)
4. Forward refs and maintain component props

## Example

```tsx
// Create a readable form input
const Input = ({ label, ...props }) => (
  <div>
    <label>{label}</label>
    <input {...props} />
  </div>
);

const ReadableInput = makeAssistantVisible(Input);

// Use in your component
function Form() {
  return (
    <ReadableInput label="Email" type="email" placeholder="Enter your email" />
  );
}
```

## Technical Details

When a component is made readable:

* It's wrapped in a `ReadableContext.Provider` to handle nesting
* The component's `outerHTML` is provided as system context
* If `clickable` is true, a unique `data-click-id` is added and a `click` tool is provided
* The click tool uses `querySelector` and simulates a click event
* All props and refs are properly forwarded to maintain component functionality


file: ./content/docs/copilots/make-assistant-tool-ui.mdx
# makeAssistantToolUI


        
import { ParametersTable } from "@/components/docs";

The `makeAssistantToolUI` utility is used to register a tool UI component with the Assistant.

## Usage

```tsx
import { makeAssistantToolUI } from "@assistant-ui/react";

const MyToolUI = makeAssistantToolUI({
  toolName: "myTool",
  render: ({ args, result, status }) => {
    // render your tool UI here
  },
});
```

## API

### Parameters

<ParametersTable
  type="AssistantToolUIProps<TArgs, TResult>"
  parameters={[
  {
    name: "toolName",
    type: "string",
    description: "The name of the tool. This must match the name of the tool defined in the assistant.",
  },
  {
    name: "render",
    type: "ComponentType<ToolCallContentPartProps<TArgs, TResult>>",
    description: "A React component that renders the tool UI. Receives the following props:",
    required: true,
    children: [
      {
        type: "ToolCallContentPartProps<TArgs, TResult>",
        parameters: [
          {
            name: "type",
            type: "\"tool-call\"",
            description: "The content part type",
          },
          {
            name: "toolCallId",
            type: "string",
            description: "Unique identifier for this tool call",
          },
          {
            name: "toolName",
            type: "string",
            description: "The name of the tool being called",
          },
          {
            name: "args",
            type: "TArgs",
            description: "The arguments passed to the tool",
          },
          {
            name: "argsText",
            type: "string",
            description: "String representation of the arguments",
          },
          {
            name: "result",
            type: "TResult | undefined",
            description: "The result of the tool execution (if complete)",
          },
          {
            name: "isError",
            type: "boolean | undefined",
            description: "Whether the result is an error",
          },
          {
            name: "status",
            type: "ToolCallContentPartStatus",
            description: "The execution status object with a type property: \"running\", \"complete\", \"incomplete\", or \"requires_action\"",
          },
          {
            name: "addResult",
            type: "(result: TResult | ToolResponse<TResult>) => void",
            description: "Function to add a result (useful for human-in-the-loop tools)",
          },
          {
            name: "artifact",
            type: "unknown",
            description: "Optional artifact data associated with the tool call",
          },
        ],
      },
    ],
  },
]}
/>

### Returns

A React functional component that should be included in your component tree. This component doesn't render anything itself, but it registers the tool UI with the Assistant.

## Example

```tsx
import { makeAssistantToolUI } from "@assistant-ui/react";
import { AssistantRuntimeProvider } from "@assistant-ui/react";

const GetWeatherUI = makeAssistantToolUI({
  toolName: "get_weather",
  render: ({ args, result, status }) => {
    if (status.type === "requires_action") return <p>Getting weather for {args.location}...</p>;
    if (status.type === "running") return <p>Loading...</p>;
    if (status.type === "incomplete" && status.reason === "error") return <p>Error getting weather.</p>;
    if (status.type === "complete") return <p>The weather is {result.weather}.</p>;
    return null;
  },
});

function App() {
  return (
    <AssistantRuntimeProvider>
      {/* ...your other components */}
      <GetWeatherUI />
    </AssistantRuntimeProvider>
  );
}
```

This example shows how to create a simple UI for a `get_weather` tool. The UI will display different messages depending on the status of the tool execution.


file: ./content/docs/copilots/make-assistant-tool.mdx
# makeAssistantTool


        
import { ParametersTable } from "@/components/docs";

`makeAssistantTool` creates a React component that provides a tool to the assistant. This is useful for defining reusable tools that can be composed into your application.

## Usage

```tsx
import { makeAssistantTool, tool } from "@assistant-ui/react";
import { z } from "zod";

// Define the tool using the tool() helper
const submitForm = tool({
  parameters: z.object({
    email: z.string().email(),
    name: z.string(),
  }),
  execute: async ({ email, name }) => {
    // Implementation
    return { success: true };
  },
});

// Create a tool component
const SubmitFormTool = makeAssistantTool({
  ...submitForm,
  toolName: "submitForm"
});

// Use in your component
function Form() {
  return (
    <div>
      <form>{/* form fields */}</form>
      <SubmitFormTool />
    </div>
  );
}
```

## API Reference

### Parameters

<ParametersTable
  type="AssistantToolProps<TArgs, TResult>"
  parameters={[
  {
    name: "toolName",
    type: "string",
    description: "The unique identifier for the tool",
    required: true,
  },
  {
    name: "parameters",
    type: "StandardSchemaV1<TArgs> | JSONSchema7",
    description: "Schema defining the tool's parameters (typically a Zod schema)",
    required: true,
  },
  {
    name: "execute",
    type: "(args: TArgs, context: ToolExecutionContext) => TResult | Promise<TResult>",
    description: "Function that implements the tool's behavior (required for frontend tools)",
    required: true,
  },
  {
    name: "description",
    type: "string",
    description: "Optional description of the tool's purpose",
  },
  {
    name: "render",
    type: "ComponentType<ToolCallContentPartProps<TArgs, TResult>>",
    description: "Optional custom UI component for rendering the tool execution. Receives the following props:",
    children: [
      {
        type: "ToolCallContentPartProps<TArgs, TResult>",
        parameters: [
          {
            name: "type",
            type: "\"tool-call\"",
            description: "The content part type",
          },
          {
            name: "toolCallId",
            type: "string",
            description: "Unique identifier for this tool call",
          },
          {
            name: "toolName",
            type: "string",
            description: "The name of the tool being called",
          },
          {
            name: "args",
            type: "TArgs",
            description: "The arguments passed to the tool",
          },
          {
            name: "argsText",
            type: "string",
            description: "String representation of the arguments",
          },
          {
            name: "result",
            type: "TResult | undefined",
            description: "The result of the tool execution (if complete)",
          },
          {
            name: "isError",
            type: "boolean | undefined",
            description: "Whether the result is an error",
          },
          {
            name: "status",
            type: "ToolCallContentPartStatus",
            description: "The execution status object with a type property: \"running\", \"complete\", \"incomplete\", or \"requires_action\"",
          },
          {
            name: "addResult",
            type: "(result: TResult | ToolResponse<TResult>) => void",
            description: "Function to add a result (useful for human-in-the-loop tools)",
          },
          {
            name: "artifact",
            type: "unknown",
            description: "Optional artifact data associated with the tool call",
          },
        ],
      },
    ],
  },
]}
/>

### Returns

Returns a React component that:

* Provides the tool to the assistant when mounted
* Automatically removes the tool when unmounted
* Renders nothing in the DOM (returns null)

## Example with Multiple Tools

```tsx
import { makeAssistantTool, tool } from "@assistant-ui/react";
import { z } from "zod";

// Define tools
const validateEmail = tool({
  parameters: z.object({
    email: z.string(),
  }),
  execute: ({ email }) => {
    const isValid = email.includes("@");
    return { isValid, reason: isValid ? "Valid email" : "Missing @" };
  },
});

const sendEmail = tool({
  parameters: z.object({
    to: z.string().email(),
    subject: z.string(),
    body: z.string(),
  }),
  execute: async (params) => {
    // Tool logic
    return { sent: true };
  },
});

// Create tool components
const EmailValidator = makeAssistantTool({
  ...validateEmail,
  toolName: "validateEmail"
});
const EmailSender = makeAssistantTool({
  ...sendEmail,
  toolName: "sendEmail"
});

// Use together
function EmailForm() {
  return (
    <div>
      <form>{/* form fields */}</form>
      <EmailValidator />
      <EmailSender />
    </div>
  );
}
```

## Best Practices

1. **Parameter Validation**

   * Always use Zod schemas to define parameters
   * Be specific about parameter types and constraints
   * Add helpful error messages to schema validations

2. **Error Handling**

   * Return meaningful error messages
   * Consider returning partial results when possible
   * Handle async errors appropriately

3. **Composition**
   * Break complex tools into smaller, focused ones
   * Consider tool dependencies and interactions
   * Use multiple tools together for complex functionality


file: ./content/docs/copilots/model-context.mdx
# Model Context


        
Model Context is the foundation of intelligence in assistant-ui components. It provides configuration and capabilities to the assistant through a context provider system.

## Core Concepts

### System Instructions

System instructions define the base behavior and knowledge available to the assistant. These can be provided in several ways:

```tsx
import {
  useAssistantInstructions,
  makeAssistantVisible,
} from "@assistant-ui/react";

// Via useAssistantInstructions
useAssistantInstructions("You are a helpful assistant...");

// Via makeAssistantVisible
const ReadableComponent = makeAssistantVisible(MyComponent);
// Automatically provides component HTML as system context
```

### Tools

Tools are functions that the assistant can use to interact with your application. They can be provided through various mechanisms:

```tsx
import {
  makeAssistantVisible,
  makeAssistantTool,
  tool,
  useAssistantRuntime,
} from "@assistant-ui/react";
import { z } from "zod";

// Via makeAssistantVisible's clickable option
const ClickableButton = makeAssistantVisible(Button, {
  clickable: true, // Provides a click tool
});

// Via makeAssistantTool
const submitForm = tool({
  parameters: z.object({
    email: z.string().email(),
    name: z.string(),
  }),
  execute: async ({ email, name }) => {
    // Implementation
    return { success: true };
  },
});

const SubmitFormTool = makeAssistantTool({
  ...submitForm,
  toolName: "submitForm"
});

// Use in your component
function Form() {
  return (
    <div>
      <form>{/* form fields */}</form>
      <SubmitFormTool />
    </div>
  );
}
```

## Context Provider System

The context provider system allows components to contribute to the model context. Here's a typical usage pattern:

```tsx
import { useAssistantRuntime, tool } from "@assistant-ui/react";
import { useEffect } from "react";
import { z } from "zod";

function MyComponent() {
  const assistantRuntime = useAssistantRuntime();

  // Define tool using the tool() helper
  const myTool = tool({
    parameters: z.object({
      query: z.string(),
    }),
    execute: async ({ query }) => {
      const result = await searchDatabase(query);
      return { result };
    },
  });

  useEffect(() => {
    // Register context provider
    return assistantRuntime.registerModelContextProvider({
      getModelContext: () => ({
        system: "You are a helpful search assistant...",
        tools: { myTool },
      }),
    });
  }, [assistantRuntime]); // Re-register if runtime changes

  return <div>{/* component content */}</div>;
}
```

### Provider Composition

Multiple providers can be registered, and their contexts will be composed:

* System instructions are concatenated
* Tool sets are merged
* Nested readable components only contribute their context at the outermost level

## Best Practices

1. **System Instructions**

   * Keep them focused and specific to the component's purpose
   * Use useAssistantInstructions for explicit instructions
   * Let makeAssistantVisible handle component structure

2. **Tools**

   * Use the tool() helper to define tool schemas and behavior
   * Prefer makeAssistantTool for reusable tools
   * Handle errors gracefully
   * Consider async operations and loading states
   * Use the built-in click tool when possible

3. **Context Management**
   * Register providers in useEffect for proper cleanup
   * Clean up providers when components unmount
   * Avoid deeply nested readable components
   * Consider performance implications of large HTML structures


file: ./content/docs/copilots/motivation.mdx
# Intelligent Components


        
React revolutionized web development with components that combine logic, structure, and style. Now, with assistant-ui, we're adding a fourth dimension: intelligence. Let's learn how to build smart components through a practical banking app example.

## The Evolution of Components

Traditional React components combine three elements:

```tsx
// Traditional React Component
function TransactionHistory({ transactions }) {
  // 1. Logic (JavaScript/TypeScript)
  const handleRefund = (transactionId) => {
    // Process refund...
  };

  // 2. Structure (JSX/TSX)
  return (
    // 3. Style (CSS via className)
    <div className="transaction-list">
      {transactions.map((transaction) => (
        <div key={transaction.id} className="transaction-item">
          <span>${transaction.amount}</span>
          <span>{transaction.merchant}</span>
          <button onClick={() => handleRefund(transaction.id)}>
            Request Refund
          </button>
        </div>
      ))}
    </div>
  );
}
```

## Adding Intelligence

With assistant-ui, we can enhance this component with intelligence using four powerful APIs:

### 1. Making Components Readable (makeAssistantVisible)

First, let's make our buttons "readable" and interactive:

```tsx
import { makeAssistantVisible } from "@assistant-ui/react";

// Make the refund button intelligent
const SmartButton = makeAssistantVisible(
  ({ onClick, children }) => <button onClick={onClick}>{children}</button>,
  {
    clickable: true, // Allow the assistant to click the button
  },
);

function TransactionHistory({ transactions }) {
  return (
    <div className="transaction-list">
      {transactions.map((transaction) => (
        <div key={transaction.id} className="transaction-item">
          <span>${transaction.amount}</span>
          <span>{transaction.merchant}</span>
          <SmartButton onClick={() => handleRefund(transaction.id)}>
            Request Refund
          </SmartButton>
        </div>
      ))}
    </div>
  );
}
```

Now the assistant can:

* Understand the transaction history structure
* Interact with refund buttons
* Help users manage their transactions

### 2. Adding System Instructions (useAssistantInstructions)

Next, let's give the assistant specific instructions about its role:

```tsx
import { useAssistantInstructions } from "@assistant-ui/react";

function SmartTransactionHistory() {
  useAssistantInstructions(`
    You are a helpful banking assistant that:
    1. Helps users understand their transactions
    2. Explains refund policies
    3. Identifies suspicious transactions
    4. Guides users through the refund process
  `);

  return <TransactionHistory transactions={transactions} />;
}
```

### 3. Creating Tools (makeAssistantTool)

Let's add transaction-specific tools for the assistant:

```tsx
import { makeAssistantTool, tool } from "@assistant-ui/react";
import { z } from "zod";

// Define a tool to analyze transactions
const analyzeTransaction = tool({
  parameters: z.object({
    transactionId: z.string(),
    merchantName: z.string(),
  }),
  execute: async ({ transactionId, merchantName }) => {
    // Analyze transaction patterns, merchant reputation, etc.
    return {
      isSuspicious: false,
      merchantRating: 4.5,
      similarTransactions: 3,
      refundEligible: true,
    };
  },
});

// Create a tool component
const TransactionAnalyzer = makeAssistantTool({
  ...analyzeTransaction,
  toolName: "analyzeTransaction",
});

function SmartTransactionHistory() {
  // Previous instructions...
  return (
    <>
      <TransactionHistory transactions={transactions} />
      <TransactionAnalyzer />
    </>
  );
}
```

### 4. Adding Custom Context (Model Context)

Finally, let's add dynamic context based on the user's transaction patterns:

```tsx
import { useAssistantRuntime } from "@assistant-ui/react";
import { useEffect } from "react";

function SmartTransactionHistory({ userProfile }) {
  const assistantRuntime = useAssistantRuntime();

  useEffect(() => {
    return assistantRuntime.registerModelContextProvider({
      getModelContext: () => ({
        system: `
          User spending patterns:
          - Average transaction: ${userProfile.avgTransaction}
          - Common merchants: ${userProfile.frequentMerchants.join(", ")}
          - Refund history: ${userProfile.refundCount} requests
        `,
      }),
    });
  }, [assistantRuntime, userProfile]);

  // Previous components...
}
```

## The Result: An Intelligent Banking Experience

This enhanced component now provides:

* Natural language interaction with transaction history
* Contextual help for understanding transactions
* Automated transaction analysis
* Smart refund assistance

The assistant can now:

1. Read and understand transaction details
2. Follow banking-specific guidelines
3. Use tools to analyze transactions
4. Access user patterns for personalized help

This creates a more intuitive and safer banking experience while maintaining the familiar React component model.

## Next Steps

Learn more about each API:

* [makeAssistantVisible](make-assistant-readable) for component understanding
* [makeAssistantTool](make-assistant-tool) for transaction analysis
* [useAssistantInstructions](use-assistant-instructions) for behavior guidance
* [Model Context](model-context) for dynamic context management


file: ./content/docs/copilots/use-assistant-instructions.mdx
# useAssistantInstructions


        
`useAssistantInstructions` is a React hook that allows you to set system instructions for your assistant-ui components.

## Usage

```tsx
import { useAssistantInstructions } from "@assistant-ui/react";

function MyComponent() {
  // Simple string usage
  useAssistantInstructions("You are a helpful form assistant...");

  // With configuration object
  useAssistantInstructions({
    instruction: "You are a helpful form assistant...",
    disabled: false, // Optional: disable the instructions
  });

  return <div>My Component</div>;
}
```

## API Reference

### Parameters

The hook accepts either:

* A string containing the system instructions
* A configuration object with:
  * `instruction`: The system instructions
  * `disabled`: Optional boolean to disable the instructions

### Behavior

The hook will:

1. Register the provided instructions as system instructions in the model context
2. Automatically clean up when the component unmounts
3. Update when the instructions change
4. Do nothing if disabled is set to true

## Example

```tsx
function SmartForm() {
  useAssistantInstructions({
    instruction: `
      You are a form assistant that:
      - Validates user input
      - Provides helpful suggestions
      - Explains any errors
      - Guides users through complex fields
    `,
  });

  return <form>{/* Your form fields here */}</form>;
}
```


file: ./content/docs/guides/Attachments.mdx
# Attachments


        
import { AttachmentSample } from "../../../components/samples/attachment-sample";
import { Steps, Step } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";

Enable users to attach files to their messages, enhancing conversations with images, documents, and other content.

<AttachmentSample />

## Overview

The attachment system in assistant-ui provides a flexible framework for handling file uploads in your AI chat interface. It consists of:

* **Attachment Adapters**: Backend logic for processing attachment files
* **UI Components**: Pre-built components for attachment display and interaction
* **Runtime Integration**: Seamless integration with all assistant-ui runtimes

## Getting Started

<Steps>
  <Step>
    ### Install UI Components

    First, add the attachment UI components to your project:

    ```sh
    npx shadcn@latest add "https://r.assistant-ui.com/attachment"
    ```

    This adds `/components/assistant-ui/attachment.tsx` to your project.

    <Callout type="tip">
      **Next steps:** Feel free to adjust these auto-generated components (styling, layout, behavior) to match your application's design system.
    </Callout>
  </Step>

  <Step>
    ### Configure Attachment Adapter

    Set up an attachment adapter in your runtime provider:

    ```tsx title="/app/MyRuntimeProvider.tsx"
    import { useChatRuntime } from "@assistant-ui/react-ai-sdk";
    import {
      CompositeAttachmentAdapter,
      SimpleImageAttachmentAdapter,
      SimpleTextAttachmentAdapter,
    } from "@assistant-ui/react";

    const runtime = useChatRuntime({
      api: "/api/chat",
      adapters: {
        attachments: new CompositeAttachmentAdapter([
          new SimpleImageAttachmentAdapter(),
          new SimpleTextAttachmentAdapter(),
        ]),
      },
    });
    ```
  </Step>

  <Step>
    ### Add UI Components

    Integrate attachment components into your chat interface:

    ```tsx title="/components/assistant-ui/thread.tsx"
    // In your Composer component
    import {
      ComposerAttachments,
      ComposerAddAttachment,
    } from "@/components/assistant-ui/attachment";

    const Composer = () => {
      return (
        <ComposerPrimitive.Root>
          <ComposerAttachments />
          <ComposerAddAttachment />
          <ComposerPrimitive.Input placeholder="Type a message..." />
        </ComposerPrimitive.Root>
      );
    };

    // In your UserMessage component
    import { UserMessageAttachments } from "@/components/assistant-ui/attachment";

    const UserMessage = () => {
      return (
        <MessagePrimitive.Root>
          <UserMessageAttachments />
          <MessagePrimitive.Content />
        </MessagePrimitive.Root>
      );
    };
    ```
  </Step>
</Steps>

## Built-in Attachment Adapters

### SimpleImageAttachmentAdapter

Handles image files and converts them to data URLs for display in the chat UI. By default, images are shown inline but not sent to the LLM - use the VisionImageAdapter example above to send images to vision-capable models.

```tsx
const imageAdapter = new SimpleImageAttachmentAdapter();
// Accepts: image/* (JPEG, PNG, GIF, etc.)
// Output: { type: "image", url: "data:image/..." }
```

### SimpleTextAttachmentAdapter

Processes text files and wraps content in formatted tags:

```tsx
const textAdapter = new SimpleTextAttachmentAdapter();
// Accepts: text/plain, text/html, text/markdown, etc.
// Output: Content wrapped in <attachment>...</attachment> tags
```

### CompositeAttachmentAdapter

Combines multiple adapters to support various file types:

```tsx
const compositeAdapter = new CompositeAttachmentAdapter([
  new SimpleImageAttachmentAdapter(),
  new SimpleTextAttachmentAdapter(),
  // Add more adapters as needed
]);
```

## Creating Custom Attachment Adapters

Build your own adapters for specialized file handling. Below are complete examples for common use cases.

### Vision-Capable Image Adapter

Send images to vision-capable LLMs like GPT-4V, Claude 3, or Gemini Pro Vision:

```tsx
import {
  AttachmentAdapter,
  PendingAttachment,
  CompleteAttachment,
} from "@assistant-ui/react";

class VisionImageAdapter implements AttachmentAdapter {
  accept = "image/jpeg,image/png,image/webp,image/gif";

  async add({ file }: { file: File }): Promise<PendingAttachment> {
    // Validate file size (e.g., 20MB limit for most LLMs)
    const maxSize = 20 * 1024 * 1024; // 20MB
    if (file.size > maxSize) {
      throw new Error("Image size exceeds 20MB limit");
    }

    // Return pending attachment while processing
    return {
      id: crypto.randomUUID(),
      type: "image",
      name: file.name,
      file,
      status: { type: "running" },
    };
  }

  async send(attachment: PendingAttachment): Promise<CompleteAttachment> {
    // Convert image to base64 data URL
    const base64 = await this.fileToBase64DataURL(attachment.file);

    // Return in assistant-ui format with image content
    return {
      id: attachment.id,
      type: "image",
      name: attachment.name,
      content: [
        {
          type: "image",
          image: base64, // data:image/jpeg;base64,... format
        },
      ],
      status: { type: "complete" },
    };
  }

  async remove(attachment: PendingAttachment): Promise<void> {
    // Cleanup if needed (e.g., revoke object URLs if you created any)
  }

  private async fileToBase64DataURL(file: File): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        // FileReader result is already a data URL
        resolve(reader.result as string);
      };
      reader.onerror = reject;
      reader.readAsDataURL(file);
    });
  }
}
```

### PDF Document Adapter

Handle PDF files by extracting text or converting to base64 for processing:

```tsx
import {
  AttachmentAdapter,
  PendingAttachment,
  CompleteAttachment,
} from "@assistant-ui/react";

class PDFAttachmentAdapter implements AttachmentAdapter {
  accept = "application/pdf";

  async add({ file }: { file: File }): Promise<PendingAttachment> {
    // Validate file size
    const maxSize = 10 * 1024 * 1024; // 10MB limit
    if (file.size > maxSize) {
      throw new Error("PDF size exceeds 10MB limit");
    }

    return {
      id: crypto.randomUUID(),
      type: "document",
      name: file.name,
      file,
      status: { type: "running" },
    };
  }

  async send(attachment: PendingAttachment): Promise<CompleteAttachment> {
    // Option 1: Extract text from PDF (requires pdf parsing library)
    // const text = await this.extractTextFromPDF(attachment.file);
    
    // Option 2: Convert to base64 for API processing
    const base64Data = await this.fileToBase64(attachment.file);

    return {
      id: attachment.id,
      type: "document",
      name: attachment.name,
      content: [
        {
          type: "text",
          text: `[PDF Document: ${attachment.name}]\nBase64 data: ${base64Data.substring(0, 50)}...`
        }
      ],
      status: { type: "complete" },
    };
  }

  async remove(attachment: PendingAttachment): Promise<void> {
    // Cleanup if needed
  }

  private async fileToBase64(file: File): Promise<string> {
    const arrayBuffer = await file.arrayBuffer();
    const bytes = new Uint8Array(arrayBuffer);
    let binary = "";
    bytes.forEach(byte => {
      binary += String.fromCharCode(byte);
    });
    return btoa(binary);
  }
  
  // Optional: Extract text from PDF using a library like pdf.js
  private async extractTextFromPDF(file: File): Promise<string> {
    // Implementation would use pdf.js or similar
    // This is a placeholder
    return "Extracted PDF text content";
  }
}
```

## Using Custom Adapters

### With LocalRuntime

When using `LocalRuntime`, you need to handle images in your `ChatModelAdapter` (the adapter that connects to your AI backend):

```tsx
import { useLocalRuntime, ChatModelAdapter } from "@assistant-ui/react";

// This adapter connects LocalRuntime to your AI backend
const MyModelAdapter: ChatModelAdapter = {
  async run({ messages, abortSignal }) {
    // Convert messages to format expected by your vision-capable API
    const formattedMessages = messages.map(msg => {
      if (msg.role === "user" && msg.content.some(part => part.type === "image")) {
        // Format for GPT-4V or similar vision models
        return {
          role: "user",
          content: msg.content.map(part => {
            if (part.type === "text") {
              return { type: "text", text: part.text };
            }
            if (part.type === "image") {
              return {
                type: "image_url",
                image_url: { url: part.image }
              };
            }
            return part;
          })
        };
      }
      
      // Regular text messages
      return {
        role: msg.role,
        content: msg.content
          .filter(c => c.type === "text")
          .map(c => c.text)
          .join("\n")
      };
    });

    // Send to your vision-capable API
    const response = await fetch("/api/vision-chat", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ messages: formattedMessages }),
      signal: abortSignal,
    });

    const data = await response.json();
    return {
      content: [{ type: "text", text: data.message }],
    };
  },
};

// Create runtime with vision image adapter
const runtime = useLocalRuntime(MyModelAdapter, {
  adapters: { 
    attachments: new VisionImageAdapter() 
  },
});
```

### With Vercel AI SDK

If you're using the Vercel AI SDK, images are handled automatically through experimental attachments:

```tsx
// In your API route
import { streamText } from "ai";
import { openai } from "@ai-sdk/openai";

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: openai("gpt-4-vision-preview"),
    messages: messages.map(msg => {
      if (msg.experimental_attachments?.length) {
        // Images are automatically formatted for the model
        return {
          ...msg,
          experimental_attachments: msg.experimental_attachments
        };
      }
      return msg;
    }),
  });

  return result.toDataStreamResponse();
}
```

## Advanced Features

### Progress Updates

Provide real-time upload progress using async generators:

```tsx
class UploadAttachmentAdapter implements AttachmentAdapter {
  accept = "*/*";

  async *add({ file }: { file: File }) {
    const id = generateId();

    // Initial pending state
    yield {
      id,
      type: "file",
      name: file.name,
      file,
      status: { type: "running", progress: 0 },
    } as PendingAttachment;

    // Simulate upload progress
    for (let progress = 10; progress <= 90; progress += 10) {
      await new Promise((resolve) => setTimeout(resolve, 100));

      yield {
        id,
        type: "file",
        name: file.name,
        file,
        status: { type: "running", progress },
      } as PendingAttachment;
    }

    // Return final pending state
    return {
      id,
      type: "file",
      name: file.name,
      file,
      status: { type: "running", progress: 100 },
    } as PendingAttachment;
  }

  async send(attachment: PendingAttachment): Promise<CompleteAttachment> {
    // Upload the file and return complete attachment
    const url = await this.uploadFile(attachment.file);

    return {
      id: attachment.id,
      type: attachment.type,
      name: attachment.name,
      content: [
        {
          type: "file",
          data: url, // or base64 data
          mimeType: attachment.file.type,
        },
      ],
      status: { type: "complete" },
    };
  }

  async remove(attachment: PendingAttachment): Promise<void> {
    // Cleanup logic
  }

  private async uploadFile(file: File): Promise<string> {
    // Your upload logic here
    return "https://example.com/file-url";
  }
}
```

### Validation and Error Handling

Implement robust validation in your adapters:

```tsx
class ValidatedImageAdapter implements AttachmentAdapter {
  accept = "image/*";
  maxSizeBytes = 5 * 1024 * 1024; // 5MB

  async add({ file }: { file: File }): Promise<PendingAttachment> {
    // Validate file size
    if (file.size > this.maxSizeBytes) {
      return {
        id: generateId(),
        type: "image",
        name: file.name,
        file,
        status: {
          type: "incomplete",
          reason: "error",
          error: new Error("File size exceeds 5MB limit"),
        },
      };
    }

    // Validate image dimensions
    try {
      const dimensions = await this.getImageDimensions(file);
      if (dimensions.width > 4096 || dimensions.height > 4096) {
        throw new Error("Image dimensions exceed 4096x4096");
      }
    } catch (error) {
      return {
        id: generateId(),
        type: "image",
        name: file.name,
        file,
        status: {
          type: "incomplete",
          reason: "error",
          error,
        },
      };
    }

    // Return valid attachment
    return {
      id: generateId(),
      type: "image",
      name: file.name,
      file,
      status: { type: "running" },
    };
  }

  private async getImageDimensions(file: File) {
    // Implementation to check image dimensions
  }
}
```

### Multiple File Selection

Enable multi-file selection with custom limits:

```tsx
const composer = useComposer();

const handleMultipleFiles = async (files: FileList) => {
  const maxFiles = 5;
  const filesToAdd = Array.from(files).slice(0, maxFiles);

  for (const file of filesToAdd) {
    await composer.addAttachment({ file });
  }
};
```

## Backend Integration

### With Vercel AI SDK

Process attachments in your API route:

```tsx title="/app/api/chat/route.ts"
import { streamText } from "ai";
import { openai } from "@ai-sdk/openai";

export async function POST(req: Request) {
  const { messages } = await req.json();

  // Process messages with attachments
  const processedMessages = messages.map((msg) => {
    if (msg.role === "user" && msg.experimental_attachments) {
      // Handle attachments
      const attachmentContent = msg.experimental_attachments
        .map((att) => {
          if (att.contentType.startsWith("image/")) {
            return `[Image: ${att.name}]`;
          }
          return att.content;
        })
        .join("\n");

      return {
        ...msg,
        content: `${msg.content}\n\nAttachments:\n${attachmentContent}`,
      };
    }
    return msg;
  });

  const result = streamText({
    model: openai("gpt-4o"),
    messages: processedMessages,
  });

  return result.toDataStreamResponse();
}
```

### Custom Backend Handling

Implement your own attachment processing:

```tsx
// In your attachment adapter
class ServerUploadAdapter implements AttachmentAdapter {
  async send(attachment: PendingAttachment): Promise<CompleteAttachment> {
    const formData = new FormData();
    formData.append("file", attachment.file);

    const response = await fetch("/api/upload", {
      method: "POST",
      body: formData,
    });

    const { url, id } = await response.json();

    return {
      id,
      type: attachment.type,
      name: attachment.name,
      content: [
        {
          type: "image",
          url,
        },
      ],
      status: { type: "complete" },
    };
  }
}
```

## Runtime Support

Attachments work with all assistant-ui runtimes:

* **AI SDK Runtime**: `useChatRuntime`, `useAssistantRuntime`
* **External Store**: `useExternalStoreRuntime`
* **LangGraph**: `useLangGraphRuntime`
* **Custom Runtimes**: Any runtime implementing the attachment interface

<Callout type="tip">
  The attachment system is designed to be extensible. You can create adapters
  for any file type, integrate with cloud storage services, or implement custom
  processing logic to fit your specific needs.
</Callout>

## Best Practices

1. **File Size Limits**: Always validate file sizes to prevent memory issues
2. **Type Validation**: Verify file types match your `accept` pattern
3. **Error Handling**: Provide clear error messages for failed uploads
4. **Progress Feedback**: Show upload progress for better UX
5. **Security**: Validate and sanitize file content before processing
6. **Accessibility**: Ensure attachment UI is keyboard navigable

## Resources

* [Attachment UI Components](/docs/ui/Attachment) - UI implementation details
* [API Reference](/docs/api-reference) - Detailed type definitions


file: ./content/docs/guides/Branching.mdx
# Message Branching


        
import { BranchingSample } from "../../../components/samples/branching-sample";

Switch between different conversation branches.

<BranchingSample />

A new branch is created when:

* a user message is edited
* an assistant message is reloaded

Branches are automatically tracked by assistant-ui by observing changes to the `messages` array.

## Enabling branch support

You can show a branch picker by using `BranchPickerPrimitive`.

```tsx {1, 8, 15-30}
import { BranchPickerPrimitive } from "@assistant-ui/react";


const Message = () => {
  return (
    <MessagePrimitive.Root>
      ...
      <BranchPicker /> {/* <-- show the branch picker */}
      ...
    </EditComposerPrimitive.Root>
  );
};


const BranchPicker = () => {
  return (
    <BranchPickerPrimitive.Root hideWhenSingleBranch>
      <BranchPickerPrimitive.Previous />
      <BranchPickerPrimitive.Number /> / <BranchPickerPrimitive.Count />
      <BranchPickerPrimitive.Next />
    </BranchPickerPrimitive.Root>
  );
};
```

## API

You can access the current branch state or navigate via the API as well.\
These APIs rely on the message state and may only be called inside a message component.

```tsx
const hasBranches = useMessageIf({ hasBranches: true }); // whether branchCount is >= 2

// navigation
const goToNextBranch = useGoToNextBranch(); // null if there is no next branch
const goToPreviousBranch = useGoToPreviousBranch(); // null if there is no previous branch
```


file: ./content/docs/guides/Editing.mdx
# Message Editing


        
Give the user the ability to edit their message.

## Enabling edit support

You can show an editor interface by using `ComposerPrimitive`.

```tsx {1,11,25,31-43}
import { ComposerPrimitive } from "@assistant-ui/react";
...

const Thread = () => {
  return (
    <ThreadPrimitive.Root>
      <ThreadPrimitive.Viewport>
        ...
        <ThreadPrimitive.Messages components={{
          ...,
          EditComposer, // <-- Show our new component during edit mode
        }} />
      </ThreadPrimitive.Viewport>
      ...
    </ThreadPrimitive.Root>
  );
};

const UserMessage = () => {
  return (
    <MessagePrimitive.Root>
      ...
      <ActionBarPrimitive.Root>
        ...
        <ActionBarPrimitive.Edit /> {/* <-- add a button to enable edit mode */}
      </ActionBarPrimitive.Root>
    </MessagePrimitive.Root>
  );
};

// define a new component
const EditComposer = () => {
  return (
    // you can return a MessagePrimitive including a ComposerPrimitive, or only a ComposerPrimitive
    <MessagePrimitive.Root>
      ...
      <ComposerPrimitive.Root>
        <ComposerPrimitive.Input />
        <ComposerPrimitive.Cancel />
        <ComposerPrimitive.Send />
      </ComposerPrimitive.Root>
    </MessagePrimitive.Root>
  );
};
```


file: ./content/docs/guides/Speech.mdx
# Speech


        
import { SpeechSample } from "../../../components/samples/speech-sample";

## Text-to-Speech

assistant-ui supports text-to-speech via the `SpeechSynthesisAdapter` interface.

<SpeechSample />

### SpeechSynthesisAdapter

Currently, the following speech synthesis adapters are supported:

* `WebSpeechSynthesisAdapter`: Uses the browser's `Web Speech API` API

Support for other speech synthesis adapters is planned for the future.

Passing a `SpeechSynthesisAdapter` to the `EdgeRuntime` will enable text-to-speech support.

### UI

By default, a `Read aloud` button will be shown in the assistant message action bar.

This is implemented using `AssistantActionBar.SpeechControl` which is a wrapper around `AssistantActionBar.Speak` and `AssistantActionBar.StopSpeaking`.
The underlying primitives are `ActionBarPrimitive.Speak` and `ActionBarPrimitive.StopSpeaking`.

### Example

The following example uses the `WebSpeechSynthesisAdapter`.

```tsx
import { WebSpeechSynthesisAdapter } from "@assistant-ui/react";

const runtime = useChatRuntime({
  api: "/api/chat",
  adapters: {
    speech: new WebSpeechSynthesisAdapter(),
  },
});
```


file: ./content/docs/guides/ToolUI.mdx
# Generative UI


        
import { ToolUISample } from "../../../components/samples/tool-ui-sample";
import { Steps, Step } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";

Create custom UI components for AI tool calls, providing visual feedback and interactive experiences when tools are executed.

<ToolUISample />

## Overview

Tool UIs in assistant-ui allow you to create custom interfaces that appear when AI tools are called. These generative UI components enhance the user experience by:

* **Visualizing tool execution** with loading states and progress indicators
* **Displaying results** in rich, formatted layouts
* **Enabling user interaction** through forms and controls
* **Providing error feedback** with helpful recovery options

This guide demonstrates building tool UIs with the **Vercel AI SDK**.

## Creating Tool UIs

There are two main approaches to creating tool UIs in assistant-ui:

### 1. Client-Defined Tools (`makeAssistantTool`)

If you're creating tools on the client side, use `makeAssistantTool` to register them with the assistant context. Then create a UI component with `makeAssistantToolUI`:

```tsx
import { makeAssistantTool, tool } from "@assistant-ui/react";
import { z } from "zod";

// Define the tool
const weatherTool = tool({
  description: "Get current weather for a location",
  parameters: z.object({
    location: z.string(),
    unit: z.enum(["celsius", "fahrenheit"]),
  }),
  execute: async ({ location, unit }) => {
    const weather = await fetchWeatherAPI(location, unit);
    return weather;
  }
});

// Register the tool
const WeatherTool = makeAssistantTool({
  ...weatherTool,
  toolName: "getWeather"
});

// Create the UI
const WeatherToolUI = makeAssistantToolUI<
  { location: string; unit: "celsius" | "fahrenheit" },
  { temperature: number; description: string }
>({
  toolName: "getWeather",
  render: ({ args, result, status }) => {
    if (status.type === "running") {
      return <div>Checking weather in {args.location}...</div>;
    }

    return (
      <div className="weather-card">
        <h3>{args.location}</h3>
        <p>
          {result.temperature}{args.unit === "celsius" ? "C" : "F"}
        </p>
        <p>{result.description}</p>
      </div>
    );
  },
});
```

<Callout type="tip">
  Tools defined with `makeAssistantTool` can be passed to your backend using the `frontendTools` utility
</Callout>

Learn more about creating tools in the [Tools Guide](/docs/guides/Tools).

### 2. UI-Only for Existing Tools (`makeAssistantToolUI`)

If your tool is defined elsewhere (e.g., in your backend API, MCP server, or LangGraph), use `makeAssistantToolUI` to create just the UI component:

```tsx
import { makeAssistantToolUI } from "@assistant-ui/react";

const WeatherToolUI = makeAssistantToolUI<
  { location: string; unit: "celsius" | "fahrenheit" },
  { temperature: number; description: string }
>({
  toolName: "getWeather", // Must match the backend tool name
  render: ({ args, result, status }) => {
    // UI rendering logic only
  },
});
```

## Quick Start Example

This example shows how to implement the UI-only approach using `makeAssistantToolUI`:

<Steps>
  <Step>
    ### Create a Tool UI Component

    ```tsx
    import { makeAssistantToolUI } from "@assistant-ui/react";
    import { z } from "zod";

    type WeatherArgs = {
      location: string;
      unit: "celsius" | "fahrenheit";
    };

    type WeatherResult = {
      temperature: number;
      description: string;
      humidity: number;
      windSpeed: number;
    };

    const WeatherToolUI = makeAssistantToolUI<WeatherArgs, WeatherResult>({
      toolName: "getWeather",
      render: ({ args, status, result }) => {
        if (status.type === "running") {
          return (
            <div className="flex items-center gap-2">
              <Spinner />
              <span>Checking weather in {args.location}...</span>
            </div>
          );
        }

        if (status.type === "incomplete" && status.reason === "error") {
          return (
            <div className="text-red-500">
              Failed to get weather for {args.location}
            </div>
          );
        }

        return (
          <div className="weather-card rounded-lg bg-blue-50 p-4">
            <h3 className="text-lg font-bold">{args.location}</h3>
            <div className="mt-2 grid grid-cols-2 gap-4">
              <div>
                <p className="text-2xl">
                  {result.temperature}{args.unit === "celsius" ? "C" : "F"}
                </p>
                <p className="text-gray-600">{result.description}</p>
              </div>
              <div className="text-sm">
                <p>Humidity: {result.humidity}%</p>
                <p>Wind: {result.windSpeed} km/h</p>
              </div>
            </div>
          </div>
        );
      },
    });
    ```
  </Step>

  <Step>
    ### Register the Tool UI

    Place the component inside your `AssistantRuntimeProvider`:

    ```tsx
    function App() {
      return (
        <AssistantRuntimeProvider runtime={runtime}>
          <Thread />
          <WeatherToolUI />
        </AssistantRuntimeProvider>
      );
    }
    ```
  </Step>

  <Step>
    ### Define the Backend Tool (Vercel AI SDK)

    When using the Vercel AI SDK, define the corresponding tool in your API route:

    ```tsx title="/app/api/chat/route.ts"
    import { streamText, tool } from "ai";
    import { z } from "zod";

    export async function POST(req: Request) {
      const { messages } = await req.json();

      const result = streamText({
        model: openai("gpt-4o"),
        messages,
        tools: {
          getWeather: tool({
            description: "Get current weather for a location",
            parameters: z.object({
              location: z.string(),
              unit: z.enum(["celsius", "fahrenheit"]),
            }),
            execute: async ({ location, unit }) => {
              const weather = await fetchWeatherAPI(location);
              return {
                temperature: weather.temp,
                description: weather.condition,
                humidity: weather.humidity,
                windSpeed: weather.wind,
              };
            },
          }),
        },
      });

      return result.toDataStreamResponse();
    }
    ```
  </Step>
</Steps>

## Tool UI Patterns

### Component Pattern

Create standalone tool UI components:

```tsx
export const WebSearchToolUI = makeAssistantToolUI<
  { query: string },
  { results: SearchResult[] }
>({
  toolName: "webSearch",
  render: ({ args, status, result }) => {
    return (
      <div className="search-container">
        <div className="mb-3 flex items-center gap-2">
          <SearchIcon />
          <span>Search results for: "{args.query}"</span>
        </div>

        {status.type === "running" && <LoadingSpinner />}

        {result && (
          <div className="space-y-2">
            {result.results.map((item, index) => (
              <div key={index} className="rounded border p-3">
                <a href={item.url} className="font-medium text-blue-600">
                  {item.title}
                </a>
                <p className="text-sm text-gray-600">{item.snippet}</p>
              </div>
            ))}
          </div>
        )}
      </div>
    );
  },
});
```

### Hook Pattern

Use hooks for dynamic tool UI registration:

<Callout type="tip">
  When you assign your `makeAssistantToolUI({...})` call to a constant starting with `use`, you can call it directly as a hook inside your component. This pattern lets you access local props or state when rendering the tool UI.
</Callout>

```tsx
import { useAssistantToolUI } from "@assistant-ui/react";

function DynamicToolUI() {
  const [theme, setTheme] = useState("light");

  useAssistantToolUI({
    toolName: "analyzeData",
    render: ({ args, result, status }) => {
      // Hook allows access to component state
      return (
        <DataVisualization
          data={result}
          theme={theme}
          loading={status.type === "running"}
        />
      );
    },
  });

  return null;
}
```

### Inline Pattern

For tools that need access to parent component props:

<Callout type="tip">
  **Why `useInlineRender`?**
  By default, a tool UI's `render` function is static. Use `useInlineRender` when your UI needs access to dynamic component props (for example, to pass in an `id` or other contextual data).
</Callout>

```tsx
import { useAssistantToolUI, useInlineRender } from "@assistant-ui/react";

function ProductPage({ productId, productName }) {
  useAssistantToolUI({
    toolName: "checkInventory",
    render: useInlineRender(({ args, result }) => {
      // Access parent component props
      return (
        <div className="inventory-status">
          <h4>{productName} Inventory</h4>
          <p>
            Stock for {productId}: {result.quantity} units
          </p>
          <p>Location: {result.warehouse}</p>
        </div>
      );
    }),
  });

  return <div>Product details...</div>;
}
```

## Interactive Tool UIs

### User Input Collection

Create tools that collect user input during execution:

<Callout type="tip">
  **Pro tip:** Call `addResult(...)` exactly once to complete the tool call. After it's invoked, the assistant will resume the conversation with your provided data.
</Callout>

```tsx
const DatePickerToolUI = makeAssistantToolUI<
  { prompt: string },
  { date: string }
>({
  toolName: "selectDate",
  render: ({ args, result, addResult }) => {
    if (result) {
      return (
        <div className="rounded bg-green-50 p-3">
           Selected date: {new Date(result.date).toLocaleDateString()}
        </div>
      );
    }

    return (
      <div className="rounded border p-4">
        <p className="mb-3">{args.prompt}</p>
        <DatePicker
          onChange={(date) => {
            addResult({ date: date.toISOString() });
          }}
        />
      </div>
    );
  },
});
```

### Multi-Step Interactions

Build complex workflows with multiple user interactions:

```tsx
const ApprovalToolUI = makeAssistantToolUI<
  { action: string; details: any },
  { approved: boolean; reason?: string }
>({
  toolName: "requestApproval",
  render: ({ args, result, addResult }) => {
    const [reason, setReason] = useState("");

    if (result) {
      return (
        <div className={result.approved ? "text-green-600" : "text-red-600"}>
          {result.approved ? " Approved" : ` Rejected: ${result.reason}`}
        </div>
      );
    }

    return (
      <div className="rounded border-2 border-yellow-400 p-4">
        <h4 className="font-bold">Approval Required</h4>
        <p className="my-2">{args.action}</p>
        <pre className="rounded bg-gray-100 p-2 text-sm">
          {JSON.stringify(args.details, null, 2)}
        </pre>

        <div className="mt-4 flex gap-2">
          <button
            onClick={() => addResult({ approved: true })}
            className="rounded bg-green-500 px-4 py-2 text-white"
          >
            Approve
          </button>
          <button
            onClick={() => addResult({ approved: false, reason })}
            className="rounded bg-red-500 px-4 py-2 text-white"
          >
            Reject
          </button>
          <input
            type="text"
            placeholder="Rejection reason..."
            value={reason}
            onChange={(e) => setReason(e.target.value)}
            className="flex-1 rounded border px-2"
          />
        </div>
      </div>
    );
  },
});
```

## Advanced Features

### Tool Status Handling

The `status` prop provides detailed execution state:

```tsx
render: ({ status, args }) => {
  switch (status.type) {
    case "running":
      return <LoadingState />;

    case "requires-action":
      return <UserInputRequired reason={status.reason} />;

    case "incomplete":
      if (status.reason === "cancelled") {
        return <div>Operation cancelled</div>;
      }
      if (status.reason === "error") {
        return <ErrorDisplay error={status.error} />;
      }
      return <div>Failed: {status.reason}</div>;

    case "complete":
      return <SuccessDisplay />;
  }
};
```

### Field-Level Validation

Use `useToolArgsFieldStatus` to show validation states:

```tsx
import { useToolArgsFieldStatus } from "@assistant-ui/react";

const FormToolUI = makeAssistantToolUI({
  toolName: "submitForm",
  render: ({ args }) => {
    const emailStatus = useToolArgsFieldStatus("email");
    const phoneStatus = useToolArgsFieldStatus("phone");

    return (
      <form className="space-y-4">
        <div>
          <input
            type="email"
            value={args.email}
            className={emailStatus.type === "running" ? "loading" : ""}
            disabled
          />
          {emailStatus.type === "incomplete" && (
            <span className="text-red-500">Invalid email</span>
          )}
        </div>

        <div>
          <input
            type="tel"
            value={args.phone}
            className={phoneStatus.type === "running" ? "loading" : ""}
            disabled
          />
        </div>
      </form>
    );
  },
});
```

### Partial Results & Streaming

Display results as they stream in:

```tsx
const AnalysisToolUI = makeAssistantToolUI<
  { data: string },
  { progress: number; insights: string[] }
>({
  toolName: "analyzeData",
  render: ({ result, status }) => {
    const progress = result?.progress || 0;
    const insights = result?.insights || [];

    return (
      <div className="analysis-container">
        {status.type === "running" && (
          <div className="mb-4">
            <div className="mb-1 flex justify-between">
              <span>Analyzing...</span>
              <span>{progress}%</span>
            </div>
            <div className="w-full rounded bg-gray-200">
              <div
                className="h-2 rounded bg-blue-500"
                style={{ width: `${progress}%` }}
              />
            </div>
          </div>
        )}

        <div className="space-y-2">
          {insights.map((insight, i) => (
            <div key={i} className="rounded bg-gray-50 p-2">
              {insight}
            </div>
          ))}
        </div>
      </div>
    );
  },
});
```

### Custom Tool Fallback

Provide a custom UI for tools without specific UIs:

```tsx
<Thread
  components={{
    ToolFallback: ({ toolName, args, result }) => (
      <div className="tool-fallback rounded bg-gray-100 p-3">
        <code className="text-sm">
          {toolName}({JSON.stringify(args)})
        </code>
        {result && (
          <pre className="mt-2 text-xs">{JSON.stringify(result, null, 2)}</pre>
        )}
      </div>
    ),
  }}
/>
```

## Execution Context

Generative UI components have access to execution context through props:

```tsx
type ToolUIRenderProps<TArgs, TResult> = {
  // Tool arguments
  args: TArgs;
  argsText: string; // JSON stringified args

  // Execution status
  status: ToolCallContentPartStatus;
  isError?: boolean;

  // Tool result (may be partial during streaming)
  result?: TResult;

  // Tool metadata
  toolName: string;
  toolCallId: string;

  // Interactive callback
  addResult: (result: TResult) => void;

  // Optional artifact data
  artifact?: unknown;
};
```

## Best Practices

### 1. Handle All Status States

Always handle loading, error, and success states:

```tsx
render: ({ status, result, args }) => {
  if (status.type === "running") return <Skeleton />;
  if (status.type === "incomplete") return <ErrorState />;
  if (!result) return null;
  return <ResultDisplay result={result} />;
};
```

### 2. Provide Visual Feedback

Use animations and transitions for better UX:

```tsx
<div
  className={cn(
    "transition-all duration-300",
    status.type === "running" && "opacity-50",
    status.type === "complete" && "opacity-100",
  )}
>
  {/* Tool UI content */}
</div>
```

### 3. Make UIs Accessible

Ensure keyboard navigation and screen reader support:

```tsx
<button
  onClick={() => addResult(value)}
  aria-label="Confirm selection"
  className="focus:outline-none focus:ring-2"
>
  Confirm
</button>
```

### 4. Optimize Performance

Use `useInlineRender` to prevent unnecessary re-renders:

```tsx
useAssistantToolUI({
  toolName: "heavyComputation",
  render: useInlineRender(({ result }) => {
    // Expensive rendering logic
    return <ComplexVisualization data={result} />;
  }),
});
```

<Callout>
  Generative UI components are only displayed in the chat interface. The actual
  tool execution happens on the backend. This separation allows you to create
  rich, interactive experiences while keeping sensitive logic secure on the
  server.
</Callout>

## Related Guides

* [Tools Guide](/docs/guides/Tools) - Learn how to create and use tools with AI models
* [Tool Fallback](/docs/ui/ToolFallback) - Default UI for tools without custom components
* [API Reference](/docs/api-reference/primitives/ContentPart) - Detailed type definitions and component APIs


file: ./content/docs/guides/Tools.mdx
# Tools


        
Tools enable LLMs to take actions and interact with external systems. assistant-ui provides a comprehensive toolkit for creating, managing, and visualizing tool interactions in real-time.

## Overview

Tools in assistant-ui are functions that the LLM can call to perform specific tasks. They bridge the gap between the LLM's reasoning capabilities and real-world actions like:

* Fetching data from APIs
* Performing calculations
* Interacting with databases
* Controlling UI elements
* Executing workflows

When tools are executed, you can display custom generative UI components that provide rich, interactive visualizations of the tool's execution and results. Learn more in the [Generative UI guide](/docs/guides/ToolUI).

<Callout type="tip">
  If you haven't provided a custom UI for a tool, assistant-ui offers a [`ToolFallback`](/docs/ui/ToolFallback) component that you can add to your codebase to render a default UI for tool executions. You can customize this by creating your own Tool UI component for the tool's name.
</Callout>

## Tool Creation Methods

assistant-ui offers multiple ways to create and register tools, each suited for different use cases:

* **`makeAssistantTool`**: Register client-defined tools with the assistant context
* **`useAssistantTool`**: Hook-based dynamic tool registration
* **`makeAssistantToolUI`**: UI-only components for existing tools
* **Direct context registration**: Advanced registration with full model context control

### 1. Using `makeAssistantTool`

Register tools with the assistant context. Returns a React component that registers the tool when rendered:

```tsx
import { makeAssistantTool, tool } from "@assistant-ui/react";
import { z } from "zod";

// Define the tool
const weatherTool = tool({
  description: "Get current weather for a location",
  parameters: z.object({
    location: z.string().describe("City name or zip code"),
    unit: z.enum(["celsius", "fahrenheit"]).default("celsius")
  }),
  execute: async ({ location, unit }) => {
    // Tool execution logic
    const weather = await fetchWeatherAPI(location, unit);
    return weather;
  }
});

// Create the component
const WeatherTool = makeAssistantTool({
  ...weatherTool,
  toolName: "getWeather"
});

// Place the tool component inside AssistantRuntimeProvider
function App() {
  return (
    <AssistantRuntimeProvider runtime={runtime}>
      <WeatherTool />
      <Thread />
    </AssistantRuntimeProvider>
  );
}
```

<Callout type="tip">
  When using server-side runtimes like Vercel AI SDK, you can pass client-defined tools to your backend using `frontendTools`. See the [Client-Defined Tools with frontendTools](#client-defined-tools-with-frontendtools) section below.
</Callout>

### 2. Using `useAssistantTool` Hook

Register tools dynamically using React hooks. Useful for conditional tools or when tool availability depends on component state:

```tsx
import { useAssistantTool } from "@assistant-ui/react";
import { z } from "zod";

function DynamicTools() {
  const [dataSource, setDataSource] = useState<"local" | "cloud">("local");
  
  useAssistantTool({
    toolName: "searchData",
    description: "Search through the selected data source",
    parameters: z.object({
      query: z.string()
    }),
    execute: async ({ query }) => {
      if (dataSource === "local") {
        return await searchLocalDatabase(query);
      } else {
        return await searchCloudDatabase(query);
      }
    },
    // Re-register when data source changes
    enabled: true
  });
  
  return null;
}
```

### 3. Using `makeAssistantToolUI`

Create generative UI components for tools that are defined elsewhere. This is UI-only - the tool's execution logic must be registered separately (e.g., in your backend, MCP server, or another component):

<Callout type="note">
  This creates only the UI component. The actual tool execution happens where you've defined it (typically in your API route with server-based runtimes like Vercel AI SDK).
</Callout>

```tsx
import { makeAssistantToolUI, AssistantToolUI } from "@assistant-ui/react";

const SearchResultsUI = makeAssistantToolUI<{
  query: string;
}, {
  results: Array<{
    id: string;
    url: string;
    title: string;
    snippet: string;
  }>;
}>({
  toolName: "webSearch", // Must match the registered tool's name
  render: ({ args, result }) => {
    return (
      <div className="search-results">
        <h3>Search: {args.query}</h3>
        {result.results.map((item) => (
          <div key={item.id}>
            <a href={item.url}>{item.title}</a>
            <p>{item.snippet}</p>
          </div>
        ))}
      </div>
    );
  }
});

// Place the tool component inside AssistantRuntimeProvider
function App() {
  return (
    <AssistantRuntimeProvider runtime={runtime}>
      <SearchResultsUI />
      <Thread />
    </AssistantRuntimeProvider>
  );
}
```

### 4. Advanced: Direct Context Registration

Use `registerModelContextProvider` when you need to configure more than just tools:

```tsx
import { tool, useAssistantRuntime } from "@assistant-ui/react";
import { useEffect, useState } from "react";
import { z } from "zod";

function MyComponent() {
  const runtime = useAssistantRuntime();
  const [isCreativeMode, setIsCreativeMode] = useState(false);
  
  useEffect(() => {
    const calculateTool = tool({
      description: "Perform mathematical calculations",
      parameters: z.object({
        expression: z.string()
      }),
      execute: async ({ expression }) => {
        return eval(expression); // Note: Use proper math parser in production
      }
    });

    // Register tools with model configuration
    return runtime.registerModelContextProvider({
      getModelContext: () => ({
        tools: { calculate: calculateTool },
        callSettings: {
          temperature: isCreativeMode ? 0.9 : 0.2,
          maxTokens: 1000
        },
        priority: 10 // Higher priority overrides other providers
      })
    });
  }, [runtime, isCreativeMode]);
  
  return <div>{/* Your component */}</div>;
}
```

Use this approach when you need:

* Dynamic model parameters (temperature, maxTokens, etc.)
* Priority-based context merging
* Multiple context types in one registration

## Tool Paradigms

### Frontend Tools

Tools that execute in the browser, accessing client-side resources:

```tsx
const screenshotTool = tool({
  description: "Capture a screenshot of the current page",
  parameters: z.object({
    selector: z.string().optional()
  }),
  execute: async ({ selector }) => {
    const element = selector ? document.querySelector(selector) : document.body;
    const screenshot = await captureElement(element);
    return { dataUrl: screenshot };
  }
});

const ScreenshotTool = makeAssistantTool({
  ...screenshotTool,
  toolName: "screenshot"
});
```

### Backend Tools

Tools that trigger server-side operations:

```tsx
// Backend route (AI SDK)
export async function POST(req: Request) {
  const { messages } = await req.json();
  
  const result = streamText({
    model: openai("gpt-4o"),
    messages,
    tools: {
      queryDatabase: {
        description: "Query the application database",
        parameters: z.object({
          query: z.string(),
          table: z.string()
        }),
        execute: async ({ query, table }) => {
          // Server-side database access
          const results = await db.query(query, { table });
          return results;
        }
      }
    }
  });
  
  return result.toDataStreamResponse();
}
```

### Client-Defined Tools with frontendTools

Currently, the Vercel AI SDK adapter implements automatic serialization of client-defined tools. When using this adapter, tools registered via `makeAssistantTool`, `useAssistantTool`, or `registerModelContextProvider` are automatically included in API requests. The `frontendTools` utility helps you use these tools server-side:

```tsx
// Frontend: Define tool with makeAssistantTool
import { makeAssistantTool, tool } from "@assistant-ui/react";

const calculateTool = tool({
  description: "Perform calculations",
  parameters: z.object({
    expression: z.string()
  }),
  execute: async ({ expression }) => {
    return eval(expression); // Note: Use proper math parser in production
  }
});

const CalculateTool = makeAssistantTool({
  ...calculateTool,
  toolName: "calculate"
});

// Backend: Use frontendTools to receive client tools
import { frontendTools } from "@assistant-ui/react-ai-sdk";

export async function POST(req: Request) {
  const { messages, tools } = await req.json();
  
  const result = streamText({
    model: openai("gpt-4o"),
    messages,
    tools: {
      ...frontendTools(tools), // Client-defined tools
      // Additional server-side tools
      queryDatabase: {
        description: "Query the application database",
        parameters: z.object({ query: z.string() }),
        execute: async ({ query }) => {
          return await db.query(query);
        }
      }
    }
  });
  
  return result.toDataStreamResponse();
}
```

<Callout type="note">
  The `frontendTools` utility is currently only available for the Vercel AI SDK integration. Other adapters like LangGraph follow a server-side tool definition model and don't yet implement client tool serialization. Learn more in the [Vercel AI SDK integration guide](/docs/runtimes/ai-sdk/use-chat-hook).
</Callout>

### Human-in-the-Loop Tools

Tools that require human approval or input:

```tsx
import { makeAssistantTool, tool } from "@assistant-ui/react";
import { z } from "zod";

const refundTool = tool({
  description: "Process a customer refund",
  parameters: z.object({
    orderId: z.string(),
    amount: z.number(),
    reason: z.string()
  }),
  execute: async ({ orderId, amount, reason }) => {
    // Wait for human approval
    const approved = await requestHumanApproval({
      action: "refund",
      details: { orderId, amount, reason }
    });
    
    if (!approved) {
      throw new Error("Refund rejected by administrator");
    }
    
    return await processRefund(orderId, amount);
  }
});

const RefundTool = makeAssistantTool({
  ...refundTool,
  toolName: "requestRefund"
});
```

### MCP (Model Context Protocol) Tools

Integration with MCP servers:

```tsx
// Using AI SDK's MCP support
import { createMCPClient } from "ai/mcp";

const mcpClient = createMCPClient({
  servers: {
    github: {
      command: "npx",
      args: ["@modelcontextprotocol/server-github"]
    }
  }
});

// Tools are automatically available through the runtime
const runtime = useChatRuntime({
  api: "/api/chat",
  tools: await mcpClient.getTools()
});
```

## Advanced Patterns

### Tool Composition

Combining multiple tools for complex workflows:

```tsx
const travelPlannerTool = tool({
  description: "Plan a complete trip itinerary",
  parameters: z.object({
    destination: z.string(),
    dates: z.object({
      start: z.string(),
      end: z.string()
    })
  }),
  execute: async ({ destination, dates }) => {
    // Execute multiple operations
    const weather = await getWeatherAPI(destination);
    const hotels = await searchHotelsAPI({ 
      location: destination,
      dates 
    });
    const activities = await findActivitiesAPI({
      location: destination,
      weather: weather.forecast
    });
    
    return {
      weather,
      hotels,
      activities,
      itinerary: generateItinerary({ weather, hotels, activities })
    };
  }
});

const TravelPlannerTool = makeAssistantTool({
  ...travelPlannerTool,
  toolName: "planTrip"
});
```

### Conditional Tool Availability

Tools that appear based on context:

```tsx
function ConditionalTools() {
  const { user } = useAuth();
  const { subscription } = useSubscription();
  
  // Premium features
  useAssistantTool({
    toolName: "advancedAnalysis",
    description: "Perform advanced data analysis",
    parameters: z.object({
      dataset: z.string()
    }),
    execute: async (args) => {
      // Premium analysis logic
    },
    enabled: subscription?.tier === "premium"
  });
  
  // Role-based tools
  useAssistantTool({
    toolName: "adminPanel",
    description: "Access admin controls",
    parameters: z.object({}),
    execute: async () => {
      // Admin actions
    },
    enabled: user?.role === "admin"
  });
}
```

### Tool Error Handling

Robust error handling and recovery:

```tsx
const resilientTool = tool({
  description: "Fetch data with retry logic",
  parameters: z.object({
    endpoint: z.string()
  }),
  execute: async ({ endpoint }, { abortSignal }) => {
    const maxRetries = 3;
    let lastError;
    
    for (let i = 0; i < maxRetries; i++) {
      try {
        const response = await fetch(endpoint, { signal: abortSignal });
        if (!response.ok) throw new Error(`HTTP ${response.status}`);
        return await response.json();
      } catch (error) {
        lastError = error;
        if (abortSignal.aborted) throw error; // Don't retry on abort
        await new Promise(resolve => setTimeout(resolve, 1000 * i));
      }
    }
    
    throw new Error(`Failed after ${maxRetries} attempts: ${lastError.message}`);
  }
});

const ResilientTool = makeAssistantTool({
  ...resilientTool,
  toolName: "fetchWithRetries"
});
```

## Best Practices

1. **Clear Descriptions**: Write descriptive tool descriptions that help the LLM understand when to use each tool
2. **Parameter Validation**: Use Zod schemas to ensure type safety and provide clear parameter descriptions
3. **Error Handling**: Always handle potential errors gracefully with user-friendly messages
4. **Loading States**: Provide visual feedback during tool execution
5. **Security**: Validate permissions and sanitize inputs, especially for destructive operations
6. **Performance**: Use abort signals for cancellable operations and implement timeouts
7. **Testing**: Test tools in isolation and with the full assistant flow

## Tool Execution Context

Tools receive additional context during execution:

```tsx
execute: async (args, context) => {
  // context.abortSignal - AbortSignal for cancellation
  // context.toolCallId - Unique identifier for this invocation
}
```

## Runtime Integration

Each integration handles tools differently:

* **Vercel AI SDK**: Tools defined in API routes with `streamText({ tools: {...} })`. Also supports client-defined tools via `frontendTools`.
* **LangGraph**: Tools defined in your LangGraph graph configuration.
* **Mastra**: Tools defined as typed functions used by agents and workflows.

All integrations support tool UI customization via `makeAssistantToolUI`.


file: ./content/docs/migrations/deprecation-policy.mdx
# Deprecation Policy


        
assistant-ui is committed to providing a stable API, so you can spend your time building amazing things on top of it.

Rarely, we need to deprecate a feature we've already shipped, because it is causing performance, usability, or security issues.
In such cases, we will communicate the intent to unship as soon as possible by marking the feature as `@deprecated` and publishing a notice in the documentation.

Deprecations and breaking changes primarily affect new features released. The longer an API has been in the library, the less likely it is to be deprecated.
For features that have long existed in the library, we will provide a longer deprecation notice period (as described below).

Below is a list of features considered stable and those considered experimental.

## Experimental Features

These features may be removed at any time without notice.

* Anything marked as `unstable_`, `experimental_`, or `internal`
* The `RuntimeCore` API (considered internal)

## Beta Features

A deprecation of these features will undergo a short (\<1) month deprecation notice period.

* TailwindCSS Plugins (e.g. `@assistant-ui/react-ui/tailwindcss`)
* Context API
* Runtime API
* Message types
* Styled UI components
* Primitive Hooks (e.g. useBranchPickerNext)
* Attachment APIs
* shadcn/ui styles

## Stable Features

A deprecation of these features will undergo a long (>3 month) deprecation notice period.

The following features are considered stable:

* Primitives (except for `AttachmentPrimitive`)


file: ./content/docs/migrations/v0-7.mdx
# Migration to v0.7


        
import { Callout } from "fumadocs-ui/components/callout";

This guide serves as a reference for users facing breaking changes during upgrade to v0.7. You do not need to read this guide to upgrade to v0.7.

All breaking changes in v0.7 are renames or removals of existing APIs. Therefore, all breaking changes should cause a Typescript error, so you can simply check for errors after upgrading.

### Component Property Types moved to `Component.Props`

Component property types are now neatly organized under the component itself.

```diff
-import { ThreadPrimitiveMessagesProps } from "@assistant-ui/react";
+import { ThreadPrimitive } from "@assistant-ui/react";

-type Props = ThreadPrimitiveMessagesProps;
+type Props = ThreadPrimitive.Messages.Props;
```

## Context API simplifications

### `useThreadContext`, `useMessageContext`, ... replaced with direct imports of stores

`useAssistantContext`, `useThreadContext`, `useMessageContext` and `useContentPartContext` have been removed in favor of direct exports from `@assistant-ui/react`;

```diff
-const { useThread } = useThreadContext();

+import { useThread } from "@assistant-ui/react";
```

# Assistant Context API simplifications

### `useAssistantActions` replaced with `useAssistantRuntime`

`useAssistantActions` has been removed in favor of `useAssistantRuntime`.

```diff
-const switchToNewThread = useAssistantActions(a => a.switchToNewThread);
+const runtime = useAssistantRuntime();
+runtime.switchToNewThread();
```

### `switchToThread(null)` replaced with `switchToNewThread()`

```diff
-useThreadRuntime().switchToThread(null);
+useThreadRuntime().switchToNewThread();
```

### useSwtichToNewThread() moved to useAssistantRuntime().switchToNewThread()

```diff
-useSwitchToNewThread();
+const runtime = useAssistantRuntime()
+runtime.switchToNewThread(); 
```

### `runtime.subscribe` removed, `subscribeToMainThread` removed

Previously, you needed to subscribe to the runtime to receive updates whenever the main thread changed and resubscribe to the main thread whenever you switched to a new thread. The `runtime.thread` value now always refers to the current main thread, there is no need to subscribe to the runtime anymore.

## ThreadRuntime API simplifications

### `useAppendMessage` moved to `useThreadRuntime().append()`

```diff
-const append = useAppendMessage();
+const threadRuntime = useThreadRuntime();
-append("hello world");
+threadRuntime.append("hello world");
```

### `useThreadActions` replaced with `useThreadRuntime`

`useThreadActions` has been removed in favor of `useThreadRuntime`.

```diff
-const reload = useThreadActions(a => a.reload);
+const threadRuntime = useThreadRuntime();
+threadRuntime.reload();
```

### State values moved to `threadRuntime.getState()`

In order to make it clear that accessing the state only provides a snapshot of the current state and will not cause a re-render on changes, the state values of `useThreadRuntime` have been moved to `threadRuntime.getState()`.

```diff
-const isRunning = useThreadRuntime().isRunning; // anti-pattern, your code will not update on change
+const isRunning = useThread(t => t.isRunning);
```

### `useThreadStore` replaced with `useThreadRuntime().getState()`

`useThreadStore` has been removed in favor of `useThreadRuntime().getState()`.

### `threadRuntime.getBranches()` replaced with `useThreadRuntime().getMessageByIndex(idx).getState().branchNumber/Count`

The branch IDs are an internal implementation detail. The new Message Runtime API provides `branchNumber` and `branchCount` state fields that can be used instead.

### New Message Runtime API replaces several methods from `useThreadRuntime`

A few methods from `useThreadRuntime` have been moved to `useMessageRuntime()`.

* `threadRuntime.switchToBranch()` has been removed in favor of `useThreadRuntime().getMessageByIndex(idx).switchToBranch()`.
* `threadRuntime.addToolResult()` has been removed in favor of `useThreadRuntime().getMessageByIndex(idx).getContentPartByToolCallId(toolCallId).addToolResult()`.
* `threadRuntime.speak()` has been removed in favor of `useThreadRuntime().getMessageByIndex(idx).speak()`.
* `threadRuntime.submitFeedback()` has been removed in favor of `useThreadRuntime().getMessageByIndex(idx).submitFeedback()`.
* `threadRuntime.getEditComposer()` has been removed in favor of `useThreadRuntime().getMessageById(id).getMessageByIndex(idx).composer`.
* `threadRuntime.beginEdit()` has been removed in favor of `useThreadRuntime().getMessageById(id).getMessageByIndex(idx).composer.beginEdit()`.

## Composer Runtime API simplifications

### Methods inside `useComposer` moved to `useComposerRuntime`

`useComposer()` used to provide several methods such as `setText`, `addAttachment`, `send`, `edit`, `cancel`, ...
These methods have been moved to `useComposerRuntime()`.

### `useComposerStore` replaced with `useComposerRuntime().getState()`

`useComposerStore` has been removed in favor of `useComposerRuntime().getState()`.

### `value` `setValue` replaced with `text` `setText`

```diff
-useComposer(c => c.value);
+useComposer(c => c.text);
```

### `focus`, `onFocus` methods removed

These methods have been removed.

## Message Context API simplifications

### Flattened context values `useMessage().message` -> `useMessage()`

`MessageState` is now itself a message, so you no longer need to access the nested `useMessage().message` field.

```diff
-useMessage(m => m.message.content);
+useMessage(m => m.content);
```

### `useMessageStore` replaced with `useMessageRuntime().getState()`

`useMessageStore` has been removed in favor of `useMessageRuntime().getState()`.

## Content Part Context API simplifications

### Flattened context values `useContentPart().part` -> `useContentPart()`

`ContentPartState` is now itself a content part, so you no longer need to access the nested `useContentPart().part` field.

```diff
-useContentPart(c => c.part.type);
+useContentPart(c => c.type);
```

This also applies to tool UI render functions:

```diff
 makeAssistantToolUI({
   ...
-  render: ({ part: { args } }) => <>{args}</>,
+  render: ({ args }) => <>{args}</>,
 });
```

## Attachment Context API simplifications

### Flattened context values `useAttachment().attachment` -> `useAttachment()`

`AttachmentState` is now itself an attachment, so you no longer need to access the nested `useAttachment().attachment` field.

```diff
-useAttachment(a => a.attachment.type);
+useAttachment(a => a.type);
```

## Roundtrips renamed to steps

`AssistantMessage.roundtrips` was renamed to `AssistantMessage.metadata.steps`.

Edge runtime's `maxToolRoundtrips` was replaced with `maxSteps` (which is `maxToolRoundtrips` + 1; if you had `maxToolRoundtrips` at 2, set `maxSteps` to 3).


file: ./content/docs/migrations/v0-8.mdx
# Migration to v0.8


        
## Styled Components moved to @assistant-ui/react-ui

All styled components (Thread, ThreadList, AssistantModal, makeMarkdownText, etc.) have been moved to a new package, `@assistant-ui/react-ui`.

To migrate, use the migration codemod:

```sh
# IMPORTANT: make sure to commit all changes to git / creating a backup before running the codemod
npx assistant-ui upgrade
```

## Vercel AI SDK RSC requires additional setup

Built-in RSC support in assistant-ui has been removed, so an additional setup step is required.
The RSC runtime now requires additional setup to display React Server Components.

```ts
import { RSCDisplay } from "@assistant-ui/react-ai-sdk";

// if you are using the default Thread component
// add RSCDisplay to assistantMessage.components.Text
<Thread assistantMessage={{ components: { Text: RSCDisplay } }} />


// if you are using unstyled primitives, update MyThread.tsx
<MessagePrimitive.Content components={{ Text: RSCDisplay }} />
```

## Migrate away from UIContentPart

For instructions on migrating for Vercel AI SDK RSC, see section above.
This migration guide is for users of `useExternalStoreRuntime`.

### Recommended Approach: Use ToolUI

First, reconsider your approach.

Creating UI components in the `convertMessage` callback is considered an anti-pattern.
The recommended alternative approach is to pass tool-call content parts, and use `makeAssistantToolUI` to map these tool calls to UI components.

This ensures that the data layer is separate and decoupled from the UI layer.

#### Example

Consider the following example, where you are using a UIContentPart to show a loading indicator.

```ts title="bad.ts"
// THIS IS BAD
const convertMessage = (message: MyMessage): ThreadMessageLike => {
  if (message.isLoading) {
    return { content: [{ type: "ui", display:< MyLoader /> }] };
  }
  // ...
};
```

```ts title="good.ts"
const convertMessage = (message: MyMessage): ThreadMessageLike => {
  if (message.isLoading) {
    return { content: [] };
  }
  // ...
};

// use the empty content part to show the loading indicator
<Thread assistantMessage={{ components: { Empty: MyLoader } }} />;
```

(if you are using unstyled primitives, update MyThread.tsx, and pass the component to MessagePrimitive.Content)

#### Example 2

Consider the following example, where you are displaying a custom chart based on data received from an external source.

```ts title="bad.ts"
// THIS IS BAD
const convertMessage = (message: MyMessage): ThreadMessageLike => {
  return { content: [{ type: "ui", display: <MyChart data={message.chartData} /> }] };
};
```

```ts title="good.ts"
const convertMessage = (message: MyMessage): ThreadMessageLike => {
  return {
    content: [
      {
        type: "tool-call",
        toolName: "chart",
        args: message.chartData,
      },
    ],
  };
};

const ChartToolUI = makeAssistantToolUI({
  toolName: "chart",
  render: ({ args }) => <MyChart data={args} />,
});

// use tool UI to display the chart
<Thread tools={[ChartToolUI]} />;
```

(if you are using unstyled primitives, render the `<ChartToolUI />` component anywhere inside your AssistantRuntimeProvider)

### Fallback Approach: Override ContentPartText

However, sometimes you receive UI components from an external source.

The example below assumes that your custom `MyMessage` type has a `display` field.

First, we define a dummy `UI_PLACEHOLDER` content part, which we will replace with the UI component later:

```ts
const UI_PLACEHOLDER = Object.freeze({
  type: "text",
  text: "UI content placeholder",
});
const convertMessage = (message: MyMessage): ThreadMessageLike => ({
  content: [
    // other content parts,
    UI_PLACEHOLDER,
  ],
});
```

Then, we define a custom `TextContentPartComponent`:

```tsx
const MyText: TextContentPartComponent = () => {
  const isUIPlaceholder = useContentPart((p) => p === UI_PLACEHOLDER);

  // this assumes that you have a `display` field on your original message objects before conversion.
  const ui = useMessage((m) =>
    isUIPlaceholder ? getExternalStoreMessage(m).display : undefined,
  );
  if (ui) {
    return ui;
  }

  return <MarkdownText />; // your default text component
};
```

We pass this component to our Thread:

```tsx
<Thread
  assistantMessage={{ components: { Text: MyText } }}
  userMessage={{ components: { Text: MyText } }}
/>
```

(if you are using unstyled primitives, update MyThread.tsx, and pass the component to MessagePrimitive.Content)

Now, the `UI_PLACEHOLDER` content part is replaced with the UI component we defined earlier.


file: ./content/docs/migrations/v0-9.mdx
# Migration to v0.9


        
## Edge Runtime moved to @assistant-ui/react-edge

The edge runtime, as well as the `CoreMessage` type, moved to `@assistant-ui/react-edge`.

The following components and types have been moved to `@assistant-ui/react-edge`:

* Edge Runtime

  * `useEdgeRuntime`
  * `EdgeRuntimeOptions`
  * `EdgeModelAdapter`
  * `EdgeChatAdapter`
  * `EdgeRuntimeRequestOptions`
  * `createEdgeRuntimeAPI`
  * `getEdgeRuntimeResponse`

* Core Types
  * `CoreMessage`
  * `CoreUserMessage`
  * `CoreAssistantMessage`
  * `CoreSystemMessage`
  * `CoreUserContentPart`
  * `CoreAssistantContentPart`
  * `CoreToolCallContentPart`

* Core message converters
  * `fromCoreMessages`
  * `fromCoreMessage`
  * `toCoreMessages`
  * `toCoreMessage`

To migrate, use the migration codemod:

```sh
# IMPORTANT: make sure to commit all changes to git / creating a backup before running the codemod
npx assistant-ui upgrade
```

## Language Model converters and useDangerousInBrowserRuntime moved to @assistant-ui/react-ai-sdk

The following methods have been moved to `@assistant-ui/react-ai-sdk`:

* Language Model converters
  * `toLanguageModelMessages`
  * `toLanguageModelTools`
  * `fromLanguageModelMessages`
  * `fromLanguageModelTools`
* Dangerous in Browser Runtime
  * `useDangerousInBrowserRuntime`

To migrate, use the migration codemod:

```sh
# IMPORTANT: make sure to commit all changes to git / creating a backup before running the codemod
npx assistant-ui upgrade
```

## LangGraph `unstable_allowImageAttachments` removed

The `unstable_allowImageAttachments` option has been removed. Use the `adapters` option instead.

```ts
useLangGraphRuntime({
  adapters: {
    attachments: new SimpleImageAttachmentAdapter(),
  },
});
```

## Markdown `components.by_language` removed

The `components.by_language` option has been removed. Use the `componentsByLanguage` option instead.


file: ./content/docs/runtimes/helicone.mdx
# Helicone


        
Helicone acts as a proxy for your OpenAI API calls, enabling detailed logging and monitoring. To integrate, update your API base URL and add the Helicone-Auth header.

## AI SDK by vercel

1. **Set Environment Variables:**

   * `HELICONE_API_KEY`
   * `OPENAI_API_KEY`

2. **Configure the OpenAI client:**

```ts
import { createOpenAI } from "@ai-sdk/openai";
import { streamText } from "ai";

const openai = createOpenAI({
  baseURL: "https://oai.helicone.ai/v1",
  headers: {
    "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
  },
});

export async function POST(req: Request) {
  const { prompt } = await req.json();
  return streamText({
    model: openai("gpt-4o"),
    prompt,
  });
}
```

## LangChain Integration (Python)

1. **Set Environment Variables:**

   * `HELICONE_API_KEY`
   * `OPENAI_API_KEY`

2. **Configure ChatOpenAI:**

```python
from langchain.chat_models import ChatOpenAI
import os

llm = ChatOpenAI(
    model_name="gpt-3.5-turbo",
    temperature=0,
    openai_api_base="https://oai.helicone.ai/v1",
    openai_api_key=os.environ["OPENAI_API_KEY"],
    openai_api_headers={"Helicone-Auth": f"Bearer {os.environ['HELICONE_API_KEY']}"}
)
```

## Summary

Update your API base URL to `https://oai.helicone.ai/v1` and add the `Helicone-Auth` header with your API key either in your Vercel AI SDK or LangChain configuration.


file: ./content/docs/runtimes/langserve.mdx
# LangChain LangServe


        
## Overview

Integration with a LangServe server via Vercel AI SDK.

## Getting Started

import { Steps, Step } from "fumadocs-ui/components/steps";

<Steps>
  <Step>
    ### Create a Next.JS project

    ```sh
    npx create-next-app@latest my-app
    cd my-app
    ```
  </Step>

  <Step>
    ### Install `@langchain/core`, `ai-sdk` and `@assistant-ui/react`

    ```sh npm2yarn
    npm install @assistant-ui/react @assistant-ui/react-ai-sdk ai @ai-sdk/react @langchain/core
    ```
  </Step>

  <Step>
    ### Setup a backend route under `/api/chat`

    ```tsx twoslash title="@/app/api/chat/route.ts"
    // @errors: 2558 2345
    import { RemoteRunnable } from "@langchain/core/runnables/remote";
    import type { RunnableConfig } from "@langchain/core/runnables";
    import { streamText, LangChainAdapter, type Message } from "ai";

    export const maxDuration = 30;

    export async function POST(req: Request) {
      const { messages } = (await req.json()) as { messages: Message[] };

      // TODO replace with your own langserve URL
      const remoteChain = new RemoteRunnable<
        { messages: Message[] },
        string,
        RunnableConfig
      >({
        url: "<YOUR_LANGSERVE_URL>",
      });

      const stream = await remoteChain.stream({
        messages,
      });

      return LangChainAdapter.toDataStreamResponse(stream);
    }
    ```
  </Step>

  <Step>
    ### Define a `MyRuntimeProvider` component

    ```tsx twoslash include MyRuntimeProvider title="@/app/MyRuntimeProvider.tsx"
    // @filename: /app/MyRuntimeProvider.tsx
    // ---cut---
    "use client";

    import { useChat } from "@ai-sdk/react";
    import { AssistantRuntimeProvider } from "@assistant-ui/react";
    import { useVercelUseChatRuntime } from "@assistant-ui/react-ai-sdk";

    export function MyRuntimeProvider({
      children,
    }: Readonly<{
      children: React.ReactNode;
    }>) {
      const chat = useChat({
        api: "/api/chat",
        unstable_AISDKInterop: true,
      });

      const runtime = useVercelUseChatRuntime(chat);

      return (
        <AssistantRuntimeProvider runtime={runtime}>
          {children}
        </AssistantRuntimeProvider>
      );
    }
    ```
  </Step>

  <Step>
    ### Wrap your app in `MyRuntimeProvider`

    ```tsx twoslash title="@/app/layout.tsx"
    // @include: MyRuntimeProvider
    // @filename: /app/layout.tsx
    // ---cut---
    import type { ReactNode } from "react";
    import { MyRuntimeProvider } from "@/app/MyRuntimeProvider";

    export default function RootLayout({
      children,
    }: Readonly<{
      children: ReactNode;
    }>) {
      return (
        <MyRuntimeProvider>
          <html lang="en">
            <body>{children}</body>
          </html>
        </MyRuntimeProvider>
      );
    }
    ```
  </Step>
</Steps>


file: ./content/docs/runtimes/pick-a-runtime.mdx
# Picking a Runtime


        
import { Card, Cards } from "fumadocs-ui/components/card";
import { Callout } from "fumadocs-ui/components/callout";

Choosing the right runtime is crucial for your assistant-ui implementation. This guide helps you navigate the options based on your specific needs.

## Quick Decision Tree

```mermaid
graph TD
    A[What's your starting point?] --> B{Existing Framework?}
    B -->|Vercel AI SDK| C[Use AI SDK Integration]
    B -->|LangGraph| D[Use LangGraph Runtime]
    B -->|LangServe| E[Use LangServe Runtime]
    B -->|Mastra| F[Use Mastra Runtime]
    B -->|Custom Backend| G{State Management?}
    G -->|Let assistant-ui handle it| H[Use LocalRuntime]
    G -->|I'll manage it myself| I[Use ExternalStoreRuntime]
```

## Core Runtimes

These are the foundational runtimes that power assistant-ui:

<Cards>
  <Card title="`LocalRuntime`" description="assistant-ui manages chat state internally. Simple adapter pattern for any backend." href="/docs/runtimes/custom/local" />

  <Card title="`ExternalStoreRuntime`" description="You control the state. Perfect for Redux, Zustand, or existing state management." href="/docs/runtimes/custom/external-store" />
</Cards>

## Pre-Built Integrations

For popular frameworks, we provide ready-to-use integrations built on top of our core runtimes:

<Cards>
  <Card title="Vercel AI SDK" description="For useChat and useAssistant hooks - streaming with all major providers" href="/docs/runtimes/ai-sdk/use-chat" />

  <Card title="LangGraph" description="For complex agent workflows with LangChain's graph framework" href="/docs/runtimes/langgraph" />

  <Card title="LangServe" description="For LangChain applications deployed with LangServe" href="/docs/runtimes/langserve" />

  <Card title="Mastra" description="For workflow orchestration with Mastra's ecosystem" href="/docs/runtimes/mastra/overview" />
</Cards>

## Understanding Runtime Architecture

### How Pre-Built Integrations Work

The pre-built integrations (AI SDK, LangGraph, etc.) are **not separate runtime types**. They're convenient wrappers built on top of our core runtimes:

* **AI SDK Integration**  Built on `LocalRuntime` with streaming adapter
* **LangGraph Runtime**  Built on `LocalRuntime` with graph execution adapter
* **LangServe Runtime**  Built on `LocalRuntime` with LangServe client adapter
* **Mastra Runtime**  Built on `LocalRuntime` with workflow adapter

This means you get all the benefits of `LocalRuntime` (automatic state management, built-in features) with zero configuration for your specific framework.

### When to Use Pre-Built vs Core Runtimes

**Use a pre-built integration when:**

* You're already using that framework
* You want the fastest possible setup
* The integration covers your needs

**Use a core runtime when:**

* You have a custom backend
* You need features not exposed by the integration
* You want full control over the implementation

<Callout>
  Pre-built integrations can always be replaced with a custom `LocalRuntime` or `ExternalStoreRuntime` implementation if you need more control later.
</Callout>

## Feature Comparison

### Core Runtime Capabilities

| Feature              | `LocalRuntime` | `ExternalStoreRuntime`  |
| -------------------- | -------------- | ----------------------- |
| **State Management** | Automatic      | You control             |
| **Setup Complexity** | Simple         | Moderate                |
| **Message Editing**  | Built-in       | Implement `onEdit`      |
| **Branch Switching** | Built-in       | Implement `setMessages` |
| **Regeneration**     | Built-in       | Implement `onReload`    |
| **Cancellation**     | Built-in       | Implement `onCancel`    |
| **Multi-thread**     | Via adapters   | Via adapters            |

### Available Adapters

| Adapter     | `LocalRuntime` | `ExternalStoreRuntime` |
| ----------- | -------------- | ---------------------- |
| ChatModel   |  Required     |  N/A                  |
| Attachments |               |                       |
| Speech      |               |                       |
| Feedback    |               |                       |
| History     |               |  Use your state       |
| Suggestions |               |  Use your state       |

## Common Implementation Patterns

### Vercel AI SDK with Streaming

```tsx
import { useChatRuntime } from "@assistant-ui/react-ai-sdk";

export function MyAssistant() {
  const runtime = useChatRuntime({
    api: "/api/chat",
  });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      <Thread />
    </AssistantRuntimeProvider>
  );
}
```

### Custom Backend with `LocalRuntime`

```tsx
import { useLocalRuntime } from "@assistant-ui/react";

const runtime = useLocalRuntime({
  async run({ messages, abortSignal }) {
    const response = await fetch("/api/chat", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ messages }),
      signal: abortSignal,
    });
    return response.json();
  },
});
```

### Redux Integration with `ExternalStoreRuntime`

```tsx
import { useExternalStoreRuntime } from "@assistant-ui/react";

const messages = useSelector(selectMessages);
const dispatch = useDispatch();

const runtime = useExternalStoreRuntime({
  messages,
  onNew: async (message) => {
    dispatch(addUserMessage(message));
    const response = await api.chat(message);
    dispatch(addAssistantMessage(response));
  },
  setMessages: (messages) => dispatch(setMessages(messages)),
  onEdit: async (message) => dispatch(editMessage(message)),
  onReload: async (parentId) => dispatch(reloadMessage(parentId)),
});
```

## Examples

Explore our implementation examples:

* **[AI SDK Example](https://github.com/assistant-ui/assistant-ui/tree/main/examples/with-ai-sdk)** - Vercel AI SDK with `useChatRuntime`
* **[External Store Example](https://github.com/assistant-ui/assistant-ui/tree/main/examples/with-external-store)** - `ExternalStoreRuntime` with custom state
* **[Assistant Cloud Example](https://github.com/assistant-ui/assistant-ui/tree/main/examples/with-cloud)** - Multi-thread with cloud persistence
* **[LangGraph Example](https://github.com/assistant-ui/assistant-ui/tree/main/examples/with-langgraph)** - Agent workflows
* **[OpenAI Assistants Example](https://github.com/assistant-ui/assistant-ui/tree/main/examples/with-openai-assistants)** - OpenAI Assistants API

## Common Pitfalls to Avoid

### LocalRuntime Pitfalls

* **Forgetting the adapter**: `LocalRuntime` requires a `ChatModelAdapter` - it won't work without one
* **Not handling errors**: Always handle API errors in your adapter's `run` function
* **Missing abort signal**: Pass `abortSignal` to your fetch calls for proper cancellation

### ExternalStoreRuntime Pitfalls

* **Mutating state**: Always create new arrays/objects when updating messages
* **Missing handlers**: Each UI feature requires its corresponding handler (e.g., no edit button without `onEdit`)
* **Forgetting optimistic updates**: Set `isRunning` to `true` for loading states

### General Pitfalls

* **Wrong integration level**: Don't use `LocalRuntime` if you already have Vercel AI SDK - use the AI SDK integration instead
* **Over-engineering**: Start with pre-built integrations before building custom solutions
* **Ignoring TypeScript**: The types will guide you to the correct implementation

## Next Steps

1. **Choose your runtime** based on the decision tree above
2. **Follow the specific guide**:
   * [AI SDK Integration](/docs/runtimes/ai-sdk/use-chat)
   * [`LocalRuntime` Guide](/docs/runtimes/custom/local)
   * [`ExternalStoreRuntime` Guide](/docs/runtimes/custom/external-store)
   * [LangGraph Integration](/docs/runtimes/langgraph)
3. **Start with an example** from our [examples repository](https://github.com/assistant-ui/assistant-ui/tree/main/examples)
4. **Add features progressively** using adapters
5. **Consider Assistant Cloud** for production persistence

<Callout type="info">
  Need help? Join our [Discord community](https://discord.gg/assistant-ui) or check the [GitHub](https://github.com/assistant-ui/assistant-ui).
</Callout>


file: ./content/docs/ui/AssistantModal.mdx
# AssistantModal


        
import { Steps, Step } from "fumadocs-ui/components/steps";
import { AssistantModalSample } from "../../../components/samples/assistant-modal-sample";

## Overview

A chat bubble shown in the bottom right corner of the screen. Useful for support or Q\&A use cases.

<AssistantModalSample />

## Getting Started

<Steps>
  <Step>
    ### Add `assistant-modal`

    ```sh
    npx shadcn@latest add "https://r.assistant-ui.com/assistant-modal"
    ```

    This adds `/components/assistant-ui/assistant-modal.tsx` to your project, which you can adjust as needed.
  </Step>

  <Step>
    ### Use in your application

    ```tsx title="/app/page.tsx" {1,6}
    import { AssistantModal } from "@/components/assistant-ui/assistant-modal";

    export default function Home() {
      return (
        <div className="h-full">
          <AssistantModal />
        </div>
      );
    }
    ```
  </Step>
</Steps>


file: ./content/docs/ui/AssistantSidebar.mdx
# AssistantSidebar


        
import { Steps, Step } from "fumadocs-ui/components/steps";

## Overview

A chat sidebar show on the right side of the screen. Useful for co-pilot use cases.

## Getting Started

<Steps>
  <Step>
    ### Add `assistant-sidebar`

    ```sh
    npx shadcn@latest add "https://r.assistant-ui.com/assistant-sidebar"
    ```

    This adds `/components/assistant-ui/assistant-sidebar.tsx` to your project, which you can adjust as needed.
  </Step>

  <Step>
    ### Use in your application

    ```tsx title="/app/page.tsx" {1,6}
    import { AssistantSidebar } from "@/components/assistant-ui/assistant-sidebar";

    export default function Home() {
      return (
        <div className="h-full">
          <AssistantSidebar>{/* your app */}</AssistantSidebar>
        </div>
      );
    }
    ```
  </Step>
</Steps>


file: ./content/docs/ui/Attachment.mdx
# Attachment


        
import { Steps, Step } from "fumadocs-ui/components/steps";
import { AttachmentSample } from "../../../components/samples/attachment-sample";
import { Callout } from "fumadocs-ui/components/callout";

## Overview

The Attachment components let the user attach files and view the attachments.

<AttachmentSample />

<Callout type="info">
  **Note:** These components provide the UI for attachments, but you also need to configure attachment adapters in your runtime to handle file uploads and processing. See the [Attachments Guide](/docs/guides/Attachments) for complete setup instructions.
</Callout>

## Getting Started

<Steps>
  <Step>
    ### Add `attachment`

    ```sh
    npx shadcn@latest add "https://r.assistant-ui.com/attachment"
    ```

    This adds a `/components/assistant-ui/attachment.tsx` file to your project, which you can adjust as needed.
  </Step>

  <Step>
    ### Use in your application

    ```tsx title="/components/assistant-ui/thread.tsx" {1-4,9-10}
    import {
      ComposerAttachments,
      ComposerAddAttachment,
    } from "@/components/assistant-ui/attachment";

    const Composer: FC = () => {
      return (
        <ComposerPrimitive.Root className="...">
          <ComposerAttachments />
          <ComposerAddAttachment />

          <ComposerPrimitive.Input
            autoFocus
            placeholder="Write a message..."
            rows={1}
            className="..."
          />
          <ComposerAction />
        </ComposerPrimitive.Root>
      );
    };
    ```

    ```tsx title="/components/assistant-ui/thread.tsx" {1,8}
    import { UserMessageAttachments } from "@/components/assistant-ui/attachment";

    const UserMessage: FC = () => {
      return (
        <MessagePrimitive.Root className="...">
          <UserActionBar />

          <UserMessageAttachments />

          <div className="...">
            <MessagePrimitive.Content />
          </div>

          <BranchPicker className="..." />
        </MessagePrimitive.Root>
      );
    };
    ```
  </Step>
</Steps>


file: ./content/docs/ui/Markdown.mdx
# Markdown


        
Allow the assistant to display rich text using markdown.

import { Step, Steps } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";

<Callout>
  Markdown support is already included by default in the `Thread` component.
</Callout>

## Enabling markdown support

<Steps>
  <Step>
    ### Add `markdown-text`

    ```tsx
    npx shadcn@latest add "https://r.assistant-ui.com/markdown-text"
    ```

    This adds a `/components/assistant-ui/markdown-text.tsx` file to your project, which you can adjust as needed.
  </Step>

  <Step>
    ### Use it in your application

    Pass the `MarkdownText` component to the `MessagePrimitive.Content` component

    ```tsx twoslash title="/components/assistant-ui/thread.tsx" {1,11}
    // @filename: /components/assistant-ui/markdown-text.tsx
    import { FC } from "react";
    export const MarkdownText: FC = () => null;

    // @filename: ./thread.tsx
    import { FC } from "react";
    import { MessagePrimitive } from "@assistant-ui/react";
    import { Avatar, AvatarFallback } from "@/components/ui/avatar";

    const AssistantActionBar: FC = () => null;
    const BranchPicker: FC<{ className?: string }> = () => null;

    // ---cut---
    import { MarkdownText } from "@/components/assistant-ui/markdown-text";

    const AssistantMessage: FC = () => {
      return (
        <MessagePrimitive.Root className="...">
          <div className="...">
            <MessagePrimitive.Content components={{ Text: MarkdownText }} />
          </div>
          <AssistantActionBar />

          <BranchPicker className="..." />
        </MessagePrimitive.Root>
      );
    };
    ```
  </Step>
</Steps>

## Syntax highlighting

Syntax Highlighting is not included by default, see [Syntax Highlighting](/docs/ui/SyntaxHighlighting) to learn how to add it.


file: ./content/docs/ui/Mermaid.mdx
# Mermaid Diagrams


        
import { Callout } from "fumadocs-ui/components/callout";
import { Step, Steps } from "fumadocs-ui/components/steps";

Render Mermaid diagrams in chat messages with the `mermaid-diagram` component.

<Steps>
  <Step>
    ### Add `mermaid-diagram` component

    ```bash
    npx shadcn@latest add "https://r.assistant-ui.com/mermaid-diagram"
    ```

    This will install the required dependencies and add the component to your project.
  </Step>

  <Step>
    ### Add it to `componentsByLanguage` in `markdown-text.tsx`

    ```tsx title="/components/assistant-ui/markdown-text.tsx"
    import { MermaidDiagram } from "@/components/assistant-ui/mermaid-diagram"; // [!code ++]

    const MarkdownTextImpl = () => {
      return (
        <MarkdownTextPrimitive
          remarkPlugins={[remarkGfm]}
          className="aui-md"
          components={defaultComponents}
          componentsByLanguage={{               // [!code ++]
            mermaid: {                          // [!code ++]
              SyntaxHighlighter: MermaidDiagram // [!code ++]
            },                                  // [!code ++]
          }}                                    // [!code ++]
        />
      );
    };

    export const MarkdownText = memo(MarkdownTextImpl);
    ```
  </Step>
</Steps>

## Configuration

Configure mermaid options in `mermaid-diagram.tsx`:

```tsx title="/components/assistant-ui/mermaid-diagram.tsx"
mermaid.initialize({ theme: "default" });
```

## Streaming Performance

The `MermaidDiagram` component is optimized for streaming scenarios:

* **Smart completion detection**: Only renders when the specific code block is complete
* **Zero failed renders**: Avoids parsing incomplete diagram code during streaming

## Supported Diagram Types

Mermaid supports various diagram types including:

* Flowcharts and decision trees
* Sequence diagrams
* Gantt charts
* Class diagrams
* State diagrams
* Git graphs
* User journey maps
* Entity relationship diagrams

See the [Mermaid documentation](https://mermaid.js.org/) for complete syntax reference.


file: ./content/docs/ui/Scrollbar.mdx
# Custom Scrollbar


        
If you want to show a custom scrollbar UI of the Thread.Viewport in place of the system default, you can integrate `@radix-ui/react-scroll-area`.
An example implementation of this is [shadcn/ui's Scroll Area](https://ui.shadcn.com/docs/components/scroll-area).

## Add shadcn Scroll Area

```sh
npx shadcn@latest add scroll-area
```

### @radix-ui/react-scroll-area v1.2.0 release candidate required

The v1.2.0-rc.x release candidate can be installed via

```sh
pnpm add @radix-ui/react-scroll-area@next
```

## Additional Styles

The Radix UI Viewport component adds an intermediate `<div data-radix-scroll-area-content>` element.
Add the following CSS to your `globals.css`:

```css title="@/app/globals.css"
.thread-viewport > [data-radix-scroll-area-content] {
  @apply flex flex-col items-center self-stretch bg-inherit;
}
```

## Integration

* Wrap `Thread.Root` with `<ScrollAreaPrimitive.Root asChild>`
* Wrap `Thread.Viewport` with `<ScrollAreaPrimitive.Viewport className="thread-viewport" asChild>`
* Add shadcn's `<ScrollBar />` to `Thread.Root`

The resulting MyThread component should look like this:

```tsx {1-2,6,8,12-13,15}
import * as ScrollAreaPrimitive from "@radix-ui/react-scroll-area";
import { ScrollBar } from "@/components/ui/scroll-area";

const MyThread: FC = () => {
  return (
    <ScrollAreaPrimitive.Root asChild>
      <ThreadPrimitive.Root className="...">
        <ScrollAreaPrimitive.Viewport className="thread-viewport" asChild>
          <ThreadPrimitive.Viewport className="...">
            ...
          </ThreadPrimitive.Viewport>
        </ScrollAreaPrimitive.Viewport>
        <ScrollBar />
      </ThreadPrimitive.Root>
    </ScrollAreaPrimitive.Root>
  );
};
```


file: ./content/docs/ui/SyntaxHighlighting.mdx
# Syntax Highlighting


        
import { Steps, Step } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";
import { TypeTable } from "fumadocs-ui/components/type-table";

Syntax highlighting for code blocks in markdown.

<Callout type="warn">Syntax highlighting is not enabled in markdown by default.</Callout>

<Callout type="info">
  `assistant-ui` provides two options for syntax highlighting:

  * **react-shiki** (recommended for performance & dynamic language support)
  * **react-syntax-highlighter** (legacy - Prism or Highlight.js based)
</Callout>

***

## react-shiki

<Steps>
  <Step>
    #### Add `shiki-highlighter`

    ```bash
    npx shadcn@latest add "https://r.assistant-ui.com/shiki-highlighter"
    ```

    This adds a `/components/assistant-ui/shiki-highlighter.tsx` file to your project and
    installs the `react-shiki` dependency. The highlighter can be customized by editing
    the config in the `shiki-highlighter.tsx` file.
  </Step>

  <Step>
    #### Add it to `defaultComponents` in `markdown-text.tsx`

    ```tsx title="/components/assistant-ui/markdown-text.tsx"
    import { SyntaxHighlighter } from "./shiki-highlighter";

    export const defaultComponents = memoizeMarkdownComponents({
      SyntaxHighlighter: SyntaxHighlighter, // [!code ++]
      h1: /* ... */,
      // ...other elements...
    });
    ```
  </Step>
</Steps>

### Options

<TypeTable
  type={Object.fromEntries(
  Object.entries({
    theme: {
      description:
        "Shiki built-in or custom textmate themes. Accepts a single theme or an object of themes mapped to theme mode strings.",
      type: "Theme | Themes",
      typeDescriptionLink:
        "https://github.com/AVGVSTVS96/react-shiki/blob/694433ef697c9791b3816cf94d12d571e8abbb3a/package/src/types.ts#L51",
      default: "github-dark",
      required: true,
    },
    language: {
      description:
        "Shiki built-in or custom textmate grammar object for highlighting",
      type: "Language (string | object)",
      typeDescriptionLink:
        "https://github.com/AVGVSTVS96/react-shiki/blob/694433ef697c9791b3816cf94d12d571e8abbb3a/package/src/types.ts#L24",
      default: "text",
      required: true,
    },
    as: {
      description: "The code block container element type",
      type: "React.ElementType",
      default: "pre",
    },
    className: {
      description: "Custom CSS classes for the code block container element",
      type: "string",
      default: "",
    },
    style: {
      description: "Inline styles for the code block container element",
      type: "React.CSSProperties",
      default: undefined,
    },
    delay: {
      description:
        "Delay in milliseconds between consecutive highlights, useful for streamed code responses.",
      type: "number",
      default: 0,
    },
    customLanguages: {
      description: "Custom languages to preload for highlighting",
      type: "Language[]",
      typeDescriptionLink:
        "https://github.com/AVGVSTVS96/react-shiki/blob/694433ef697c9791b3816cf94d12d571e8abbb3a/package/src/types.ts#L24",
      default: "",
    },
    codeToHastOptions: {
      description: "All other options supported by Shiki's `codeToHast`",
      type: "CodeToHastOptions",
      typeDescriptionLink:
        "https://github.com/shikijs/shiki/blob/main/packages/types/src/options.ts#L121",
      default: "{}",
      required: true,
    },
    // This reverts the order of the type table, fumadocs reversed the order on 4/22/25 in:
    // https://github.com/fuma-nama/fumadocs/commit/3a5595aa65acfa5c20be2377d09c03fbb1de72a6
  }).reverse(),
)}
/>

### Bundle Optimization

By default, `react-shiki` includes the full Shiki bundle, which contains all supported languages and themes.

To reduce bundle size, you can use the web bundle by changing the import to `react-shiki/web`, to include a smaller bundle of web related languages:

```tsx title="/components/assistant-ui/shiki-highlighter.tsx"
import ShikiHighlighter, { type ShikiHighlighterProps } from "react-shiki/web";
```

#### Custom Bundles

For strict bundle size control, `react-shiki` also supports custom bundles created using `createHighlighterCore` from `react-shiki/core` (re-exported from Shiki):

```tsx title="/components/assistant-ui/shiki-highlighter.tsx" {3-9}
import { createHighlighterCore, createOnigurumaEngine } from "react-shiki/core"; // [!code ++]

// Create the highlighter
// Use dynamic imports to load languages and themes on client on demand
const customHighlighter = await createHighlighterCore({
  themes: [import("@shikijs/themes/nord")],
  langs: [
    import("@shikijs/langs/javascript"),
    import("@shikijs/langs/typescript"),
  ],
  engine: createOnigurumaEngine(import("shiki/wasm")), 
});

// Then pass it to the highlighter prop
<SyntaxHighlighter
  {...props}
  language={language}
  theme={theme}
  highlighter={customHighlighter} // [!code ++]
/>;
```

<Callout type="info">
  For more information, see [react-shiki - bundle options](https://github.com/avgvstvs96/react-shiki#bundle-options).
</Callout>

### Dual/multi theme support

To use multiple theme modes, pass an object with your multi-theme configuration to the `theme` prop in the `ShikiHighlighter` component:

```tsx title="/components/assistant-ui/shiki-highlighter.tsx"
<ShikiHighlighter
  /* ... */
  theme={{
    light: "github-light",
    dark: "github-dark",
  }}
  /* ... */
>
```

To make themes responsive to your site's theme mode, add one of the following CSS snippets to your project:

```css title="shiki.css"
/* for class based dark mode */
html.dark .shiki,
html.dark .shiki span {
  color: var(--shiki-dark) !important;
  background-color: var(--shiki-dark-bg) !important;
  /* Optional, if you also want font styles */
  font-style: var(--shiki-dark-font-style) !important;
  font-weight: var(--shiki-dark-font-weight) !important;
  text-decoration: var(--shiki-dark-text-decoration) !important;
}

/* for query based dark mode */
@media (prefers-color-scheme: dark) {
  .shiki,
  .shiki span {
    color: var(--shiki-dark) !important;
    background-color: var(--shiki-dark-bg) !important;
    /* Optional, if you also want font styles */
    font-style: var(--shiki-dark-font-style) !important;
    font-weight: var(--shiki-dark-font-weight) !important;
    text-decoration: var(--shiki-dark-text-decoration) !important;
  }
}
```

For more information, see [Shiki's documentation on dual and multi themes](https://shiki.style/guide/dual-themes).

***

## react-syntax-highlighter

<Callout type="warn">
  This option may be removed in a future release. Consider using
  [react-shiki](#react-shiki) instead.
</Callout>

<Steps>
  <Step>
    #### Add `syntax-highlighter`

    ```bash
    npx shadcn@latest add "https://r.assistant-ui.com/syntax-highlighter"
    ```

    Adds a `/components/assistant-ui/syntax-highlighter.tsx` file to your project and installs the `react-syntax-highlighter` dependency.
  </Step>

  <Step>
    #### Add it to `defaultComponents` in `markdown-text.tsx`

    ```tsx title="/components/assistant-ui/markdown-text.tsx"
    import { SyntaxHighlighter } from "./syntax-highlighter";

    export const defaultComponents = memoizeMarkdownComponents({
      SyntaxHighlighter: SyntaxHighlighter, // [!code ++]
      h1: /* ... */,
      // ...other elements...
    });
    ```
  </Step>
</Steps>

### Options

Supports all options from [`react-syntax-highlighter`](https://github.com/react-syntax-highlighter/react-syntax-highlighter#props).

### Bundle Optimization

By default, the syntax highlighter uses a light build that only includes languages you register. To include all languages:

```tsx title="/components/assistant-ui/syntax-highlighter.tsx"
import { makePrismAsyncSyntaxHighlighter } from "@assistant-ui/react-syntax-highlighter/full";
```


file: ./content/docs/ui/Thread.mdx
# Thread


        
import { Steps, Step } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";
import { ThreadSample } from "../../../components/samples/thread-sample";

## Overview

The raw message list and message composer UI.

<ThreadSample />

## Getting Started

<Steps>
  <Step>
    ### Add `thread`

    ```sh
    npx shadcn@latest add "https://r.assistant-ui.com/thread"
    ```

    This adds a `/components/assistant-ui/thread.tsx` file to your project, which you can adjust as needed.
  </Step>

  <Step>
    ### Use in your application

    ```tsx title="/app/page.tsx" {1,6}
    import { Thread } from "@/components/assistant-ui/thread";

    export default function Home() {
      return (
        <div className="h-full">
          <Thread />
        </div>
      );
    }
    ```
  </Step>
</Steps>


file: ./content/docs/ui/ThreadList.mdx
# ThreadList


        
import { Steps, Step } from "fumadocs-ui/components/steps";
import { ThreadListSample } from "../../../components/samples/threadlist-sample";

## Overview

The ThreadList component lets the user switch between threads.

<ThreadListSample />

## Getting Started

<Steps>
  <Step>
    ### Add `thread-list`

    ```sh
    npx shadcn@latest add "https://r.assistant-ui.com/thread-list"
    ```

    This adds a `/components/assistant-ui/thread-list.tsx` file to your project, which you can adjust as needed.
  </Step>

  <Step>
    ### Use in your application

    ```tsx title="/app/page.tsx" {1,5-6}
    import { Thread } from "@/components/assistant-ui/thread";
    import { ThreadList } from "@/components/assistant-ui/thread-list";

    export default function Home() {
      return (
        <div className="grid h-full grid-cols-[200px_1fr]">
          <ThreadList />
          <Thread />
        </div>
      );
    }
    ```
  </Step>
</Steps>


file: ./content/docs/ui/ToolFallback.mdx
# ToolFallback


        
import { Steps, Step } from "fumadocs-ui/components/steps";

## Overview

The ToolFallback component displays a default ToolUI for tools that do not have a dedicated ToolUI.

## Getting Started

<Steps>
  <Step>
    ### Add `tool-fallback`

    ```sh
    npx shadcn@latest add "https://r.assistant-ui.com/tool-fallback"
    ```

    This adds a `/components/assistant-ui/tool-fallback.tsx` file to your project, which you can adjust as needed.
  </Step>

  <Step>
    ### Use it in your application

    Pass the `ToolFallback` component to the `MessagePrimitive.Content` component

    ```tsx twoslash title="/components/assistant-ui/thread.tsx" {1,11}
    // @filename: /components/assistant-ui/tool-fallback.tsx
    import { FC } from "react";
    export const ToolFallback: FC = () => null;

    // @filename: ./thread.tsx
    import { FC } from "react";
    import { MessagePrimitive } from "@assistant-ui/react";
    import { Avatar, AvatarFallback } from "@/components/ui/avatar";

    const AssistantActionBar: FC = () => null;
    const BranchPicker: FC<{ className?: string }> = () => null;

    // ---cut---
    import { ToolFallback } from "@/components/assistant-ui/tool-fallback";

    const AssistantMessage: FC = () => {
      return (
        <MessagePrimitive.Root className="...">
          <div className="...">
            <MessagePrimitive.Content
              components={{ tools: { Fallback: ToolFallback } }}
            />
          </div>
          <AssistantActionBar />

          <BranchPicker className="..." />
        </MessagePrimitive.Root>
      );
    };
    ```
  </Step>
</Steps>


file: ./content/docs/api-reference/context-providers/AssistantRuntimeProvider.mdx
# <AssistantRuntimeProvider />


        
import { ParametersTable } from "@/components/docs";
import { AssistantRuntimeProvider } from "@/generated/typeDocs";

The `AssistantRuntimeProvider` provides data and APIs used by assistant-ui components.

Almost all components in assistant-ui require an `AssistantRuntimeProvider` around them to function properly.

You must either wrap your app in an `AssistantRuntimeProvider` or pass a `runtime` to the `<Thread />` component instead.

```tsx {1, 8, 10}
import { AssistantRuntimeProvider } from "@assistant-ui/react";

const MyApp = () => {
  const runtime = useChatRuntime({ api: "/api/chat" });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {/* your app */}
    </AssistantRuntimeProvider>
  );
};
```

#### Properties

<ParametersTable {...AssistantRuntimeProvider} />


file: ./content/docs/api-reference/context-providers/TextContentPartProvider.mdx
# <TextContentPartProvider />


        
import { ParametersTable } from "@/components/docs";
import { AssistantRuntimeProvider } from "@/generated/typeDocs";

The `TextContentPartProvider` provides data and APIs for `TextContentPart` components.

This is useful if you want to reuse the same `Text` component outside of a message text, e.g. with the `@assistant-ui/react-markdown` package.

```tsx {1, 8, 10}
import { AssistantRuntimeProvider } from "@assistant-ui/react";

const MyApp = () => {
  return (
    <TextContentPartProvider text={"Hello!"}>
      <MyMarkdownText />
    </AssistantRuntimeProvider>
  );
};
```

#### Properties

<ParametersTable {...AssistantRuntimeProvider} />


file: ./content/docs/api-reference/integrations/react-hook-form.mdx
# @assistant-ui/react-hook-form


        
A React Hook Form integration for @assistant-ui.

import { ParametersTable } from "@/components/docs";

## API Reference

### `useAssistantForm`

Drop-in replacement hook for `useForm` that adds support for `@assistant-ui/react`.

```diff
- import { useForm } from "react-hook-form";
+ import { useAssistantForm } from "@assistant-ui/react-hook-form";

- useForm({
+ useAssistantForm({
    ...
  });
```

#### Properties

<ParametersTable
  type="UseAssistantFormProps"
  parameters={[
  {
    name: "assistant",
    type: "object",
    optional: true,
    description: "Configuration for useAssistantForm",
    children: [
      {
        parameters: [
          {
            name: "tools",
            type: "object",
            description: "Tools configuration for useAssistantForm",
            children: [
              {
                parameters: [
                  {
                    name: "set_form_field",
                    type: "object",
                    description: "Configuration for the set_form_field tool",
                    children: [
                      {
                        parameters: [
                          {
                            name: "render",
                            type: "ToolCallContentPartComponent<{ name: string; value: string; }, {}>",
                            description:
                              "The component to render when set_form_field is called.",
                          },
                        ],
                      },
                    ],
                  },
                  {
                    name: "submit_form",
                    type: "object",
                    description: "Configuration for the submit_form tool",
                    children: [
                      {
                        parameters: [
                          {
                            name: "render",
                            type: "ToolCallContentPartComponent<{}, {}>",
                            description:
                              "The component to render when submit_form is called.",
                          },
                        ],
                      },
                    ],
                  },
                ],
              },
            ],
          },
        ],
      },
    ],
  },
]}
/>

### `formTools`

The set of tools to use with `useAssistantForm`, useful for runtimes that do not support client-side tool definitions (i.e. Vercel AI SDK).

```tsx {1, 5-7}
import { formTools } from "@assistant-ui/react-hook-form";

const result = streamText({
  ...
  tools: {
    ...formTools,
  }
});
```


file: ./content/docs/api-reference/integrations/vercel-ai-sdk.mdx
# @assistant-ui/react-ai-sdk


        
Vercel AI SDK integration for assistant-ui.

import { ParametersTable } from "@/components/docs";

## API Reference

### `useVercelUseChatRuntime`

Convert Vercel AI SDK chat helpers into a `AssistantRuntime`.

```tsx
import { useVercelUseChatRuntime } from "@assistant-ui/react-ai-sdk";

const MyRuntimeProvider = ({ children }: { children: React.ReactNode }) => {
  const chat = useChat();
  const runtime = useVercelUseChatRuntime(chat);

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
};
```

<ParametersTable
  parameters={[
  {
    name: "chat",
    type: "ReturnType<typeof useChat>",
    description: "The UseChatHelpers from @ai-sdk/react.",
  },
]}
/>

### `useVercelUseAssistantRuntime`

Convert Vercel AI SDK assistant helpers into a `AssistantRuntime`.

```tsx
import { useVercelUseAssistantRuntime } from "@assistant-ui/react-ai-sdk";

const MyRuntimeProvider = ({ children }: { children: React.ReactNode }) => {
  const assistant = useAssistant();
  const runtime = useVercelUseAssistantRuntime(assistant);

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
};
```

<ParametersTable
  parameters={[
  {
    name: "assistant",
    type: "ReturnType<typeof useAssistant>",
    description: "The UseAssistantHelpers from @ai-sdk/react.",
  },
]}
/>

### `useVercelRSCRuntime`

Convert Vercel RSC runtime into a `AssistantRuntime`.

```tsx
import { useVercelRSCRuntime } from "@assistant-ui/react-ai-sdk";

const MyRuntimeProvider = ({ children }: { children: React.ReactNode }) => {
  const [messages, setMessages] = useUIState<typeof AI>();

  const onNew = async (m: AppendMessage) => {
    if (m.content[0]?.type !== "text")
      throw new Error("Only text messages are supported");

    const input = m.content[0].text;
    setMessages((currentConversation) => [
      ...currentConversation,
      { id: nanoid(), role: "user", display: input },
    ]);

    const message = await continueConversation(input);

    setMessages((currentConversation) => [...currentConversation, message]);
  };

  const runtime = useVercelRSCRuntime({ messages, onNew });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
};
```

<ParametersTable
  parameters={[
  {
    name: "adapter",
    type: "VercelRSCAdapter<TMessage>",
    description: "The Vercel RSC adapter to use.",
    children: [
      {
        type: "VercelRSCAdapter<TMessage>",
        parameters: [
          {
            name: "messages",
            type: "readonly ThreadMessage[]",
            description: "The messages in the thread.",
          },
          {
            name: "onNew",
            type: "(message: AppendMessage) => Promise<void>",
            description: "A function to append a message to the thread.",
          },
          {
            name: "onEdit",
            type: "(message: AppendMessage) => Promise<void>",
            description: "A function to edit a message.",
          },
          {
            name: "onReload",
            type: "(parentId: string | null) => Promise<void>",
            description: "A function to reload a message.",
          },
          {
            name: "convertMessage",
            type: "(message: TMessage) => VercelRSCMessage",
            description:
              "A function to convert messages to the VercelRSCMessage format. Only required if your message objects are not already compatible with Vercel RSC.",
          },
        ],
      },
    ],
  },
]}
/>


file: ./content/docs/api-reference/primitives/ActionBar.mdx
# ActionBarPrimitive


        
Buttons to interact with the message.

import { ParametersTable, DataAttributesTable } from "@/components/docs";
import { Code } from "@radix-ui/themes";

## Anatomy

```tsx
import { ActionBarPrimitive } from "@assistant-ui/react";

const UserMessageBar = () => (
  <ActionBarPrimitive.Root>
    <ActionBarPrimitive.Edit />
    <ActionBarPrimitive.Copy />
  </ActionBarPrimitive.Root>
);

const AssistantMessageBar = () => (
  <ActionBarPrimitive.Root>
    <ActionBarPrimitive.Reload />
    <ActionBarPrimitive.Copy />
  </ActionBarPrimitive.Root>
);
```

## API Reference

### Container

Containts all parts of the action bar.

This primitive renders a `<div>` element unless `asChild` is set.

<ParametersTable
  type="ActionBarPrimitiveRootProps"
  parameters={[
  {
    name: "asChild",
  },
  {
    name: "hideWhenRunning",
    type: "boolean",
    default: "false",
    description: (
      <span>
        Do not render the ActionBar when the thread is in running state.
      </span>
    ),
  },
  {
    name: "autohide",
    type: '"always" | "not-last" | "never"',
    default: '"never"',
    description: (
      <span>
        Do not render the ActionBar unless the mouse is hovering over the
        message.
        <br />
        <br />
        <Code>"always"</Code>: always autohide.
        <br />
        <Code>"not-last"</Code>; only autohide if the message is not the last
        one in the thread.
      </span>
    ),
  },
  {
    name: "autohideFloat",
    type: '"always" | "single-branch" | "never"',
    default: '"never"',
    description: (
      <span>
        Float the ActionBar during autohide.
        <br />
        <br />
        <Code>"always"</Code>: always float during autohide.
        <br />
        <Code>"single-branch"</Code>: only float if the message is the only
        one in the thread.
        <br />
        <br />
        Note: this only sets `data-floating` on the ActionBar. You need to set
        the appropriate styles on the ActionBar to make it float.
      </span>
    ),
  },
]}
/>

<DataAttributesTable
  data={[
  {
    attribute: "[data-floating]",
    values: "Present when floating",
  },
]}
/>

### Edit

Enables edit mode on user message.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ActionBarPrimitiveEditProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### Reload

Regenerates the assistant message.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ActionBarPrimitiveReloadProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

{" "}

### Copy

Copies the message to the clipboard.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ActionBarPrimitiveCopyProps"
  parameters={[
  {
    name: "asChild",
  },
  {
    name: "copiedDuration",
    type: "number",
    description:
      "The duration in milliseconds to change the message status to 'copied'.",
    default: "3000",
  },
]}
/>

<DataAttributesTable
  data={[
  {
    attribute: "[data-copied]",
    values: "Present when the message was recently copied.",
  },
]}
/>

#### Copied state

Show a different icon for a few seconds after the message is copied.

```tsx
<ActionBarPrimitive.Copy>
  <MessagePrimitive.If copied={false}>
    <CopyIcon />
  </MessagePrimitive.If>
  <MessagePrimitive.If copied>
    <CopySuccessIcon />
  </MessagePrimitive.If>
</ActionBarPrimitive.Copy>
```

or using the `data-copied` attribute:

```tsx
<ActionBarPrimitive.Copy className="group">
  <CopyIcon className="group-data-[copied]:hidden" />
  <CheckIcon className="hidden group-data-[copied]:block" />
</ActionBarPrimitive.Copy>
```

### Speak

Plays the message text as speech.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ActionBarPrimitiveSpeakProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### StopSpeaking

Stops the message text from being played as speech.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ActionBarPrimitiveStopSpeakingProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### Feedback Positive

Shows a positive feedback submission button.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ActionBarPrimitiveFeedbackPositiveProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

<DataAttributesTable
  data={[
  {
    attribute: "[data-submitted]",
    values: "Present when positive feedback was submitted.",
  },
]}
/>

### Feedback Negative

Shows a negative feedback submission button.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ActionBarPrimitiveFeedbackNegativeProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

<DataAttributesTable
  data={[
  {
    attribute: "[data-submitted]",
    values: "Present when negative feedback was submitted.",
  },
]}
/>


file: ./content/docs/api-reference/primitives/AssistantModal.mdx
# AssistantModalPrimitive


        
A modal chat UI usually displayed in the bottom right corner of the screen.

import { Code } from "@radix-ui/themes";
import { ParametersTable, DataAttributesTable } from "@/components/docs";

## Anatomy

```tsx
import { AssistantModalPrimitive } from "@assistant-ui/react";

const Thread = () => (
  <AssistantModalPrimitive.Root>
    <AssistantModalPrimitive.Trigger>
      <FloatingAssistantButton />
    </AssistantModalPrimitive.Trigger>
    <AssistantModalPrimitive.Content>
      <Thread />
    </AssistantModalPrimitive.Content>
  </AssistantModalPrimitive.Root>
);
```

## API Reference

### Root

Contains all parts of the assistant modal.

<ParametersTable
  type="AssistantModalPrimitiveRootProps"
  parameters={[
  {
    name: "defaultOpen",
    type: "boolean",
    default: "false",
    description:
      "The open state of the assistant modal when it is initially rendered. Use when you do not need to control its open state.",
  },
  {
    name: "open",
    type: "boolean",
    description:
      "Not recommended. The controlled open state of the assistant modal. Must be used in conjunction with onOpenChange.",
  },
  {
    name: "onOpenChange",
    type: "(open: boolean) => void",
    description:
      "Event handler called when the open state of the assistant modal changes.",
  },
  {
    name: "modal",
    type: "boolean",
    default: "false",
    description:
      "The modality of the assistant modal. When set to true, interaction with outside elements will be disabled and only modal content will be visible to screen readers.",
  },
]}
/>

### Trigger

A button that toggles the open state of the assistant modal. `AssistantModalPrimitive.Content` will position itself against this button.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="AssistantModalPrimitiveTriggerProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

<DataAttributesTable
  data={[
  {
    attribute: "[data-state]",
    values: <Code>"open" | "closed"</Code>,
  },
]}
/>

### Anchor

The anchor element that the assistant modal is attached to. Defaults to the `Trigger` element.

This primitive renders a `<div>` element unless `asChild` is set.

### Content

The component that pops out when the assistant modal is open.

This primitive renders a `<div>` element unless `asChild` is set.

<ParametersTable
  type="AssistantModalPrimitiveContentProps"
  parameters={[
  {
    name: "asChild",
  },
  {
    name: "side",
    type: "'top' | 'right' | 'bottom' | 'left'",
    default: "'top'",
    description: "The side of the assistant modal to position against.",
  },
  {
    name: "align",
    type: "'start' | 'center' | 'end'",
    default: "'end'",
    description: "The alignment of the assistant modal to position against.",
  },
  {
    name: "dissmissOnInteractOutside",
    type: "boolean",
    default: "false",
    description:
      "Dismiss the assistant modal when the user interacts outside of it.",
  },
]}
/>

Refer to Radix UI's Documentation for [Popover.Content](https://www.radix-ui.com/primitives/docs/components/popover#content) for more details.


file: ./content/docs/api-reference/primitives/Attachment.mdx
# AttachmentPrimitive


        
Buttons to interact with attachments.

import { ParametersTable, DataAttributesTable } from "@/components/docs";
import { Code } from "@radix-ui/themes";
import { Callout } from "fumadocs-ui/components/callout";

<Callout>
  **Dual Use!** Attachments can appear in both messages and composers.
</Callout>

## Anatomy

```tsx
import { AttachmentPrimitive } from "@assistant-ui/react";

const MyMessageAttachment = () => (
  <AttachmentPrimitive.Root>
    <AttachmentPrimitive.Thumbnail />
    <AttachmentPrimitive.Name />
  </AttachmentPrimitive.Root>
);

const MyComposerAttachment = () => (
  <AttachmentPrimitive.Root>
    <AttachmentPrimitive.Thumbnail />
    <AttachmentPrimitive.Name />
    <AttachmentPrimitive.Remove />
  </AttachmentPrimitive.Root>
);
```

## API Reference

### Container

Containts all parts of the attachment.

This primitive renders a `<div>` element unless `asChild` is set.

<ParametersTable
  type="AttachmentPrimitiveRootProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### Thumbnail

The thumbnail of the attachment.

This primitive renders a `<div>` element unless `asChild` is set.

<ParametersTable
  type="AttachmentPrimitiveThumbnailProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### Name

The name of the attachment.

This primitive renders a `<div>` element unless `asChild` is set.

<ParametersTable
  type="AttachmentPrimitiveNameProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### Remove

Removes the attachment.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="AttachmentPrimitiveRemoveProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>


file: ./content/docs/api-reference/primitives/BranchPicker.mdx
# BranchPickerPrimitive


        
View and switch between branches.

import { ParametersTable } from "@/components/docs";

## Anatomy

```tsx
import { BranchPickerPrimitive } from "@assistant-ui/react";

const BranchPicker = () => (
  <BranchPickerPrimitive.Root>
    <BranchPickerPrimitive.Previous />
    <BranchPickerPrimitive.Number /> / <BranchPickerPrimitive.Count />
    <BranchPickerPrimitive.Next />
  </BranchPickerPrimitive.Root>
);
```

## API Reference

### Root

Containts all parts of the branch picker.

This primitive renders a `<div>` element unless `asChild` is set.

<ParametersTable
  type="BranchPickerPrimitiveRootProps"
  parameters={[
  {
    name: "asChild",
  },
  {
    name: "hideWhenSingleBranch",
    type: "boolean",
    default: "false",
    description:
      "Do not render the BranchPicker when there is only one branch at the current message.",
  },
]}
/>

### Number

The current branch number.

This primitive renders the raw number as a string.

### Count

The total number of branches.

This primitive renders the raw number as a string.

### Previous

Navigates to the previous branch.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="BranchPickerPrimitivePreviousProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### Next

Navigates to the next branch.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="BranchPickerPrimitiveNextProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>


file: ./content/docs/api-reference/primitives/Composer.mdx
# ComposerPrimitive


        
The user interface to add new messages or edit existing ones.

import { Callout } from "fumadocs-ui/components/callout";

import { ParametersTable, KeyboardTable } from "@/components/docs";
import { Code } from "@radix-ui/themes";

<Callout>
  **Dual Use!** A Composer placed directly inside a `Thread` will compose new
  messages. A Composer placed inside a `Message` will edit that message.
</Callout>

## Anatomy

```tsx
import { ComposerPrimitive } from "@assistant-ui/react";

// creating a new message
const Composer = () => (
  <ComposerPrimitive.Root>
    <ComposerPrimitive.Attachments />
    <ComposerPrimitive.AddAttachment />
    <ComposerPrimitive.Input />
    <ComposerPrimitive.Send />
  </ComposerPrimitive.Root>
);

// editing an existing message
const EditComposer = () => (
  <ComposerPrimitive.Root>
    <ComposerPrimitive.Input />
    <ComposerPrimitive.Send />
    <ComposerPrimitive.Cancel />
  </ComposerPrimitive.Root>
);
```

## API Reference

### Root

Containts all parts of the composer.

This primitive renders a `<form>` element unless `asChild` is set.

<ParametersTable
  type="ComposerRootProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### Input

The text input field for the user to type a new message.

This primitive renders a `<textarea>` element unless `asChild` is set.

<ParametersTable
  type="ComposerPrimitiveInputProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

#### Keyboard Shortcuts

<KeyboardTable
  data={[
  {
    keys: ["Enter"],
    description: "Sends the message.",
  },
  {
    keys: ["Escape"],
    description: "Sends a cancel action.",
  },
]}
/>

### Send

The button to send the message.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ComposerPrimitiveSendProps"
  parameters={[
  {
    name: "asChild",
  },
  {
    name: "multiple",
    type: "boolean | undefined",
    description: "Allow selecting multiple attachments at the same time.",
    default: "true",
  },
]}
/>

### Cancel

Sends a cancel action.

In edit composers, this action exits the edit mode.\
In thread composers, this action stops the current run.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ComposerPrimitiveCancelProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### Attachments

Renders attachments. This primitive renders a separate component for each attachment.

<ParametersTable
  type="ComposerPrimitiveAttachmentsProps"
  parameters={[
  {
    name: "components",
    type: "ComposerAttachmentsComponents",
    description: "The component to render for each attachment.",
    children: [
      {
        type: "ComposerPrimitiveAttachmentsProps['components']",
        parameters: [
          {
            name: "Image",
            type: "ComponentType",
            description: "The component to render for each image attachment.",
          },
          {
            name: "Document",
            type: "ComponentType",
            description:
              "The component to render for each document attachment.",
          },
          {
            name: "File",
            type: "ComponentType",
            description: "The component to render for each file attachment.",
          },
          {
            name: "Fallback",
            type: "ComponentType",
            description: "The component to render for each attachment type.",
          },
        ],
      },
    ],
  },
]}
/>

### AddAttachment

Renders a button to add an attachment.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ComposerPrimitiveAddAttachmentProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### If

Renders children if a condition is met.

<ParametersTable
  type="UseComposerIfProps"
  parameters={[
  {
    name: "editing",
    required: false,
    type: "boolean | undefined",
    description: "Render children if the message is being edited.",
  },
]}
/>

```tsx
<Composer.If editing>{/* rendered if message is being edited */}</Composer.If>
```


file: ./content/docs/api-reference/primitives/ContentPart.mdx
# ContentPartPrimitive

A part of a message's content. Content parts may be text, image, tool call or UI elements.
        
import { ParametersTable } from "@/components/docs";
import {
  ContentPartRuntime,
  TextContentPartState,
  AudioContentPartState,
  ToolCallContentPartState,
} from "@/generated/typeDocs";

Each message can have any number of content parts.\
Content parts are usually one of text, reasoning, audio or tool-call.

## Content Part Types

### Text

Standard text content, used for both user and assistant messages.

### Reasoning

Exposes the assistant's reasoning process, showing how it arrived at its responses. This is typically used only in assistant messages.

### Audio

Audio content that can be played back.

### Tool Call

Interactive elements that represent tool operations.

## Anatomy

```tsx
import { ContentPartPrimitive } from "@assistant-ui/react";

const TextContentPart = () => {
  return <ContentPartPrimitive.Text />;
};
```

## Primitives

### Plain Text

```tsx
import { ContentPartPrimitive } from "@assistant/react";

<ContentPartPrimitive.Text />;
```

### Markdown Text

Renders the message's text as Markdown.

```tsx
import { MarkdownTextPrimitive } from "@assistant-ui/react-markdown";

<MarkdownTextPrimitive />;
```

### Audio

Coming soon.

### InProgress

Renders children only if the content part is in progress.

```tsx
import { ContentPartPrimitive } from "@assistant/react";

<ContentPartPrimitive.InProgress>
  <LoadingIndicator />
</ContentPartPrimitive.InProgress>;
```

### Tool UI

You can map tool calls to UI components. We provide a few utility functions to make this easier, such as `makeAssistantToolUI`.

```tsx
const MyWeatherToolUI = makeAssistantToolUI({
  toolName: "get_weather",
  render: function MyWeatherToolUI({ args, result }) {
    return (
      <div className="mb-4 flex flex-col items-center">
        <pre className="whitespace-pre-wrap break-all text-center">
          get_weather({JSON.stringify(args)})
        </pre>
        {"result" in result && (
          <pre className="whitespace-pre-wrap break-all text-center">
            {JSON.stringify(result.result)}
          </pre>
        )}
      </div>
    );
  },
});
```

## Context Provider

Content part context is provided by `MessagePrimitive.Content` or `TextContentPartProvider`

### MessagePrimitive.Content

```tsx
import { MessagePrimitive } from "@assistant/react";

<MessagePrimitive.Content
  components={{
    Text: MyText,
    Reasoning: MyReasoning,
    Audio: MyAudio,
    tools: {
      by_name: {
        get_weather: MyWeatherToolUI,
      },
      Fallback: MyFallbackToolUI,
    },
  }}
/>;
```

### TextContentPartProvider

This is a helper context provider to allow you to reuse the content part components outside a message content part.

```tsx
import { TextContentPartProvider } from "@assistant-ui/react";

<TextContentPartProvider text="Hello world" isRunning={false}>
  <ContentPart.Text />
</TextContentPartProvider>;
```

## Runtime API

### `useContentPartRuntime`

```tsx
import { useContentPartRuntime } from "@assistant-ui/react";

const contentPartRuntime = useContentPartRuntime();
```

<ParametersTable {...ContentPartRuntime} />

### `useContentPart`

```tsx
import { useContentPart } from "@assistant-ui/react";

const contentPart = useContentPart();
```

<ParametersTable {...TextContentPartState} />

<ParametersTable {...AudioContentPartState} />

<ParametersTable {...ToolCallContentPartState} />

### `useContentPartText`

```tsx
import { useContentPartText } from "@assistant-ui/react";

const contentPartText = useContentPartText();
```

<ParametersTable {...TextContentPartState} />


file: ./content/docs/api-reference/primitives/Error.mdx
# ErrorPrimitive


        
A component for displaying error messages in the UI.

import { ParametersTable } from "@/components/docs";

## Anatomy

```tsx
import { ErrorPrimitive } from "@assistant-ui/react";

const ErrorDisplay = () => (
  <ErrorPrimitive.Root>
    <ErrorPrimitive.Message />
  </ErrorPrimitive.Root>
);
```

## API Reference

### Root

Contains all parts of the error display. Renders a `<div>` element with `role="alert"`.

<ParametersTable
  type="ErrorPrimitiveRootProps"
  parameters={[
  {
    name: "asChild",
    type: "boolean",
    description: "Change the component to the HTML tag or custom component of the only child.",
  },
]}
/>

### Message

Displays the error message. By default, it shows the error from the message context if available, or you can provide custom content.

<ParametersTable
  type="ErrorPrimitiveMessageProps"
  parameters={[
  {
    name: "children",
    type: "ReactNode",
    description: "Optional custom content to display instead of the default error message.",
  },
]}
/>

## Usage

The ErrorPrimitive is typically used within a MessagePrimitive.Error component to display error states in messages:

```tsx
import { MessagePrimitive, ErrorPrimitive } from "@assistant-ui/react";

const MessageWithError = () => (
  <MessagePrimitive.Root>
    <MessagePrimitive.Content />
    <MessagePrimitive.Error>
      <ErrorPrimitive.Root>
        <ErrorPrimitive.Message />
      </ErrorPrimitive.Root>
    </MessagePrimitive.Error>
  </MessagePrimitive.Root>
);
```


file: ./content/docs/api-reference/primitives/Message.mdx
# MessagePrimitive


        
A single message in a conversation. Messages may consist of multiple parts.

import { ParametersTable } from "@/components/docs";

## Anatomy

```tsx
import { MessagePrimitive } from "@assistant-ui/react";

const UserMessage = () => (
  <MessagePrimitive.Root>
    User: <MessagePrimitive.Content />
    <BranchPicker />
    <ActionBar />
  </MessagePrimitive.Root>
);

const AssistantMessage = () => (
  <MessagePrimitive.Root>
    Assistant: <MessagePrimitive.Content />
    <BranchPicker />
    <ActionBar />
  </MessagePrimitive.Root>
);
```

## API Reference

### Root

Containts all parts of the message.

This primitive renders a `<div>` element unless `asChild` is set.

<ParametersTable
  type="MessagePrimitiveRootProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### Content

The content of the message. This renders a separate component for each content part of the message.

<ParametersTable
  type="MessagePrimitiveContentProps"
  parameters={[
  {
    name: "components",
    required: false,
    type: "ContentPartComponents",
    description: "The components to render for each content part.",
    children: [
      {
        type: "ContentPartComponents",
        parameters: [
          {
            name: "Text",
            type: "TextContentPartComponent",
            description:
              "The component to render for each text content part.",
          },
          {
            name: "Image",
            type: "ImageContentPartComponent",
            description:
              "The component to render for each image content part.",
          },
          {
            name: "Source",
            type: "SourceContentPartComponent",
            description:
              "The component to render for each source content part.",
          },
          {
            name: "File",
            type: "FileContentPartComponent",
            description:
              "The component to render for each file content part.",
          },
          {
            name: "Unstable_Audio",
            type: "Unstable_AudioContentPartComponent",
            description:
              "The component to render for each audio content part.",
          },
          {
            name: "tools",
            type: "object",
            description:
              "The component to render for each tool call content part.",
            children: [
              {
                parameters: [
                  {
                    name: "by_name",
                    type: "Record<string, ToolCallContentPartComponent>",
                    description:
                      "The components to render for each tool call content part.",
                  },
                  {
                    name: "Fallback",
                    type: "ToolCallContentPartComponent",
                    description:
                      "The fallback component to render for tool call content parts.",
                  },
                ],
              },
            ],
          },
        ],
      },
    ],
  },
]}
/>

### If

Renders children if a condition is met.

<ParametersTable
  type="UseMessageIfProps"
  parameters={[
  {
    name: "user",
    type: "boolean | undefined",
    description: "Render children if the message is from the user.",
  },
  {
    name: "assistant",
    type: "boolean | undefined",
    description: "Render children if the message is from the assistant.",
  },
  {
    name: "hasBranches",
    type: "boolean | undefined",
    description: "Render children if the message has branches.",
  },
  {
    name: "copied",
    type: "boolean | undefined",
    description: "Render children if the message is copied.",
  },
  {
    name: "lastOrHover",
    type: "boolean | undefined",
    description:
      "Render children if the message is the last or hovered over.",
  },
]}
/>

```tsx
<Message.If user>
  {/* rendered if message is from the user */}
</Message.If>
<Message.If assistant>
  {/* rendered if message is from the assistant */}
</Message.If>
```

### Error

Renders children only if the message has an error status.

```tsx
<MessagePrimitive.Error>
  {/* rendered if the message has an error status */}
  <ErrorPrimitive.Root>
    <ErrorPrimitive.Message />
  </ErrorPrimitive.Root>
</MessagePrimitive.Error>
```


file: ./content/docs/api-reference/primitives/Thread.mdx
# ThreadPrimitive


        
A conversation between a user and an assistant.

import { ParametersTable } from "@/components/docs";

## Anatomy

```tsx
import { ThreadPrimitive } from "@assistant-ui/react";

const Thread = () => (
  <ThreadPrimitive.Root>
    <ThreadPrimitive.Viewport>
      <ThreadPrimitive.Empty>...</ThreadPrimitive.Empty>
      <ThreadPrimitive.Messages components={...} />
    </ThreadPrimitive.Viewport>
    <Composer />
  </ThreadPrimitive.Root>
);
```

## API Reference

### Root

Containts all parts of the thread.

This primitive renders a `<div>` element unless `asChild` is set.

<ParametersTable
  type="ThreadPrimitiveRootProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### Viewport

The scrollable area containing all messages. Anchors scroll to the bottom as new messages are added.

This primitive renders a `<div>` element unless `asChild` is set.

<ParametersTable
  type="ThreadPrimitiveViewportProps"
  parameters={[
  {
    name: "asChild",
  },
  {
    name: "autoScroll",
    type: "boolean",
    default: "true",
    description:
      "Whether to automatically scroll to the bottom of the viewport when new messages are added while the viewport is was previously scrolled to the bottom.",
  },
]}
/>

### Messages

Renders all messages. This primitive renders a separate component for each message.

<ParametersTable
  type="ThreadPrimitiveMessagesProps"
  parameters={[
  {
    name: "components",
    type: "MessageComponents",
    description: "The component to render for each message.",
    children: [
      {
        type: "MessageComponents",
        parameters: [
          {
            name: "Message",
            type: "ComponentType",
            description: "The component to render for each message.",
          },
          {
            name: "UserMessage",
            type: "ComponentType",
            description: "The component to render for user messages.",
          },
          {
            name: "EditComposer",
            type: "ComponentType",
            description:
              "The component to render for user messages that are being edited.",
          },
          {
            name: "AssistantMessage",
            type: "ComponentType",
            description: "The component to render for assistant messages.",
          },
        ],
      },
    ],
  },
]}
/>

### Empty

Renders children only when there are no messages.

### ScrollToBottom

A button to scroll the viewport to the bottom. Disabled when the viewport is already at bottom.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ThreadPrimitiveScrollToBottomProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### `ThreadPrimitive.Suggestion`

Shows a suggestion to the user. When the user clicks on the suggestion, the composer's value is set to the suggestion's prompt.

This primitive renders a `<button>` element unless `asChild` is set.

```tsx
import { ThreadPrimitive } from "@assistant-ui/react";

const Suggestion = () => {
  return (
    <ThreadPrimitive.Suggestion
      prompt="I need help with product search"
      method="replace"
      autoSend
    />
  );
};
```

<ParametersTable
  type="ThreadPrimitiveSuggestionProps"
  parameters={[
  {
    name: "prompt",
    type: "string",
    description: "The suggestion's prompt.",
  },
  {
    name: "method",
    type: "'replace'",
    description:
      "How does the suggestion interact with the composer's existing value.",
  },
  {
    name: "autoSend",
    type: "boolean",
    description:
      "Whether to automatically send the suggestion when the user clicks on it.",
    default: "false",
  },
]}
/>

### If

Renders children if a condition is met.

<ParametersTable
  type="ThreadPrimitiveIfProps"
  parameters={[
  {
    name: "empty",
    type: "boolean | undefined",
    description: "Render children if the thread is empty.",
  },
  {
    name: "running",
    type: "boolean | undefined",
    description: "Render children if the thread is running.",
  },
]}
/>

```tsx
<Thread.If empty>
  {/* equivalent to <Thread.Empty> */}
</Thread.If>
<Thread.If empty={false}>
  {/* rendered if thread is not empty */}
</Thread.If>
```


file: ./content/docs/api-reference/primitives/composition.mdx
# Composition


        
import { Code } from "@radix-ui/themes";

`assistant-ui` primitives are composable. This means that all props are forwarded, classes are merged, and event handlers are chained.

Most primitives come with a default HTML element (usually `div` or `button`). If you already have a custom component, you can use the `asChild` prop to replace it:

```tsx
// use the primitive's <button> element
<Composer.Send>Send</Composer.Send>;

// use your own <Button> component
<Composer.Send asChild>
  <Button>Send</Button>
</Composer.Send>;
```

Learn more on [Radix's composition guide](https://www.radix-ui.com/primitives/docs/guides/composition).


file: ./content/docs/api-reference/runtimes/AssistantRuntime.mdx
# AssistantRuntime


        
import { ParametersTable } from "@/components/docs";
import { AssistantRuntime, AssistantToolUIsState } from "@/generated/typeDocs";

The `AssistantRuntime` is the root runtime of the application.

### `useAssistantRuntime`

```tsx
import { useAssistantRuntime } from "@assistant-ui/react";

const runtime = useAssistantRuntime();
```

<ParametersTable {...AssistantRuntime} />

### Tool UI Registry

The tool UI registry is part of the assistant runtime. It allows you to display custom UI for tool calls, enabling generative UI.

#### `useToolUIs`

```tsx
import { useToolUIs } from "@assistant-ui/react";

const toolUIs = useToolUIs();
const webSearchToolUI = useToolUIs((m) => m.getToolUI("web_search"));
```

<ParametersTable {...AssistantToolUIsState} />


file: ./content/docs/api-reference/runtimes/AttachmentRuntime.mdx
# AttachmentRuntime


        
import { ParametersTable } from "@/components/docs";
import {
  ComposerAttachmentState,
  MessageAttachmentState,
} from "@/components/docs/parameters/context";

### `useAttachment`

Access the current attachment state:

```tsx
import { useAttachment } from "@assistant-ui/react";

const { attachment } = useAttachment();
const att = useAttachment((m) => m.attachment);
```

### `useComposerAttachment` (Composer)

When working with a composers attachment:

```tsx
import { useComposerAttachment } from "@assistant-ui/react";

const { attachment } = useComposerAttachment();
const composerAttachment = useComposerAttachment((m) => m.attachment);
```

<ParametersTable {...ComposerAttachmentState} />

### `useMessageAttachment` (Message)

For managing a messages attachment:

```tsx
import { useMessageAttachment } from "@assistant-ui/react";

const { attachment } = useMessageAttachment();
const messageAttachment = useMessageAttachment((m) => m.attachment);
```

<ParametersTable {...MessageAttachmentState} />


file: ./content/docs/api-reference/runtimes/ComposerRuntime.mdx
# ComposerRuntime


        
The composer runtime allows you to view or edit anything related to how new information is added and sent. For instance you can use the composer runtime to read the state, add attachments, update text, send a message, etc.

import { ParametersTable } from "@/components/docs";
import { ComposerRuntime, ThreadComposerRuntime, ThreadComposerState, EditComposerState } from "@/generated/typeDocs";

### `useComposer`

Grabs the nearest composer (whether its the edit composer or the threads composer):

```tsx
// Example
import { useComposer } from "@assistant-ui/react";

const composerRuntime = useComposer();

// set the text
composerRuntime.setText("Hello from the composer runtime");

// send whatever is in the composer 
composerRuntime.send();

// get the current text in the composer state
const composerState = composerRuntime.getState();
const currentText = composerState.text;

```

<ParametersTable {...ComposerRuntime} />

### `useThreadComposer`

Access the threads new message composer state:

```tsx
import { useThreadComposer } from "@assistant-ui/react";

const threadComposerRuntime = useThreadComposer();

// set the text
threadComposerRuntime.setText("Hello from the thread composer runtime");

// send whatever is in the thread composer 
threadComposerRuntime.send();

// get the current text in the composer state
const threadComposerState = threadComposerRuntime.getState();
const currentText = threadComposerRuntime.text;

```

<ParametersTable {...ThreadComposerRuntime} />

### `ThreadComposerState`

The state of the thread composer which is the composer the user can interact with at the bottom.

<ParametersTable {...ThreadComposerState} />

### `EditComposerState`

The state of the edit composer which is the composer the user can edit messages with.

<ParametersTable {...EditComposerState} />


file: ./content/docs/api-reference/runtimes/ContentPartRuntime.mdx
# ContentPartRuntime


        
import { ParametersTable } from "@/components/docs";
import { ContentPartState } from "@/components/docs/parameters/context";

### `useContentPart`

Access the content part state:

```tsx
import { useContentPart } from "@assistant-ui/react";

const part = useContentPart();
const partState = useContentPart.getState();

const status = useContentPart((m) => m.status);
const statusAgain = useContentPart.getState().status;
```

<ParametersTable {...ContentPartState} />


file: ./content/docs/api-reference/runtimes/MessageRuntime.mdx
# MessageRuntime


        
import { ParametersTable } from "@/components/docs";
import {
  MessageState,
  MessageUtilsState,
  EditComposerState,
} from "@/components/docs/parameters/context";

### `useMessage`

Retrieve the message object:

```tsx
import { useMessage } from "@assistant-ui/react";

const { message } = useMessage();
const msg = useMessage((m) => m.message);
```

<ParametersTable {...MessageState} />

### `useMessageUtils`

Provides utility functions for a message (e.g., copy status):

```tsx
import { useMessageUtils } from "@assistant-ui/react";

const messageUtils = useMessageUtils();
const isCopied = useMessageUtils((m) => m.isCopied);
```

<ParametersTable {...MessageUtilsState} />

### `useEditComposer`

Access the edit composer state (used when editing a message):

```tsx
import { useEditComposer } from "@assistant-ui/react";

const editComposer = useEditComposer();
const text = useEditComposer((m) => m.text);
```

<ParametersTable {...EditComposerState} />


file: ./content/docs/api-reference/runtimes/ThreadListItemRuntime.mdx
# ThreadListItemRuntime


        
import { ParametersTable } from "@/components/docs";
import {
  ThreadListItemRuntime,
  ThreadListItemState,
} from "@/generated/typeDocs";

### `useThreadListItemRuntime`

```tsx
import { useThreadListItemRuntime } from "@assistant-ui/react";

const threadListItemRuntime = useThreadListItemRuntime();
```

<ParametersTable {...ThreadListItemRuntime} />

### `useThreadListItem`

Access the state for a specific thread list item:

```tsx
import { useThreadListItem } from "@assistant-ui/react";

const threadListItem = useThreadListItem();
const title = useThreadListItem((m) => m.title);
```

<ParametersTable {...ThreadListItemState} />


file: ./content/docs/api-reference/runtimes/ThreadListRuntime.mdx
# ThreadListRuntime


        
import { ParametersTable } from "@/components/docs";
import { ThreadListRuntime, ThreadListState } from "@/generated/typeDocs";

### Access via `useAssistantRuntime`

You can access the thread list runtime via the assistant runtime:

```tsx
import { useAssistantRuntime } from "@assistant-ui/react";

const threadListRuntime = useAssistantRuntime().threadList;
```

<ParametersTable {...ThreadListRuntime} />

### `useThreadList`

This hook provides access to the thread list state:

```tsx
import { useThreadList } from "@assistant-ui/react";

const threadList = useThreadList();
const threads = useThreadList((m) => m.threads);
```

<ParametersTable {...ThreadListState} />


file: ./content/docs/api-reference/runtimes/ThreadRuntime.mdx
# ThreadRuntime


        
import { ParametersTable } from "@/components/docs";
import { ThreadRuntime, ThreadState } from "@/generated/typeDocs";
import {
  ThreadMessagesState,
  ThreadViewportState,
} from "@/components/docs/parameters/context";

### `useThreadRuntime`

Get the thread runtime object:

```tsx
import { useThreadRuntime } from "@assistant-ui/react";

const thread = useThreadRuntime();
```

<ParametersTable {...ThreadRuntime} />

### `useThread`

Access the thread state directly:

```tsx
import { useThread } from "@assistant-ui/react";

const thread = useThread();
const isRunning = useThread((m) => m.isRunning);
```

<ParametersTable {...ThreadState} />

### `useThreadViewport`

Manage thread viewport state (e.g., scrolling):

```tsx
import { useThreadViewport } from "@assistant-ui/react";

const threadViewport = useThreadViewport();
const isAtBottom = useThreadViewport((m) => m.isAtBottom);
```

<ParametersTable {...ThreadViewportState} />


file: ./content/docs/cloud/persistence/ai-sdk.mdx
# Chat History for AI SDK


        
## Overview

With the help of assistant-cloud, you can add thread management and thread history capabilities to assistant-ui. This guide will walk you through the process of integrating assistant-cloud with the AI SDK by Vercel.

### Prerequisites

You need an assistant-cloud account to follow this guide. You can sign up here: [https://cloud.assistant-ui.com/](https://cloud.assistant-ui.com/)

### Setting up assistant-cloud project in your react project:

1. Create a new project on the assistant-cloud dashboard and copy the Frontend API URL (`https://proj-[ID].assistant-api.com`) from the settings page.
2. Add the url as an environment variable `NEXT_PUBLIC_ASSISTANT_BASE_URL`

```bash
NEXT_PUBLIC_ASSISTANT_BASE_URL=[YOUR_FRONTEND_API_URL]
```

3. Create a client side AssistantCloud instance. Note: this will create an anonymous user id that is tied to the user's browser session. For connecting to an auth provider to persist threads for a user based on a workspace and/or user id, look at [Cloud Authorization Docs](/docs/cloud/authorization).

```typescript
"use client";
import {
  AssistantCloud,
  AssistantRuntimeProvider,
  ThreadList,
  Thread
} from "@assistant-ui/react";
import { useChatRuntime } from "@assistant-ui/react-ai-sdk";


const cloud = new AssistantCloud({
  baseUrl: process.env["NEXT_PUBLIC_ASSISTANT_BASE_URL"]!,
  anonymous: true,
});


const runtime = useChatRuntime({
  api: "/api/chat",
  cloud,
});

 return (
  <AssistantRuntimeProvider runtime={runtime}>
    <div className="grid h-dvh grid-cols-[200px_1fr] gap-x-2 px-4 py-4">
      <ThreadList />
      <Thread />
    </div>
  </AssistantRuntimeProvider>
);

```


file: ./content/docs/cloud/persistence/langgraph.mdx
# Chat History for LangGraph Cloud


        
## Overview

With the help of assistant-cloud, you can add thread management and thread history capabilities to assistant-ui.\
This guide will walk you through the process of integrating assistant-cloud with LangGraph Cloud.

### Prerequisites

You need an assistant-cloud account to follow this guide.\
You can sign up here: [https://cloud.assistant-ui.com/](https://cloud.assistant-ui.com/)

### Setting up an assistant-cloud project

To get started, follow the steps below:

* Create a new project on the assistant-cloud dashboard.
* Navigate to the "Settings" tab and copy the Frontend API URL.
* Add this URL to your .env file

```bash
NEXT_PUBLIC_ASSISTANT_BASE_URL=https://<your-frontend-api-url>
```

### Connecting the runtime provider

Now that we have everything set up, let's write the code for the runtime provider.

The code below is a simple LangGraph runtime provider that uses the assistant-cloud API to create and manage threads.

```tsx twoslash {1-2,5-6,19,27,29-36,38-45}
// @errors: 2307

"use client";

import {
  AssistantCloud,
  AssistantRuntimeProvider,
  useCloudThreadListRuntime,
  useThreadListItemRuntime,
} from "@assistant-ui/react";
import { useLangGraphRuntime } from "@assistant-ui/react-langgraph";
import { createThread, getThreadState, sendMessage } from "@/lib/chatApi";
import { LangChainMessage } from "@assistant-ui/react-langgraph";
import { useAuth } from "@clerk/nextjs";
import { useMemo } from "react";

// ---cut---
const useMyLangGraphRuntime = () => {
  const threadListItemRuntime = useThreadListItemRuntime();
  const runtime = useLangGraphRuntime({
    stream: async function* (messages) {
      const { externalId } = await threadListItemRuntime.initialize();
      if (!externalId) throw new Error("Thread not found");

      return sendMessage({ threadId: externalId, messages });
    },
    onSwitchToThread: async (externalId) => {
      const state = await getThreadState(externalId);
      return {
        messages:
          (state.values as { messages?: LangChainMessage[] }).messages ?? [],
      };
    },
  });

  return runtime;
};

export function MyRuntimeProvider({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  const { getToken } = useAuth();

  const cloud = useMemo(
    () =>
      new AssistantCloud({
        baseUrl: process.env["NEXT_PUBLIC_ASSISTANT_BASE_URL"]!,
        authToken: async () => getToken({ template: "assistant-ui" }),
      }),
    [getToken],
  );

  const runtime = useCloudThreadListRuntime({
    cloud,
    runtimeHook: useMyLangGraphRuntime,
    create: async () => {
      const { thread_id } = await createThread();
      return { externalId: thread_id };
    },
  });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
}
```

<Callout emoji="">
  Observe that the `useMyLangGraphRuntime` hook is extracted into a separate
  function. This hook will be mounted multiple times, once per active thread.
</Callout>

### Displaying a ThreadList component

Now, you can add a ThreadList component to your application. This component will display a list of threads and allow users to switch between them.

```sh
npx shadcn@latest add "https://r.assistant-ui.com/thread-list"
```

```tsx
<div className="grid grid-cols-[250px_1fr]">
  <ThreadList />
  <Thread />
</div>
```


file: ./content/docs/legacy/styled/AssistantModal.mdx
# AssistantModal


        
import { Steps, Step } from "fumadocs-ui/components/steps";
import { Tabs, Tab } from "fumadocs-ui/components/tabs";

## Overview

A chat bubble shown in the bottom right corner of the screen. Useful for support or Q\&A use cases.

## Getting Started

<Steps>
  <Step>
    ### Install `@assistant-ui/react-ui`

    ```sh npm2yarn
    npm install @assistant-ui/react-ui
    ```
  </Step>

  <Step>
    ### Import CSS styles

    Add the following to your `tailwind.config.ts`:

    <Tabs items={["Tailwind", "Tailwind + shadcn-ui", "Not using Tailwind"]}>
      ```ts title="/tailwind.config.ts" tab="Tailwind"
      {
        plugins: [
          require("tailwindcss-animate"), // make sure to "npm install tailwindcss-animate"
          require("@assistant-ui/react-ui/tailwindcss")({
            components: ["assistant-modal"],
          })
        ],
      }
      ```

      ```ts title="/tailwind.config.ts" tab="Tailwind + shadcn-ui"
      {
        plugins: [
          require("tailwindcss-animate"), // make sure to "npm install tailwindcss-animate"
          require("@assistant-ui/react-ui/tailwindcss")({
            components: ["assistant-modal"],
            shadcn: true
          })
        ],
      }
      ```

      ```ts title="/app/layout.tsx" tab="Not using Tailwind"
      import "@assistant-ui/react-ui/styles/index.css";
      import "@assistant-ui/react-ui/styles/modal.css";
      ```
    </Tabs>
  </Step>

  <Step>
    ### Use it in your app

    ```tsx title="/app/page.tsx"
    import { useChatRuntime } from "@assistant-ui/react-ai-sdk";
    import { AssistantModal } from "@assistant-ui/react-ui";

    const MyApp = () => {
      const runtime = useChatRuntime({
        api: "/api/chat",
      });

      return (
        <div>
          <AssistantModal runtime={runtime} />
        </div>
      );
    };
    ```
  </Step>
</Steps>


file: ./content/docs/legacy/styled/Decomposition.mdx
# Decomposition


        
## Overview

The Styled Components can be decomposed into smaller components. At each level, you can swap out a specific component with your own custom component.

## Thread

Renders an entire conversation thread.

```tsx
import {
  Thread,
  ThreadWelcome,
  Composer,
  type ThreadConfig,
} from "@assistant-ui/react-ui";

const MyThread: FC<ThreadConfig> = (config) => {
  return (
    <Thread.Root config={config}>
      <Thread.Viewport>
        <ThreadWelcome />
        <Thread.Messages />
        <Thread.FollowupSuggestions />
        <Thread.ViewportFooter>
          <Thread.ScrollToBottom />
          <Composer />
        </Thread.ViewportFooter>
      </Thread.Viewport>
    </Thread.Root>
  );
};
```

**Usage:**

```ts
<MyThread />
```

### Thread.Root

Contains all parts of the thread. Accepts a `config` prop which is used by many other styled components.

### Thread.Viewport

The scrollable area containing all messages. Anchors scroll to the bottom as new messages are added.

### Thread.Messages

Renders all messages. This renders a separate component for each message (passed to the `components` prop).

### Thread.ViewportFooter

Renders the footer of the thread viewport. This is the sticky footer that does not scroll with the messages.

### Thread.ScrollToBottom

A button to scroll the viewport to the bottom. Hidden when the viewport is already at bottom.

## ThreadWelcome

Renders the welcome message when no messages are present.

```tsx
import { ThreadWelcome } from "@assistant-ui/react-ui";

const MyThreadWelcome: FC = () => {
  return (
    <ThreadWelcome.Root>
      <ThreadWelcome.Center>
        <ThreadWelcome.Avatar />
        <ThreadWelcome.Message />
      </ThreadWelcome.Center>
      <ThreadWelcome.Suggestions />
    </ThreadWelcome.Root>
  );
};
```

**Usage:**

Decompose `Thread` into `MyThread` and use `MyThreadWelcome` instead of `ThreadWelcome`.

```ts
const MyThread: FC<ThreadConfig> = (config) => {
  ...
  <MyThreadWelcome />
  ...
};
```

### ThreadWelcome.Root

Contains all parts of the welcome message.

### ThreadWelcome.Center

The centered content of the welcome message.

### ThreadWelcome.Avatar

The avatar of the assistant.

### ThreadWelcome.Message

The welcome message.

### ThreadWelcome.Suggestions

Conversation starter suggestions.

```tsx
import { ThreadWelcome } from "@assistant-ui/react-ui";

const MyThreadWelcomeSuggestions: FC = () => {
  return (
    <div className="aui-thread-welcome-suggestions">
      <ThreadWelcome.Suggestion prompt="Write me a poem about the weather" />
      <ThreadWelcome.Suggestion prompt="What is assistant-ui?" />
    </div>
  );
};
```

### ThreadWelcome.Suggestion

A conversation starter suggestion.

## Composer

Renders the composer.

```tsx
import { Composer } from "@assistant-ui/react-ui";

const MyComposer: FC = () => {
  return (
    <Composer.Root>
      <Composer.Attachments />
      <Composer.AddAttachment />
      <Composer.Input autoFocus />
      <Composer.Action />
    </Composer.Root>
  );
};
```

**Usage:**

Decompose `Thread` into `MyThread` and use `MyComposer` instead of `Composer`.

```ts
const MyThread: FC<ThreadConfig> = (config) => {
  ...
  <MyComposer />
  ...
};
```

### Composer.Root

Contains all parts of the composer.

### Composer.Input

The text input field for the user to type a new message.

### Composer.Action

The button to send or cancel the message.

```tsx
import { Composer, ThreadPrimitive } from "@assistant-ui/react-ui";

const MyComposerAction: FC = () => {
  return (
    <>
      <ThreadPrimitive.If running={false}>
        <Composer.Send />
      </ThreadPrimitive.If>
      <ThreadPrimitive.If running>
        <Composer.Cancel />
      </ThreadPrimitive.If>
    </>
  );
};
```

### Composer.Send

The button to send the message.

### Composer.Cancel

Sends a cancel action.

### Composer.Attachments

Renders attachments.

### Composer.AddAttachment

Renders an add attachment button.

## AttachmentUI

<Callout type="info" emoji="">
  `AttachmentUI` is still experimental.
</Callout>

Renders an attachment.

```tsx
import { AttachmentUI } from "@assistant-ui/react-ui";

const MyAttachmentUI: FC = () => {
  return (
    <AttachmentUI.Root>
      attachment
      <AttachmentUI.Remove />
    </AttachmentUI.Root>
  );
};
```

### AttachmentUI.Root

Contains all parts of the composer attachment.

### AttachmentUI.Remove

Renders a remove attachment button.

## AssistantMessage

Renders an assistant message.

```tsx
import { AssistantMessage } from "@assistant-ui/react-ui";

const MyAssistantMessage: FC = () => {
  return (
    <AssistantMessage.Root>
      <AssistantMessage.Avatar />
      <AssistantMessage.Content />
      <BranchPicker />
      <AssistantActionBar />
    </AssistantMessage.Root>
  );
};
```

**Usage:**

Decompose `Thread` into `MyThread` and pass `MyAssistantMessage` to Thread.MEssages

```ts
const MyThread: FC<ThreadConfig> = (config) => {
  ...
  <Thread.Messages components={{ AssistantMessage: MyAssistantMessage }} />
  ...
};
```

### AssistantMessage.Root

Contains all parts of the assistant message.

### AssistantMessage.Avatar

The avatar of the assistant.

### AssistantMessage.Content

The content of the assistant message.

## AssistantActionBar

Renders the action bar for the assistant message.

```tsx
import { AssistantActionBar } from "@assistant-ui/react-ui";

const MyAssistantActionBar: FC = () => {
  return (
    <AssistantActionBar.Root
      hideWhenRunning
      autohide="not-last"
      autohideFloat="single-branch"
    >
      <AssistantActionBar.SpeechControl />
      <AssistantActionBar.Copy />
      <AssistantActionBar.Reload />
      <AssistantActionBar.FeedbackPositive />
      <AssistantActionBar.FeedbackNegative />
    </AssistantActionBar.Root>
  );
};
```

**Usage:**

Decompose `AssistantMessage` into `MyAssistantMessage` and use `MyAssistantActionBar` instead of `AssistantActionBar`.

```ts
const MyAssistantMessage: FC = () => {
  ...
  <MyAssistantActionBar />
  ...
};
```

### AssistantActionBar.Root

Contains all parts of the assistant action bar.

### AssistantActionBar.Reload

Shows a reload button.

### AssistantActionBar.Copy

Shows a copy button.

### AssistantActionBar.SpeechControl

Shows a speech control button (either Speak or StopSpeaking).

### AssistantActionBar.Speak

Shows a speak button.

### AssistantActionBar.StopSpeaking

Shows a stop speaking button.

### AssistantActionBar.FeedbackPositive

Shows a positive feedback button.

### AssistantActionBar.FeedbackNegative

Shows a negative feedback button.

## BranchPicker

Renders the branch picker.

```tsx
import { BranchPicker } from "@assistant-ui/react-ui";

const MyBranchPicker: FC = () => {
  return (
    <BranchPicker.Root hideWhenSingleBranch>
      <BranchPicker.Previous />
      <BranchPicker.State />
      <BranchPicker.Next />
    </BranchPicker.Root>
  );
};
```

**Usage:**

Decompose `AssistantMessage` and `UserMessage` and use `MyBranchPicker` instead of `BranchPicker`.

```ts
const MyAssistantMessage: FC = () => {
  ...
  <MyBranchPicker />
  ...
};
```

```ts
const MyUserMessage: FC = () => {
  ...
  <MyBranchPicker />
  ...
};
```

### BranchPicker.Root

Contains all parts of the branch picker.

### BranchPicker.Previous

Shows a previous button.

### BranchPicker.Next

Shows a next button.

### BranchPicker.State

Shows the current branch number and total number of branches.

```tsx
import { BranchPicker } from "@assistant-ui/react-ui";

const MyBranchPickerState: FC = () => {
  return (
    <span className="aui-branch-picker-state">
      <BranchPicker.Number /> / <BranchPicker.Count />
    </span>
  );
};
```

### BranchPicker.Number

The current branch number.

### BranchPicker.Count

The total number of branches.

## UserMessage

Renders a user message.

```tsx
import { UserMessage } from "@assistant-ui/react-ui";

const MyUserMessage: FC = () => {
  return (
    <UserMessage.Root>
      <UserMessage.Attachments />
      <UserMessage.Content />
      <UserActionBar />
      <BranchPicker />
    </UserMessage.Root>
  );
};
```

**Usage:**

Decompose `Thread` into `MyThread` and pass `MyUserMessage` to Thread.Messages

```ts
const MyThread: FC<ThreadConfig> = (config) => {
  ...
  <Thread.Messages components={{ UserMessage: MyUserMessage }} />
  ...
};
```

### UserMessage.Root

Contains all parts of the user message.

### UserMessage.Content

The content of the user message.

### UserMessage.Attachments

Renders attachments.

## UserActionBar

Renders the action bar for the user message.

```tsx
import { UserActionBar } from "@assistant-ui/react-ui";

const MyUserActionBar: FC = () => {
  return (
    <UserActionBar.Root hideWhenRunning autohide="not-last">
      <UserActionBar.Edit />
    </UserActionBar.Root>
  );
};
```

**Usage:**

Decompose `UserMessage` into `MyUserMessage` and use `MyUserActionBar` instead of `UserActionBar`.

```ts
const MyUserMessage: FC = () => {
  ...
  <MyUserActionBar />
  ...
};
```

### UserActionBar.Root

Contains all parts of the user action bar.

### UserActionBar.Edit

Shows an edit button.

## UserAttachment

Renders an attachment.

```tsx
import { UserAttachment } from "@assistant-ui/react-ui";

const MyUserAttachment: FC = () => {
  return <UserAttachment.Root>attachment</UserAttachment.Root>;
};
```

### UserAttachment.Root

Contains all parts of the user attachment.

## EditComposer

Renders a user message being edited.

```tsx
import { EditComposer } from "@assistant-ui/react-ui";

const MyEditComposer: FC = () => {
  return (
    <EditComposer.Root>
      <EditComposer.Input />
      <EditComposer.Footer>
        <EditComposer.Cancel />
        <EditComposer.Send />
      </EditComposer.Footer>
    </EditComposer.Root>
  );
};
```

**Usage:**

Decompose `Thread` into `MyThread` and pass `MyEditComposer` to `Thread.Messages`.

```ts
const MyThread: FC<ThreadConfig> = (config) => {
  ...
  <Thread.Messages components={{ EditComposer: MyEditComposer }} />
  ...
};
```

### EditComposer.Root

Contains all parts of the edit composer.

### EditComposer.Input

The text input field for the user to type a new message.

### EditComposer.Footer

The footer of the edit composer.

### EditComposer.Cancel

Sends a cancel action.

### EditComposer.Send

Sends the message.

## AssistantModal

Renders the assistant modal.

```tsx
import {
  AssistantModal,
  Thread,
  type ThreadConfig,
} from "@assistant-ui/react-ui";

const MyAssistantModal: FC<ThreadConfig> = (config) => {
  return (
    <AssistantModal.Root config={config}>
      <AssistantModal.Trigger />
      <AssistantModal.Content>
        <Thread />
      </AssistantModal.Content>
    </AssistantModal.Root>
  );
};
```

**Usage:**

```ts
<MyAssistantModal />
```

## ThreadList

Renders a thread list.

```tsx
import { ThreadList, ThreadListItem } from "@assistant-ui/react-ui";

const MyThreadList = () => {
  return (
    <ThreadList.Root>
      <ThreadList.New />
      <ThreadList.Items />
    </ThreadList.Root>
  );
};
```

### ThreadListItem

Renders a thread list item.

```tsx
import { ThreadListItem, ThreadListItemPrimitive } from "@assistant-ui/react-ui";

const MyThreadListItem = () => {
  return (
    <ThreadListItem.Root>
      <ThreadListItemTrigger>
        <ThreadListItemTitle />
      </ThreadListItemTrigger>
      <ThreadListItem.Archive />
    </ThreadListItem.Root>
  );
};
```


file: ./content/docs/legacy/styled/Markdown.mdx
# Markdown


        
Allow the assistant to display rich text using markdown.

import { Step, Steps } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";
import { Tabs } from "fumadocs-ui/components/tabs";

## Enabling markdown support

<Steps>
  <Step>
    ### Install `@assistant-ui/react-markdown`

    ```sh npm2yarn
    npm install @assistant-ui/react-markdown
    ```
  </Step>

  <Step>
    ### Setup styles

    <Tabs items={["Tailwind", "Tailwind + shadcn-ui", "Not using Tailwind"]}>
      ```ts {3} title="/tailwind.config.ts" tab="Tailwind"
      {
        plugins: [
          require("tailwindcss-animate"),
          require("@assistant-ui/react-ui/tailwindcss")
        ],
      }
      ```

      ```ts title="/tailwind.config.ts" tab="Tailwind + shadcn-ui"
      {
        plugins: [
          require("tailwindcss-animate"),
          require("@assistant-ui/react-ui/tailwindcss")({ shadcn: true })
        ],
      }
      ```

      ```ts title="/app/layout.tsx" tab="Not using Tailwind"
      import "@assistant-ui/react-ui/styles/index.css";
      import "@assistant-ui/react-ui/styles/markdown.css";
      ```
    </Tabs>
  </Step>

  <Step>
    ### Define a `MarkdownText` component

    ```tsx {1} title="@/components/markdown-text.tsx"
    import { makeMarkdownText } from "@assistant-ui/react-ui";

    export const MarkdownText = makeMarkdownText();
    ```
  </Step>

  <Step>
    ### Use it with `Thread`

    Pass the `MarkdownText` component to your `Thread` component.

    ```tsx {1, 7}
    import { MarkdownText } from "@/components/markdown-text";

    const Home = () => {
      return (
        <Thread assistantMessage={{ components: { Text: MarkdownText } }}>
      );
    };
    ```
  </Step>
</Steps>


file: ./content/docs/legacy/styled/Scrollbar.mdx
# Custom Scrollbar


        
If you want to show a custom scrollbar UI of the Thread.Viewport in place of the system default, you can integrate `@radix-ui/react-scroll-area`.
An example implementation of this is [shadcn-ui's Scroll Area](https://ui.shadcn.com/docs/components/scroll-area).

## Add shadcn Scroll Area

```sh
npx shadcn@latest add scroll-area
```

### @radix-ui/react-scroll-area v1.2.0 release candidate required

The v1.2.0-rc.x release candidate can be installed via

```sh
pnpm add @radix-ui/react-scroll-area@next
```

## Additional Styles

The radix-ui Viewport component adds an intermediate `<div data-radix-scroll-area-content>` element.
Add the following CSS to your `globals.css`:

```css title="@/app/globals.css"
.aui-thread-viewport > [data-radix-scroll-area-content] {
  @apply flex flex-col items-center self-stretch bg-inherit;
}
```

## Integration

* Decompose `Thread` into `MyThread` (see [Decomposition](/docs/legacy/styled/Decomposition))
* Wrap `Thread.Root` with `<ScrollAreaPrimitive.Root asChild>`
* Wrap `Thread.Viewport` with `<ScrollAreaPrimitive.Viewport asChild>`
* Add shadcn's `<ScrollBar />` to `Thread.Root`

The resulting MyThread component should look like this:

```tsx
import {
  Thread,
  ThreadWelcome,
  Composer,
  type ThreadConfig,
} from "@assistant-ui/react-ui";
import * as ScrollAreaPrimitive from "@radix-ui/react-scroll-area"; // [!code highlight]
import { ScrollBar } from "@/components/ui/scroll-area"; // [!code highlight]

const MyThread: FC<ThreadConfig> = (config) => {
  return (
    <ScrollAreaPrimitive.Root asChild> /* [!code highlight] */
      <Thread.Root config={config}>
        <ScrollAreaPrimitive.Viewport asChild> /* [!code highlight] */
          <Thread.Viewport>
            <ThreadWelcome />
            <Thread.Messages />
            <Thread.ViewportFooter>
              <Thread.ScrollToBottom />
              <Composer />
            </Thread.ViewportFooter>
          </Thread.Viewport>
        </ScrollAreaPrimitive.Viewport> /* [!code highlight] */
        <ScrollBar /> /* [!code highlight] */
      </Thread.Root>
    </ScrollAreaPrimitive.Root> /* [!code highlight] */
  );
};
```


file: ./content/docs/legacy/styled/Thread.mdx
# Thread


        
import { Steps, Step } from "fumadocs-ui/components/steps";
import { Tabs, Tab } from "fumadocs-ui/components/tabs";

## Overview

The raw message list and message composer UI. Useful for full screen chat use cases.

## Getting Started

<Steps>
  <Step>
    ### Install `@assistant-ui/react-ui`

    ```sh npm2yarn
    npm install @assistant-ui/react-ui
    ```
  </Step>

  <Step>
    ### Import CSS styles

    Add the following to your `tailwind.config.ts`:

    <Tabs items={["Tailwind", "Tailwind + shadcn-ui", "Not using Tailwind"]}>
      ```ts title="/tailwind.config.ts" tab="Tailwind"
      {
        plugins: [
          require("tailwindcss-animate"), // make sure to "npm install tailwindcss-animate"
          require("@assistant-ui/react-ui/tailwindcss")({
            components: ["thread"],
          })
        ],
      }
      ```

      ```ts title="/tailwind.config.ts" tab="Tailwind + shadcn-ui"
      {
        plugins: [
          require("tailwindcss-animate"), // make sure to "npm install tailwindcss-animate"
          require("@assistant-ui/react-ui/tailwindcss")({
            components: ["thread"],
            shadcn: true
          })
        ],
      }
      ```

      ```ts title="/app/layout.tsx" tab="Not using Tailwind"
      import "@assistant-ui/react-ui/styles/index.css";
      ```
    </Tabs>
  </Step>

  <Step>
    ### Use it in your app

    ```tsx title="/app/page.tsx"
    import { useChatRuntime } from "@assistant-ui/react-ai-sdk";
    import { Thread } from "@assistant-ui/react-ui";

    const MyApp = () => {
      const runtime = useChatRuntime({
        api: "/api/chat",
      });

      return (
        <div className="h-full">
          <Thread runtime={runtime} />
        </div>
      );
    };
    ```
  </Step>
</Steps>


file: ./content/docs/legacy/styled/ThreadWidth.mdx
# Thread Width


        
You can modify the max width of the thread via the CSS variable `--aui-thread-max-width`.

## Wider Thread

```css title="@/app/globals.css"
:root {
  --aui-thread-max-width: 600px;
}
```

## Take up the whole screen

```css title="@/app/globals.css"
:root {
  --aui-thread-max-width: infinity;
}
```


file: ./content/docs/runtimes/ai-sdk/rsc.mdx
# Vercel AI SDK RSC Runtime


        
## Overview

Integration with the Vercel AI SDK React Server Components. It allows streaming React components directly from the server.\
Integrates with OpenAI, Anthropic, Mistral, Perplexity, AWS Bedrock, Azure, Google Gemini, Hugging Face, Fireworks, Cohere, LangChain, Replicate, Ollama, and more.

## Example

[RSC Example App](https://assistant-ui-rsc-example.vercel.app/)

## Getting Started

import { Steps, Step } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";

<Steps>
  <Step>
    ### Create a Next.JS project

    ```sh
    npx create-next-app@latest my-app
    cd my-app
    ```
  </Step>

  <Step>
    ### Install Vercel AI SDK and `@assistant-ui/react-ai-sdk`

    ```sh npm2yarn
    npm install @assistant-ui/react @assistant-ui/react-ai-sdk ai @ai-sdk/openai zod nanoid
    ```
  </Step>

  <Step>
    ### Setup `actions.tsx`

    `@/app/actions.tsx`

    ```tsx
    "use server";

    import { createAI, getMutableAIState, streamUI } from "ai/rsc";
    import { openai } from "@ai-sdk/openai";
    import { ReactNode } from "react";
    import { z } from "zod";
    import { nanoid } from "nanoid";

    export interface ServerMessage {
      role: "user" | "assistant";
      content: string;
    }

    export interface ClientMessage {
      id: string;
      role: "user" | "assistant";
      display: ReactNode;
    }

    export async function continueConversation(
      input: string,
    ): Promise<ClientMessage> {
      "use server";

      const history = getMutableAIState();

      const result = await streamUI({
        model: openai("gpt-3.5-turbo"),
        messages: [...history.get(), { role: "user", content: input }],
        text: ({ content, done }) => {
          if (done) {
            history.done((messages: ServerMessage[]) => [
              ...messages,
              { role: "assistant", content },
            ]);
          }

          return <div>{content}</div>;
        },
        tools: {
          deploy: {
            description: "Deploy repository to vercel",
            parameters: z.object({
              repositoryName: z
                .string()
                .describe("The name of the repository, example: vercel/ai-chatbot"),
            }),
            generate: async function* ({ repositoryName }) {
              yield <div>Cloning repository {repositoryName}...</div>; // [!code highlight:5]
              await new Promise((resolve) => setTimeout(resolve, 3000));
              yield <div>Building repository {repositoryName}...</div>;
              await new Promise((resolve) => setTimeout(resolve, 2000));
              return <div>{repositoryName} deployed!</div>;
            },
          },
        },
      });

      return {
        id: nanoid(),
        role: "assistant",
        display: result.value,
      };
    }

    export const AI = createAI<ServerMessage[], ClientMessage[]>({
      actions: {
        continueConversation,
      },
      initialAIState: [],
      initialUIState: [],
    });
    ```
  </Step>

  <Step>
    ### Define a `MyRuntimeProvider` component

    `@/app/MyRuntimeProvider.tsx`

    ```tsx
    "use client";

    import {
      type AppendMessage,
      AssistantRuntimeProvider,
    } from "@assistant-ui/react";
    import { useVercelRSCRuntime } from "@assistant-ui/react-ai-sdk";
    import { useActions, useUIState } from "ai/rsc";
    import { nanoid } from "nanoid";

    import type { AI } from "./actions";

    export function MyRuntimeProvider({
      children,
    }: Readonly<{
      children: React.ReactNode;
    }>) {
      const { continueConversation } = useActions();
      const [messages, setMessages] = useUIState<typeof AI>();

      const onNew = async (m: AppendMessage) => {
        if (m.content[0]?.type !== "text")
          throw new Error("Only text messages are supported");

        const input = m.content[0].text;
        setMessages((currentConversation) => [
          ...currentConversation,
          { id: nanoid(), role: "user", display: input },
        ]);

        const message = await continueConversation(input);

        setMessages((currentConversation) => [...currentConversation, message]);
      };

      const runtime = useVercelRSCRuntime({ messages, onNew });

      return (
        <AssistantRuntimeProvider runtime={runtime}>
          {children}
        </AssistantRuntimeProvider>
      );
    }
    ```
  </Step>

  <Step>
    ### Wrap your app in `AI` and `MyRuntimeProvider`

    `@/app/layout.tsx`

    ```tsx {1-2,12-13,19-20}
    import { AI } from '@/app/actions';
    import { MyRuntimeProvider } from '@/app/MyRuntimeProvider';

    ...

    export default function RootLayout({
      children,
    }: Readonly<{
      children: React.ReactNode;
    }>) {
      return (
        <AI>
          <MyRuntimeProvider>
            <html lang="en">
              <body className={inter.className}>
                {children}
              </body>
            </html>
          </MyRuntimeProvider>
        </AI>
      )
    }
    ```
  </Step>
</Steps>

## Set up RSCDisplay

Pass the `RSCDisplay` component to your `MessagePrimitive.Content`:

```tsx
<MessagePrimitive.Content components={{ Text: RSCDisplay }} />
```

(if you are using react-ui: `<Thread assistantMessage={{ components: { Text: RSCDisplay } }} />`)

## Accessing AI SDK Messages

You can use the `getExternalStoreMessages` utility to convert `ThreadMessage`s back to your message format.

```tsx
const MyAssistantMessage = () => {
  const myMessage = useMessage((m) => getExternalStoreMessages(m)[0]);
  // ...
};
```


file: ./content/docs/runtimes/ai-sdk/use-assistant-hook.mdx
# useAssistant Hook Integration


        
## Overview

Integration with the Vercel AI SDK UI's `useAssistant` hook.\
This allows interaction with the OpenAI Assistants API.

## Getting Started

import { Steps, Step } from "fumadocs-ui/components/steps";

<Steps>
  <Step>
    ### Create a Next.JS project

    ```sh
    npx create-next-app@latest my-app
    cd my-app
    ```
  </Step>

  <Step>
    ### Install Vercel AI SDK and `@assistant-ui/react-ai-sdk`

    ```sh npm2yarn
    npm install @assistant-ui/react @assistant-ui/react-ai-sdk ai openai
    ```
  </Step>

  <Step>
    ### Setup a backend route under `/api/assistant`

    `/app/api/assistant/route.ts`

    ```tsx
    import { AssistantResponse } from "ai";
    import OpenAI from "openai";
    import type { Run } from "openai/resources/beta/threads/runs/runs";

    const openai = new OpenAI();

    // Allow streaming responses up to 30 seconds
    export const maxDuration = 30;

    export async function POST(req: Request) {
      // Parse the request body
      const input: {
        threadId: string | null;
        message: string;
      } = await req.json();

      // Create a thread if needed
      const threadId = input.threadId ?? (await openai.beta.threads.create({})).id;

      // Add a message to the thread
      const createdMessage = await openai.beta.threads.messages.create(threadId, {
        role: "user",
        content: input.message,
      });

      return AssistantResponse(
        { threadId, messageId: createdMessage.id },
        async ({ forwardStream, sendDataMessage }) => {
          // Run the assistant on the thread
          const runStream = openai.beta.threads.runs.stream(threadId, {
            assistant_id:
              process.env.ASSISTANT_ID ??
              (() => {
                throw new Error("ASSISTANT_ID is not set");
              })(),
          });

          // forward run status would stream message deltas
          let runResult: Run = await forwardStream(runStream);

          // status can be: queued, in_progress, requires_action, cancelling, cancelled, failed, completed, or expired
          while (
            runResult?.status === "requires_action" &&
            runResult.required_action?.type === "submit_tool_outputs"
          ) {
            const tool_outputs =
              runResult.required_action.submit_tool_outputs.tool_calls.map(
                (toolCall: any) => {
                  const parameters = JSON.parse(toolCall.function.arguments);

                  switch (toolCall.function.name) {
                    // configure your tool calls here

                    default:
                      throw new Error(
                        `Unknown tool call function: ${toolCall.function.name}`,
                      );
                  }
                },
              );

            runResult = await forwardStream(
              openai.beta.threads.runs.submitToolOutputsStream(
                threadId,
                runResult.id,
                { tool_outputs },
              ),
            );
          }
        },
      );
    }
    ```
  </Step>

  <Step>
    ### Define a `MyRuntimeProvider` component

    `@/app/MyRuntimeProvider.tsx`

    ```tsx
    "use client";

    import { useAssistant } from "@ai-sdk/react";
    import { AssistantRuntimeProvider } from "@assistant-ui/react";
    import { useVercelUseAssistantRuntime } from "@assistant-ui/react-ai-sdk";

    export function MyRuntimeProvider({
      children,
    }: Readonly<{
      children: React.ReactNode;
    }>) {
      const assistant = useAssistant({
        api: "/api/assistant",
      });

      const runtime = useVercelUseAssistantRuntime(assistant);

      return (
        <AssistantRuntimeProvider runtime={runtime}>
          {children}
        </AssistantRuntimeProvider>
      );
    }
    ```
  </Step>

  <Step>
    ### Wrap your app in `MyRuntimeProvider`

    `@/app/layout.tsx`

    ```tsx {1,11,17}
    import { MyRuntimeProvider } from '@/app/MyRuntimeProvider';

    ...

    export default function RootLayout({
      children,
    }: Readonly<{
      children: React.ReactNode;
    }>) {
      return (
        <MyRuntimeProvider>
          <html lang="en">
            <body className={inter.className}>
              {children}
            </body>
          </html>
        </MyRuntimeProvider>
      )
    }
    ```
  </Step>
</Steps>

## Accessing AI SDK Messages

You can use `getExternalStoreMessages` utility to convert `ThreadMessage`s back to `Message`s from AI SDK.

```tsx
const MyAssistantMessage = () => {
  const aiSDKMessages = useMessage((m) => getExternalStoreMessages(m));
  // ...
};

const WeatherToolUI = makeAssistantToolUI({
  render: () => {
    const aiSDKMessage = useContentPart((p) => getExternalStoreMessages(p)[0]);
    // ...
  },
});
```


file: ./content/docs/runtimes/ai-sdk/use-chat-hook.mdx
# useChat Hook Integration (Legacy)


        
## Overview

Integration with the Vercel AI SDK UI's `useChat` hook.\
It allows integration with OpenAI, Anthropic, Mistral, Perplexity, AWS Bedrock, Azure, Google Gemini, Hugging Face, Fireworks, Cohere, LangChain, Replicate, Ollama, and more.

## Getting Started

import { Steps, Step } from "fumadocs-ui/components/steps";

<Steps>
  <Step>
    ### Create a Next.JS project

    ```sh
    npx create-next-app@latest my-app
    cd my-app
    ```
  </Step>

  <Step>
    ### Install Vercel AI SDK and `@assistant-ui/react`

    ```sh npm2yarn
    npm install @assistant-ui/react @assistant-ui/react-ai-sdk ai @ai-sdk/openai
    ```
  </Step>

  <Step>
    ### Setup a backend route under `/api/chat`

    `@/app/api/chat/route.ts`

    ```tsx
    import { openai } from "@ai-sdk/openai";
    import { streamText } from "ai";

    export const maxDuration = 30;

    export async function POST(req: Request) {
      const { messages } = await req.json();

      const result = streamText({
        model: openai("gpt-4o"),
        messages: convertToCoreMessages(messages),
      });

      return result.toDataStreamResponse();
    }
    ```
  </Step>

  <Step>
    ### Define a `MyRuntimeProvider` component

    `@/app/MyRuntimeProvider.tsx`

    ```tsx
    "use client";

    import { useChat } from "@ai-sdk/react";
    import { AssistantRuntimeProvider } from "@assistant-ui/react";
    import { useVercelUseChatRuntime } from "@assistant-ui/react-ai-sdk";

    export function MyRuntimeProvider({
      children,
    }: Readonly<{
      children: React.ReactNode;
    }>) {
      const chat = useChat({
        api: "/api/chat",
      });

      const runtime = useVercelUseChatRuntime(chat);

      return (
        <AssistantRuntimeProvider runtime={runtime}>
          {children}
        </AssistantRuntimeProvider>
      );
    }
    ```
  </Step>

  <Step>
    ### Wrap your app in `MyRuntimeProvider`

    `@/app/layout.tsx`

    ```tsx {1,11,17}
    import { MyRuntimeProvider } from '@/app/MyRuntimeProvider';

    ...

    export default function RootLayout({
      children,
    }: Readonly<{
      children: React.ReactNode;
    }>) {
      return (
        <MyRuntimeProvider>
          <html lang="en">
            <body className={inter.className}>
              {children}
            </body>
          </html>
        </MyRuntimeProvider>
      )
    }
    ```
  </Step>
</Steps>

## Accessing AI SDK Messages

You can use the `getExternalStoreMessages` utility to convert `ThreadMessage`s back to `Message`s from AI SDK.

```tsx
const MyAssistantMessage = () => {
  const aiSDKMessages = useMessage((m) => getExternalStoreMessages(m));
  // ...
};

const WeatherToolUI = makeAssistantToolUI({
  render: () => {
    const aiSDKMessage = useContentPart((p) => getExternalStoreMessages(p)[0]);
    // ...
  },
});
```


file: ./content/docs/runtimes/ai-sdk/use-chat.mdx
# useChatRuntime


        
## Overview

Integration with the Vercel AI SDK UI's `useChat` hook.\
It allows integration with OpenAI, Anthropic, Mistral, Perplexity, AWS Bedrock, Azure, Google Gemini, Hugging Face, Fireworks, Cohere, LangChain, Replicate, Ollama, and more.

## Getting Started

import { Steps, Step } from "fumadocs-ui/components/steps";

<Steps>
  <Step>
    ### Create a Next.JS project

    ```sh
    npx create-next-app@latest my-app
    cd my-app
    ```
  </Step>

  <Step>
    ### Install Vercel AI SDK and `@assistant-ui/react`

    ```sh npm2yarn
    npm install @assistant-ui/react @assistant-ui/react-ai-sdk ai @ai-sdk/openai
    ```
  </Step>

  <Step>
    ### Setup a backend route under `/api/chat`

    `@/app/api/chat/route.ts`

    ```tsx
    import { openai } from "@ai-sdk/openai";
    import { streamText } from "ai";

    export const maxDuration = 30;

    export async function POST(req: Request) {
      const { messages } = await req.json();

      const result = streamText({
        model: openai("gpt-4o"),
        messages: convertToCoreMessages(messages),
      });

      return result.toDataStreamResponse();
    }
    ```
  </Step>

  <Step>
    ### Define a `MyRuntimeProvider` component

    `@/app/MyRuntimeProvider.tsx`

    ```tsx
    "use client";

    import { useChat } from "@ai-sdk/react";
    import { AssistantRuntimeProvider } from "@assistant-ui/react";
    import { useChatRuntime } from "@assistant-ui/react-ai-sdk";

    export function MyRuntimeProvider({
      children,
    }: Readonly<{
      children: React.ReactNode;
    }>) {
      const runtime = useChatRuntime({
        api: "/api/chat",
      });

      return (
        <AssistantRuntimeProvider runtime={runtime}>
          {children}
        </AssistantRuntimeProvider>
      );
    }
    ```
  </Step>

  <Step>
    ### Wrap your app in `MyRuntimeProvider`

    `@/app/layout.tsx`

    ```tsx {1,11,17}
    import { MyRuntimeProvider } from '@/app/MyRuntimeProvider';

    ...

    export default function RootLayout({
      children,
    }: Readonly<{
      children: React.ReactNode;
    }>) {
      return (
        <MyRuntimeProvider>
          <html lang="en">
            <body className={inter.className}>
              {children}
            </body>
          </html>
        </MyRuntimeProvider>
      )
    }
    ```
  </Step>
</Steps>

## Accessing AI SDK Messages

You can use the `getExternalStoreMessages` utility to convert `ThreadMessage`s back to `Message`s from AI SDK.

```tsx
const MyAssistantMessage = () => {
  const aiSDKMessages = useMessage((m) => getExternalStoreMessages(m));
  // ...
};

const WeatherToolUI = makeAssistantToolUI({
  render: () => {
    const aiSDKMessage = useContentPart((p) => getExternalStoreMessages(p)[0]);
    // ...
  },
});
```


file: ./content/docs/runtimes/custom/external-store.mdx
# ExternalStoreRuntime


        
import { Callout } from "fumadocs-ui/components/callout";
import { Steps, Step } from "fumadocs-ui/components/steps";
import { Card, Cards } from "fumadocs-ui/components/card";
import { ParametersTable } from "@/components/docs";

## Overview

`ExternalStoreRuntime` bridges your existing state management with assistant-ui components. It requires an `ExternalStoreAdapter<TMessage>` that handles communication between your state and the UI.

**Key differences from `LocalRuntime`:**

* **You own the state** - Full control over message state, thread management, and persistence logic
* **Bring your own state management** - Works with Redux, Zustand, TanStack Query, or any React state library
* **Custom message formats** - Use your backend's message structure with automatic conversion

<Callout type="warn">
  `ExternalStoreRuntime` gives you total control over state (persist, sync,
  share), but you must wire up every callback.
</Callout>

## Example Implementation

```tsx twoslash title="app/MyRuntimeProvider.tsx"
type MyMessage = {
  role: "user" | "assistant";
  content: string;
};
const backendApi = async (input: string): Promise<MyMessage> => {
  return { role: "assistant", content: "Hello, world!" };
};

// ---cut---
import { useState, ReactNode } from "react";
import {
  useExternalStoreRuntime,
  ThreadMessageLike,
  AppendMessage,
  AssistantRuntimeProvider,
} from "@assistant-ui/react";

const convertMessage = (message: MyMessage): ThreadMessageLike => {
  return {
    role: message.role,
    content: [{ type: "text", text: message.content }],
  };
};

export function MyRuntimeProvider({
  children,
}: Readonly<{
  children: ReactNode;
}>) {
  const [isRunning, setIsRunning] = useState(false);
  const [messages, setMessages] = useState<MyMessage[]>([]);

  const onNew = async (message: AppendMessage) => {
    if (message.content[0]?.type !== "text")
      throw new Error("Only text messages are supported");

    const input = message.content[0].text;
    setMessages((currentConversation) => [
      ...currentConversation,
      { role: "user", content: input },
    ]);

    setIsRunning(true);
    const assistantMessage = await backendApi(input);
    setMessages((currentConversation) => [
      ...currentConversation,
      assistantMessage,
    ]);
    setIsRunning(false);
  };

  const runtime = useExternalStoreRuntime({
    isRunning,
    messages,
    convertMessage,
    onNew,
  });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
}
```

## When to Use

Use `ExternalStoreRuntime` if you need:

* **Full control over message state** - Manage messages with Redux, Zustand, TanStack Query, or any React state management library
* **Custom multi-thread implementation** - Build your own thread management system with custom storage
* **Integration with existing state** - Keep chat state in your existing state management solution
* **Custom message formats** - Use your backend's message structure with automatic conversion
* **Complex synchronization** - Sync messages with external data sources, databases, or multiple clients
* **Custom persistence logic** - Implement your own storage patterns and caching strategies

## Key Features

<Cards>
  <Card title="State Management Integration" description="Works seamlessly with Redux, Zustand, TanStack Query, and more" />

  <Card title="Message Conversion" description="Automatic conversion between your message format and assistant-ui's format" />

  <Card title="Real-time Streaming" description="Built-in support for streaming responses and progressive updates" />

  <Card title="Thread Management" description="Multi-conversation support with archiving and thread switching" />
</Cards>

## Architecture

### How It Works

`ExternalStoreRuntime` acts as a bridge between your state management and assistant-ui:

```mermaid
graph TD
    A[Your State Management] -->|messages| B[ExternalStoreAdapter]
    B --> C[ExternalStoreRuntime]
    C --> D[assistant-ui Components]
    D -->|user actions| B
    B -->|state updates| A
```

### Key Concepts

1. **State Ownership** - You own and control all message state
2. **Adapter Pattern** - The adapter translates between your state and assistant-ui
3. **Capability-Based Features** - UI features are enabled based on which handlers you provide
4. **Message Conversion** - Automatic conversion between your message format and assistant-ui's format
5. **Optimistic Updates** - Built-in handling for streaming and loading states

## Getting Started

<Steps>
  <Step>
    ### Install Dependencies

    ```sh npm2yarn
    npm install @assistant-ui/react
    ```
  </Step>

  <Step>
    ### Create Runtime Provider

    ```tsx title="app/MyRuntimeProvider.tsx"
    "use client";

    import { useState } from "react";
    import {
      useExternalStoreRuntime,
      ThreadMessageLike,
      AppendMessage,
      AssistantRuntimeProvider,
    } from "@assistant-ui/react";

    export function MyRuntimeProvider({ children }) {
      const [messages, setMessages] = useState<ThreadMessageLike[]>([]);
      const [isRunning, setIsRunning] = useState(false);

      const onNew = async (message: AppendMessage) => {
        // Add user message
        const userMessage: ThreadMessageLike = {
          role: "user",
          content: message.content,
        };
        setMessages(prev => [...prev, userMessage]);

        // Generate response
        setIsRunning(true);
        const response = await callYourAPI(message);

        const assistantMessage: ThreadMessageLike = {
          role: "assistant",
          content: response.content,
        };
        setMessages(prev => [...prev, assistantMessage]);
        setIsRunning(false);
      };

      const runtime = useExternalStoreRuntime({
        messages,
        setMessages,
        isRunning,
        onNew,
      });

      return (
        <AssistantRuntimeProvider runtime={runtime}>
          {children}
        </AssistantRuntimeProvider>
      );
    }
    ```
  </Step>

  <Step>
    ### Use in Your App

    ```tsx title="app/page.tsx"
    import { Thread } from "@assistant-ui/react";
    import { MyRuntimeProvider } from "./MyRuntimeProvider";

    export default function Page() {
      return (
        <MyRuntimeProvider>
          <Thread />
        </MyRuntimeProvider>
      );
    }
    ```
  </Step>
</Steps>

## Implementation Patterns

### Message Conversion

Two approaches for converting your message format:

#### 1. Simple Conversion (Recommended)

```tsx
const convertMessage = (message: MyMessage): ThreadMessageLike => ({
  role: message.role,
  content: [{ type: "text", text: message.text }],
  id: message.id,
  createdAt: new Date(message.timestamp),
});

const runtime = useExternalStoreRuntime({
  messages: myMessages,
  convertMessage,
  onNew,
});
```

#### 2. Advanced Conversion with `useExternalMessageConverter`

For complex scenarios with performance optimization:

```tsx
import { useExternalMessageConverter } from "@assistant-ui/react";

const convertedMessages = useExternalMessageConverter({
  messages,
  convertMessage: (message: MyMessage): ThreadMessageLike => ({
    role: message.role,
    content: [{ type: "text", text: message.text }],
    id: message.id,
    createdAt: new Date(message.timestamp),
  }),
  joinStrategy: "concat-content", // Merge adjacent assistant messages
});

const runtime = useExternalStoreRuntime({
  messages: convertedMessages,
  onNew,
  // No convertMessage needed - already converted
});
```

### Join Strategy

Controls how adjacent assistant messages are combined:

* **`concat-content`** (default): Merges adjacent assistant messages into one
* **`none`**: Keeps all messages separate

This is useful when your backend sends multiple message chunks that should appear as a single message in the UI.

<Callout type="info">
  `useExternalMessageConverter` provides performance optimization for complex
  message conversion scenarios. For simpler cases, consider using the basic
  `convertMessage` approach shown above.
</Callout>

### Essential Handlers

#### Basic Chat (onNew only)

```tsx
const runtime = useExternalStoreRuntime({
  messages,
  onNew: async (message) => {
    // Add user message to state
    const userMsg = { role: "user", content: message.content };
    setMessages([...messages, userMsg]);

    // Get AI response
    const response = await callAI(message);
    setMessages([...messages, userMsg, response]);
  },
});
```

#### Full-Featured Chat

```tsx
const runtime = useExternalStoreRuntime({
  messages,
  setMessages, // Enables branch switching
  onNew, // Required
  onEdit, // Enables message editing
  onReload, // Enables regeneration
  onCancel, // Enables cancellation
});
```

<Callout type="info">
  Each handler you provide enables specific UI features: - `setMessages` 
  Branch switching - `onEdit`  Message editing - `onReload`  Regenerate button

  * `onCancel`  Cancel button during generation
</Callout>

### Streaming Responses

Implement real-time streaming with progressive updates:

```tsx
const onNew = async (message: AppendMessage) => {
  // Add user message
  const userMessage: ThreadMessageLike = {
    role: "user",
    content: message.content,
    id: generateId(),
  };
  setMessages((prev) => [...prev, userMessage]);

  // Create placeholder for assistant message
  setIsRunning(true);
  const assistantId = generateId();
  const assistantMessage: ThreadMessageLike = {
    role: "assistant",
    content: [{ type: "text", text: "" }],
    id: assistantId,
  };
  setMessages((prev) => [...prev, assistantMessage]);

  // Stream response
  const stream = await api.streamChat(message);
  for await (const chunk of stream) {
    setMessages((prev) =>
      prev.map((m) =>
        m.id === assistantId
          ? {
              ...m,
              content: [
                {
                  type: "text",
                  text: (m.content[0] as any).text + chunk,
                },
              ],
            }
          : m,
      ),
    );
  }
  setIsRunning(false);
};
```

### Message Editing

Enable message editing by implementing the `onEdit` handler:

<Callout type="info">
  You can also implement `onEdit(editedMessage)` and `onRemove(messageId)`
  callbacks to handle user-initiated edits or deletions in your external store.
  This enables features like "edit and re-run" on your backend.
</Callout>

```tsx
const onEdit = async (message: AppendMessage) => {
  // Find the index where to insert the edited message
  const index = messages.findIndex((m) => m.id === message.parentId) + 1;

  // Keep messages up to the parent
  const newMessages = [...messages.slice(0, index)];

  // Add the edited message
  const editedMessage: ThreadMessageLike = {
    role: "user",
    content: message.content,
    id: message.id || generateId(),
  };
  newMessages.push(editedMessage);

  setMessages(newMessages);

  // Generate new response
  setIsRunning(true);
  const response = await api.chat(message);
  newMessages.push({
    role: "assistant",
    content: response.content,
    id: generateId(),
  });
  setMessages(newMessages);
  setIsRunning(false);
};
```

### Tool Calling

Support tool calls with proper result handling:

```tsx
const onAddToolResult = (options: AddToolResultOptions) => {
  setMessages((prev) =>
    prev.map((message) => {
      if (message.id === options.messageId) {
        // Update the specific tool call with its result
        return {
          ...message,
          content: message.content.map((part) => {
            if (
              part.type === "tool-call" &&
              part.toolCallId === options.toolCallId
            ) {
              return {
                ...part,
                result: options.result,
              };
            }
            return part;
          }),
        };
      }
      return message;
    }),
  );
};

const runtime = useExternalStoreRuntime({
  messages,
  onNew,
  onAddToolResult,
  // ... other props
});
```

#### Automatic Tool Result Matching

The runtime automatically matches tool results with their corresponding tool calls. When messages are converted and joined:

1. **Tool Call Tracking** - The runtime tracks tool calls by their `toolCallId`
2. **Result Association** - Tool results are automatically associated with their corresponding calls
3. **Message Grouping** - Related tool messages are intelligently grouped together

```tsx
// Example: Tool call and result in separate messages
const messages = [
  {
    role: "assistant",
    content: [
      {
        type: "tool-call",
        toolCallId: "call_123",
        toolName: "get_weather",
        args: { location: "San Francisco" },
      },
    ],
  },
  {
    role: "tool",
    content: [
      {
        type: "tool-result",
        toolCallId: "call_123",
        result: { temperature: 72, condition: "sunny" },
      },
    ],
  },
];

// These are automatically matched and grouped by the runtime
```

### File Attachments

Enable file uploads with the attachment adapter:

```tsx
const attachmentAdapter: AttachmentAdapter = {
  accept: "image/*,application/pdf,.txt,.md",
  async add(file) {
    // Upload file to your server
    const formData = new FormData();
    formData.append("file", file);

    const response = await fetch("/api/upload", {
      method: "POST",
      body: formData,
    });

    const { id, url } = await response.json();
    return {
      id,
      type: "document",
      name: file.name,
      file,
      url,
    };
  },
  async remove(attachment) {
    // Remove file from server
    await fetch(`/api/upload/${attachment.id}`, {
      method: "DELETE",
    });
  },
};

const runtime = useExternalStoreRuntime({
  messages,
  onNew,
  adapters: {
    attachments: attachmentAdapter,
  },
});
```

### Thread Management

#### Managing Thread Context

When implementing multi-thread support with `ExternalStoreRuntime`, you need to carefully manage thread context across your application. Here's a comprehensive approach:

```tsx
// Create a context for thread management
const ThreadContext = createContext<{
  currentThreadId: string;
  setCurrentThreadId: (id: string) => void;
  threads: Map<string, ThreadMessageLike[]>;
  setThreads: React.Dispatch<
    React.SetStateAction<Map<string, ThreadMessageLike[]>>
  >;
}>({
  currentThreadId: "default",
  setCurrentThreadId: () => {},
  threads: new Map(),
  setThreads: () => {},
});

// Thread provider component
export function ThreadProvider({ children }: { children: ReactNode }) {
  const [threads, setThreads] = useState<Map<string, ThreadMessageLike[]>>(
    new Map([["default", []]]),
  );
  const [currentThreadId, setCurrentThreadId] = useState("default");

  return (
    <ThreadContext.Provider
      value={{ currentThreadId, setCurrentThreadId, threads, setThreads }}
    >
      {children}
    </ThreadContext.Provider>
  );
}

// Hook for accessing thread context
export function useThreadContext() {
  const context = useContext(ThreadContext);
  if (!context) {
    throw new Error("useThreadContext must be used within ThreadProvider");
  }
  return context;
}
```

#### Complete Thread Implementation

Here's a full implementation with proper context management:

```tsx
function ChatWithThreads() {
  const { currentThreadId, setCurrentThreadId, threads, setThreads } =
    useThreadContext();
  const [threadList, setThreadList] = useState<ExternalStoreThreadData[]>([
    { threadId: "default", status: "regular", title: "New Chat" },
  ]);

  // Get messages for current thread
  const currentMessages = threads.get(currentThreadId) || [];

  const threadListAdapter: ExternalStoreThreadListAdapter = {
    threadId: currentThreadId,
    threads: threadList.filter((t) => t.status === "regular"),
    archivedThreads: threadList.filter((t) => t.status === "archived"),

    onSwitchToNewThread: () => {
      const newId = `thread-${Date.now()}`;
      setThreadList((prev) => [
        ...prev,
        {
          threadId: newId,
          status: "regular",
          title: "New Chat",
        },
      ]);
      setThreads((prev) => new Map(prev).set(newId, []));
      setCurrentThreadId(newId);
    },

    onSwitchToThread: (threadId) => {
      setCurrentThreadId(threadId);
    },

    onRename: (threadId, newTitle) => {
      setThreadList((prev) =>
        prev.map((t) =>
          t.threadId === threadId ? { ...t, title: newTitle } : t,
        ),
      );
    },

    onArchive: (threadId) => {
      setThreadList((prev) =>
        prev.map((t) =>
          t.threadId === threadId ? { ...t, status: "archived" } : t,
        ),
      );
    },

    onDelete: (threadId) => {
      setThreadList((prev) => prev.filter((t) => t.threadId !== threadId));
      setThreads((prev) => {
        const next = new Map(prev);
        next.delete(threadId);
        return next;
      });
      if (currentThreadId === threadId) {
        setCurrentThreadId("default");
      }
    },
  };

  const runtime = useExternalStoreRuntime({
    messages: currentMessages,
    setMessages: (messages) => {
      setThreads((prev) => new Map(prev).set(currentThreadId, messages));
    },
    onNew: async (message) => {
      // Handle new message for current thread
      // Your implementation here
    },
    adapters: {
      threadList: threadListAdapter,
    },
  });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      <ThreadList />
      <Thread />
    </AssistantRuntimeProvider>
  );
}

// App component with proper context wrapping
export function App() {
  return (
    <ThreadProvider>
      <ChatWithThreads />
    </ThreadProvider>
  );
}
```

#### Thread Context Best Practices

<Callout type="info">
  **Critical**: When using `ExternalStoreRuntime` with threads, the
  `currentThreadId` must be consistent across all components and handlers.
  Mismatched thread IDs will cause messages to appear in wrong threads or
  disappear entirely.
</Callout>

1. **Centralize Thread State**: Always use a context or global state management solution to ensure thread ID consistency:

```tsx
//  Bad: Local state in multiple components
function ThreadList() {
  const [currentThreadId, setCurrentThreadId] = useState("default");
  // This won't sync with the runtime!
}

//  Good: Shared context
function ThreadList() {
  const { currentThreadId, setCurrentThreadId } = useThreadContext();
  // Thread ID is synchronized everywhere
}
```

2. **Sync Thread Changes**: Ensure all thread-related operations update both the thread ID and messages:

```tsx
//  Bad: Only updating thread ID
onSwitchToThread: (threadId) => {
  setCurrentThreadId(threadId);
  // Messages won't update!
};

//  Good: Complete state update
onSwitchToThread: (threadId) => {
  setCurrentThreadId(threadId);
  // Messages automatically update via currentMessages = threads.get(currentThreadId)
};
```

3. **Handle Edge Cases**: Always provide fallbacks for missing threads:

```tsx
// Ensure thread always exists
const currentMessages = threads.get(currentThreadId) || [];

// Initialize new threads properly
const initializeThread = (threadId: string) => {
  if (!threads.has(threadId)) {
    setThreads((prev) => new Map(prev).set(threadId, []));
  }
};
```

4. **Persist Thread State**: For production apps, sync thread state with your backend:

```tsx
// Save thread state to backend
useEffect(() => {
  const saveThread = async () => {
    await api.saveThread(currentThreadId, threads.get(currentThreadId) || []);
  };

  const debounced = debounce(saveThread, 1000);
  debounced();

  return () => debounced.cancel();
}, [currentThreadId, threads]);
```

## Integration Examples

### Redux Integration

```tsx title="app/chatSlice.ts"
// Using Redux Toolkit (recommended)
import { createSlice, PayloadAction } from "@reduxjs/toolkit";
import { ThreadMessageLike } from "@assistant-ui/react";

interface ChatState {
  messages: ThreadMessageLike[];
  isRunning: boolean;
}

const chatSlice = createSlice({
  name: "chat",
  initialState: {
    messages: [] as ThreadMessageLike[],
    isRunning: false,
  },
  reducers: {
    setMessages: (state, action: PayloadAction<ThreadMessageLike[]>) => {
      state.messages = action.payload;
    },
    addMessage: (state, action: PayloadAction<ThreadMessageLike>) => {
      state.messages.push(action.payload);
    },
    setIsRunning: (state, action: PayloadAction<boolean>) => {
      state.isRunning = action.payload;
    },
  },
});

export const { setMessages, addMessage, setIsRunning } = chatSlice.actions;
export const selectMessages = (state: RootState) => state.chat.messages;
export const selectIsRunning = (state: RootState) => state.chat.isRunning;
export default chatSlice.reducer;

// ReduxRuntimeProvider.tsx
import { useSelector, useDispatch } from "react-redux";
import {
  selectMessages,
  selectIsRunning,
  addMessage,
  setMessages,
  setIsRunning,
} from "./chatSlice";

export function ReduxRuntimeProvider({ children }) {
  const messages = useSelector(selectMessages);
  const isRunning = useSelector(selectIsRunning);
  const dispatch = useDispatch();

  const runtime = useExternalStoreRuntime({
    messages,
    isRunning,
    setMessages: (messages) => dispatch(setMessages(messages)),
    onNew: async (message) => {
      // Add user message
      dispatch(
        addMessage({
          role: "user",
          content: message.content,
          id: `msg-${Date.now()}`,
          createdAt: new Date(),
        }),
      );

      // Generate response
      dispatch(setIsRunning(true));
      const response = await api.chat(message);
      dispatch(
        addMessage({
          role: "assistant",
          content: response.content,
          id: `msg-${Date.now()}`,
          createdAt: new Date(),
        }),
      );
      dispatch(setIsRunning(false));
    },
  });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
}
```

### Zustand Integration (v5)

```tsx title="app/chatStore.ts"
// Using Zustand v5 with TypeScript
import { create } from "zustand";
import { immer } from "zustand/middleware/immer";
import { ThreadMessageLike } from "@assistant-ui/react";

interface ChatState {
  messages: ThreadMessageLike[];
  isRunning: boolean;
  addMessage: (message: ThreadMessageLike) => void;
  setMessages: (messages: ThreadMessageLike[]) => void;
  setIsRunning: (isRunning: boolean) => void;
  updateMessage: (id: string, updates: Partial<ThreadMessageLike>) => void;
}

// Zustand v5 requires the extra parentheses for TypeScript
const useChatStore = create<ChatState>()(
  immer((set) => ({
    messages: [],
    isRunning: false,

    addMessage: (message) =>
      set((state) => {
        state.messages.push(message);
      }),

    setMessages: (messages) =>
      set((state) => {
        state.messages = messages;
      }),

    setIsRunning: (isRunning) =>
      set((state) => {
        state.isRunning = isRunning;
      }),

    updateMessage: (id, updates) =>
      set((state) => {
        const index = state.messages.findIndex((m) => m.id === id);
        if (index !== -1) {
          Object.assign(state.messages[index], updates);
        }
      }),
  })),
);

// ZustandRuntimeProvider.tsx
import { useShallow } from "zustand/shallow";

export function ZustandRuntimeProvider({ children }) {
  // Use useShallow to prevent unnecessary re-renders
  const { messages, isRunning, addMessage, setMessages, setIsRunning } =
    useChatStore(
      useShallow((state) => ({
        messages: state.messages,
        isRunning: state.isRunning,
        addMessage: state.addMessage,
        setMessages: state.setMessages,
        setIsRunning: state.setIsRunning,
      })),
    );

  const runtime = useExternalStoreRuntime({
    messages,
    isRunning,
    setMessages,
    onNew: async (message) => {
      // Add user message
      addMessage({
        role: "user",
        content: message.content,
        id: `msg-${Date.now()}`,
        createdAt: new Date(),
      });

      // Generate response
      setIsRunning(true);
      const response = await api.chat(message);
      addMessage({
        role: "assistant",
        content: response.content,
        id: `msg-${Date.now()}-assistant`,
        createdAt: new Date(),
      });
      setIsRunning(false);
    },
  });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
}
```

### TanStack Query Integration

```tsx title="app/chatQueries.ts"
// Using TanStack Query v5 with TypeScript
import { useQuery, useMutation, useQueryClient } from "@tanstack/react-query";
import { ThreadMessageLike, AppendMessage } from "@assistant-ui/react";

// Query key factory pattern
export const messageKeys = {
  all: ["messages"] as const,
  thread: (threadId: string) => [...messageKeys.all, threadId] as const,
};

// TanStackQueryRuntimeProvider.tsx
export function TanStackQueryRuntimeProvider({ children }) {
  const queryClient = useQueryClient();
  const threadId = "main"; // Or from context/props

  const { data: messages = [] } = useQuery({
    queryKey: messageKeys.thread(threadId),
    queryFn: () => fetchMessages(threadId),
    staleTime: 1000 * 60 * 5, // Consider data fresh for 5 minutes
  });

  const sendMessage = useMutation({
    mutationFn: api.chat,

    // Optimistic updates with proper TypeScript types
    onMutate: async (message: AppendMessage) => {
      // Cancel any outgoing refetches
      await queryClient.cancelQueries({
        queryKey: messageKeys.thread(threadId),
      });

      // Snapshot the previous value
      const previousMessages = queryClient.getQueryData<ThreadMessageLike[]>(
        messageKeys.thread(threadId),
      );

      // Optimistically update with typed data
      const optimisticMessage: ThreadMessageLike = {
        role: "user",
        content: message.content,
        id: `temp-${Date.now()}`,
        createdAt: new Date(),
      };

      queryClient.setQueryData<ThreadMessageLike[]>(
        messageKeys.thread(threadId),
        (old = []) => [...old, optimisticMessage],
      );

      return { previousMessages, tempId: optimisticMessage.id };
    },

    onSuccess: (response, variables, context) => {
      // Replace optimistic message with real data
      queryClient.setQueryData<ThreadMessageLike[]>(
        messageKeys.thread(threadId),
        (old = []) => {
          // Remove temp message and add real ones
          return old
            .filter((m) => m.id !== context?.tempId)
            .concat([
              {
                role: "user",
                content: variables.content,
                id: `user-${Date.now()}`,
                createdAt: new Date(),
              },
              response,
            ]);
        },
      );
    },

    onError: (error, variables, context) => {
      // Rollback to previous messages on error
      if (context?.previousMessages) {
        queryClient.setQueryData(
          messageKeys.thread(threadId),
          context.previousMessages,
        );
      }
    },

    onSettled: () => {
      // Always refetch after error or success
      queryClient.invalidateQueries({
        queryKey: messageKeys.thread(threadId),
      });
    },
  });

  const runtime = useExternalStoreRuntime({
    messages,
    isRunning: sendMessage.isPending,
    onNew: async (message) => {
      await sendMessage.mutateAsync(message);
    },
    // Enable message editing
    setMessages: (newMessages) => {
      queryClient.setQueryData(messageKeys.thread(threadId), newMessages);
    },
  });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
}
```

## Key Features

### Automatic Optimistic Updates

When `isRunning` becomes true, the runtime automatically shows an optimistic assistant message:

```tsx
// Your code
setIsRunning(true);

// Runtime automatically:
// 1. Shows empty assistant message with "in_progress" status
// 2. Displays typing indicator
// 3. Updates status to "complete" when isRunning becomes false
```

### Message Status Management

Assistant messages get automatic status updates:

* `"in_progress"` - When `isRunning` is true
* `"complete"` - When `isRunning` becomes false
* `"cancelled"` - When cancelled via `onCancel`

### Tool Result Matching

The runtime automatically matches tool results with their calls:

```tsx
// Tool call and result can be in separate messages
const messages = [
  {
    role: "assistant",
    content: [
      {
        type: "tool-call",
        toolCallId: "call_123",
        toolName: "get_weather",
        args: { location: "SF" },
      },
    ],
  },
  {
    role: "tool",
    content: [
      {
        type: "tool-result",
        toolCallId: "call_123",
        result: { temp: 72 },
      },
    ],
  },
];
// Runtime automatically associates these
```

## Working with External Messages

### Converting Back to Your Format

Use `getExternalStoreMessages` to access your original messages:

```tsx
import { getExternalStoreMessages } from "@assistant-ui/react";

const MyComponent = () => {
  const originalMessages = useMessage((m) => getExternalStoreMessages(m));
  // originalMessages is MyMessage[] (your original type)
};
```

<Callout type="info">
  After the chat finishes, use `getExternalStoreMessages(runtime)` to convert
  back to your domain model. Refer to the API reference for return structures
  and edge-case behaviors.
</Callout>

<Callout type="warning">
  `getExternalStoreMessages` may return multiple messages for a single UI
  message. This happens because assistant-ui merges adjacent assistant and tool
  messages for display.
</Callout>

### Content Part Access

```tsx
const ToolUI = makeAssistantToolUI({
  render: () => {
    const originalMessages = useContentPart((p) => getExternalStoreMessages(p));
    // Access original message data for this content part
  },
});
```

## Debugging

### Common Debugging Scenarios

```tsx
// Debug message conversion
const convertMessage = (message: MyMessage): ThreadMessageLike => {
  console.log("Converting message:", message);
  const converted = {
    role: message.role,
    content: [{ type: "text", text: message.content }],
  };
  console.log("Converted to:", converted);
  return converted;
};

// Debug adapter calls
const onNew = async (message: AppendMessage) => {
  console.log("onNew called with:", message);
  // ... implementation
};

// Enable verbose logging
const runtime = useExternalStoreRuntime({
  messages,
  onNew: (...args) => {
    console.log("Runtime onNew:", args);
    return onNew(...args);
  },
  // ... other props
});
```

## Best Practices

### 1. Immutable Updates

Always create new arrays when updating messages:

```tsx
//  Wrong - mutating array
messages.push(newMessage);
setMessages(messages);

//  Correct - new array
setMessages([...messages, newMessage]);
```

### 2. Stable Handler References

Memoize handlers to prevent runtime recreation:

```tsx
const onNew = useCallback(
  async (message: AppendMessage) => {
    // Handle new message
  },
  [
    /* dependencies */
  ],
);

const runtime = useExternalStoreRuntime({
  messages,
  onNew, // Stable reference
});
```

### 3. Performance Optimization

```tsx
// For large message lists
const recentMessages = useMemo(
  () => messages.slice(-50), // Show last 50 messages
  [messages],
);

// For expensive conversions
const convertMessage = useCallback((msg) => {
  // Conversion logic
}, []);
```

## `LocalRuntime` vs `ExternalStoreRuntime`

### When to Choose Which

| Scenario                         | Recommendation                                               |
| -------------------------------- | ------------------------------------------------------------ |
| Quick prototype                  | `LocalRuntime`                                               |
| Using Redux/Zustand              | `ExternalStoreRuntime`                                       |
| Need Assistant Cloud integration | `LocalRuntime`                                               |
| Custom thread storage            | Both (`LocalRuntime` with adapter or `ExternalStoreRuntime`) |
| Simple single thread             | `LocalRuntime`                                               |
| Complex state logic              | `ExternalStoreRuntime`                                       |

### Feature Comparison

| Feature          | `LocalRuntime`              | `ExternalStoreRuntime` |
| ---------------- | --------------------------- | ---------------------- |
| State Management | Built-in                    | You provide            |
| Multi-thread     | Via Cloud or custom adapter | Via adapter            |
| Message Format   | ThreadMessage               | Any (with conversion)  |
| Setup Complexity | Low                         | Medium                 |
| Flexibility      | Medium                      | High                   |

## Common Pitfalls

<Callout type="error">
  **Features not appearing**: Each UI feature requires its corresponding handler:

  ```tsx
  //  No edit button
  const runtime = useExternalStoreRuntime({ messages, onNew });

  //  Edit button appears
  const runtime = useExternalStoreRuntime({ messages, onNew, onEdit });
  ```
</Callout>

<Callout type="warning">
  **State not updating**: Common causes:

  1. Mutating arrays instead of creating new ones
  2. Missing `setMessages` for branch switching
  3. Not handling async operations properly
  4. Incorrect message format conversion
</Callout>

### Debugging Checklist

* Are you creating new arrays when updating messages?
* Did you provide all required handlers for desired features?
* Is your `convertMessage` returning valid `ThreadMessageLike`?
* Are you properly handling `isRunning` state?
* For threads: Is your thread list adapter complete?

### Thread-Specific Debugging

Common thread context issues and solutions:

**Messages disappearing when switching threads:**

```tsx
// Check 1: Ensure currentThreadId is consistent
console.log("Runtime threadId:", threadListAdapter.threadId);
console.log("Current threadId:", currentThreadId);
console.log("Messages for thread:", threads.get(currentThreadId));

// Check 2: Verify setMessages uses correct thread
setMessages: (messages) => {
  console.log("Setting messages for thread:", currentThreadId);
  setThreads((prev) => new Map(prev).set(currentThreadId, messages));
};
```

**Thread list not updating:**

```tsx
// Ensure threadList state is properly managed
onSwitchToNewThread: () => {
  const newId = `thread-${Date.now()}`;
  console.log("Creating new thread:", newId);

  // All three updates must happen together
  setThreadList((prev) => [...prev, newThreadData]);
  setThreads((prev) => new Map(prev).set(newId, []));
  setCurrentThreadId(newId);
};
```

**Messages going to wrong thread:**

```tsx
// Add validation to prevent race conditions
const validateThreadContext = () => {
  const runtimeThread = threadListAdapter.threadId;
  const contextThread = currentThreadId;

  if (runtimeThread !== contextThread) {
    console.error("Thread mismatch!", { runtimeThread, contextThread });
    throw new Error("Thread context mismatch");
  }
};

// Call before any message operation
onNew: async (message) => {
  validateThreadContext();
  // ... handle message
};
```

## API Reference

### `ExternalStoreAdapter`

The main interface for connecting your state to assistant-ui.

<ParametersTable
  type="ExternalStoreAdapter<T>"
  parameters={[
  {
    name: "messages",
    type: "readonly T[]",
    description: "Array of messages from your state",
    required: true,
  },
  {
    name: "onNew",
    type: "(message: AppendMessage) => Promise<void>",
    description: "Handler for new messages from the user",
    required: true,
  },
  {
    name: "isRunning",
    type: "boolean",
    description:
      "Whether the assistant is currently generating a response. When true, shows optimistic assistant message",
    default: "false",
  },
  {
    name: "isDisabled",
    type: "boolean",
    description: "Whether the chat input should be disabled",
    default: "false",
  },
  {
    name: "suggestions",
    type: "readonly ThreadSuggestion[]",
    description: "Suggested prompts to display",
  },
  {
    name: "extras",
    type: "unknown",
    description: "Additional data accessible via runtime.extras",
  },
  {
    name: "setMessages",
    type: "(messages: T[]) => void",
    description: "Update messages (required for branch switching)",
  },
  {
    name: "onEdit",
    type: "(message: AppendMessage) => Promise<void>",
    description: "Handler for message edits (required for edit feature)",
  },
  {
    name: "onReload",
    type: "(parentId: string | null, config: StartRunConfig) => Promise<void>",
    description:
      "Handler for regenerating messages (required for reload feature)",
  },
  {
    name: "onCancel",
    type: "() => Promise<void>",
    description: "Handler for cancelling the current generation",
  },
  {
    name: "onAddToolResult",
    type: "(options: AddToolResultOptions) => Promise<void> | void",
    description: "Handler for adding tool call results",
  },
  {
    name: "convertMessage",
    type: "(message: T, index: number) => ThreadMessageLike",
    description:
      "Convert your message format to assistant-ui format. Not needed if using ThreadMessage type",
  },
  {
    name: "joinStrategy",
    type: '"concat-content" | "none"',
    description: "How to join adjacent assistant messages when converting",
    default: '"concat-content"',
  },
  {
    name: "adapters",
    type: "object",
    description: "Feature adapters (same as LocalRuntime)",
    children: [
      {
        type: "adapters",
        parameters: [
          {
            name: "attachments",
            type: "AttachmentAdapter",
            description: "Enable file attachments",
          },
          {
            name: "speech",
            type: "SpeechSynthesisAdapter",
            description: "Enable text-to-speech",
          },
          {
            name: "feedback",
            type: "FeedbackAdapter",
            description: "Enable message feedback",
          },
          {
            name: "threadList",
            type: "ExternalStoreThreadListAdapter",
            description: "Enable multi-thread management",
          },
        ],
      },
    ],
  },
  {
    name: "unstable_capabilities",
    type: "object",
    description: "Configure runtime capabilities",
    children: [
      {
        type: "unstable_capabilities",
        parameters: [
          {
            name: "copy",
            type: "boolean",
            description: "Enable message copy feature",
            default: "true",
          },
        ],
      },
    ],
  },
]}
/>

### `ThreadMessageLike`

A flexible message format that can be converted to assistant-ui's internal format.

<ParametersTable
  type="ThreadMessageLike"
  parameters={[
  {
    name: "role",
    type: '"assistant" | "user" | "system"',
    description: "The role of the message sender",
    required: true,
  },
  {
    name: "content",
    type: "string | readonly ContentPart[]",
    description: "Message content as string or structured content parts",
    required: true,
  },
  {
    name: "id",
    type: "string",
    description: "Unique identifier for the message",
  },
  {
    name: "createdAt",
    type: "Date",
    description: "Timestamp when the message was created",
  },
  {
    name: "status",
    type: "MessageStatus",
    description:
      "Status of assistant messages (in_progress, complete, cancelled)",
  },
  {
    name: "attachments",
    type: "readonly CompleteAttachment[]",
    description: "File attachments (user messages only)",
  },
  {
    name: "metadata",
    type: "object",
    description: "Additional message metadata",
    children: [
      {
        type: "metadata",
        parameters: [
          {
            name: "steps",
            type: "readonly ThreadStep[]",
            description: "Tool call steps for assistant messages",
          },
          {
            name: "custom",
            type: "Record<string, unknown>",
            description: "Custom metadata for your application",
          },
        ],
      },
    ],
  },
]}
/>

### `ExternalStoreThreadListAdapter`

Enable multi-thread support with custom thread management.

<ParametersTable
  type="ExternalStoreThreadListAdapter"
  parameters={[
  {
    name: "threadId",
    type: "string",
    description: "ID of the current active thread",
  },
  {
    name: "threads",
    type: "readonly ExternalStoreThreadData[]",
    description: "Array of regular threads with { threadId, title }",
  },
  {
    name: "archivedThreads",
    type: "readonly ExternalStoreThreadData[]",
    description: "Array of archived threads",
  },
  {
    name: "onSwitchToNewThread",
    type: "() => Promise<void> | void",
    description: "Handler for creating a new thread",
  },
  {
    name: "onSwitchToThread",
    type: "(threadId: string) => Promise<void> | void",
    description: "Handler for switching to an existing thread",
  },
  {
    name: "onRename",
    type: "(threadId: string, newTitle: string) => Promise<void> | void",
    description: "Handler for renaming a thread",
  },
  {
    name: "onArchive",
    type: "(threadId: string) => Promise<void> | void",
    description: "Handler for archiving a thread",
  },
  {
    name: "onUnarchive",
    type: "(threadId: string) => Promise<void> | void",
    description: "Handler for unarchiving a thread",
  },
  {
    name: "onDelete",
    type: "(threadId: string) => Promise<void> | void",
    description: "Handler for deleting a thread",
  },
]}
/>

<Callout type="info">
  The thread list adapter enables multi-thread support. Without it, the runtime
  only manages the current conversation.
</Callout>

### Related Runtime APIs

* [AssistantRuntime API](/docs/api-reference/runtimes/AssistantRuntime) - Core runtime interface and methods
* [ThreadRuntime API](/docs/api-reference/runtimes/ThreadRuntime) - Thread-specific operations and state management
* [Runtime Providers](/docs/api-reference/context-providers/AssistantRuntimeProvider) - Context providers for runtime integration

## Related Resources

* [Runtime Layer Concepts](/docs/concepts/runtime-layer)
* [Pick a Runtime Guide](/docs/runtimes/pick-a-runtime)
* [`LocalRuntime` Documentation](/docs/runtimes/custom/local)
* [Examples Repository](https://github.com/assistant-ui/assistant-ui/tree/main/examples/with-external-store)


file: ./content/docs/runtimes/custom/local.mdx
# LocalRuntime


        
import { Callout } from "fumadocs-ui/components/callout";
import { Steps, Step } from "fumadocs-ui/components/steps";
import { Card, Cards } from "fumadocs-ui/components/card";
import { ParametersTable } from "@/components/docs";

## Overview

`LocalRuntime` is the simplest way to connect your own custom backend to assistant-ui. It manages all chat state internally while providing a clean adapter interface to connect with any REST API, OpenAI, or custom language model.

`LocalRuntime` provides:

* **Built-in state management** for messages, threads, and conversation history
* **Automatic features** like message editing, reloading, and branch switching
* **Multi-thread support** through [Assistant Cloud](/docs/cloud/overview) or your own database using `useRemoteThreadListRuntime`
* **Simple adapter pattern** to connect any backend API

While LocalRuntime manages state in-memory by default, it offers multiple persistence options through adapters - use the history adapter for single-thread persistence, Assistant Cloud for managed multi-thread support, or implement your own storage with `useRemoteThreadListRuntime`.

## When to Use

Use `LocalRuntime` if you need:

* **Quick setup with minimal configuration** - Get a fully functional chat interface with just a few lines of code
* **Built-in state management** - No need to manage messages, threads, or conversation history yourself
* **Automatic features** - Branch switching, message editing, and regeneration work out of the box
* **API flexibility** - Connect to any REST endpoint, OpenAI, or custom model with a simple adapter
* **Multi-thread support** - Full thread management with Assistant Cloud or custom database
* **Thread persistence** - Via history adapter, Assistant Cloud, or custom thread list adapter

## Key Features

<Cards>
  <Card title="Built-in State Management" description="Automatic handling of messages, threads, and conversation history" />

  <Card title="Multi-Thread Support" description="Full thread management capabilities with Assistant Cloud or custom database adapter" />

  <Card title="Adapter System" description="Extend with attachments, speech, feedback, persistence, and suggestions" />

  <Card title="Tool Calling" description="Support for function calling with human-in-the-loop approval" />
</Cards>

## Getting Started

<Steps>
  <Step>
    ### Create a Next.js project

    ```sh
    npx create-next-app@latest my-app
    cd my-app
    ```
  </Step>

  <Step>
    ### Install `@assistant-ui/react`

    ```sh npm2yarn
    npm install @assistant-ui/react
    ```
  </Step>

  <Step>
    ### Define a `MyRuntimeProvider` component

    Update the `MyModelAdapter` below to integrate with your own custom API.
    See `LocalRuntimeOptions` [API Reference](#localruntimeoptions) for available configuration options.

    ```tsx twoslash include MyRuntimeProvider title="app/MyRuntimeProvider.tsx"
    // @filename: /app/MyRuntimeProvider.tsx

    // ---cut---
    "use client";

    import type { ReactNode } from "react";
    import {
      AssistantRuntimeProvider,
      useLocalRuntime,
      type ChatModelAdapter,
    } from "@assistant-ui/react";

    const MyModelAdapter: ChatModelAdapter = {
      async run({ messages, abortSignal }) {
        // TODO replace with your own API
        const result = await fetch("<YOUR_API_ENDPOINT>", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          // forward the messages in the chat to the API
          body: JSON.stringify({
            messages,
          }),
          // if the user hits the "cancel" button or escape keyboard key, cancel the request
          signal: abortSignal,
        });

        const data = await result.json();
        return {
          content: [
            {
              type: "text",
              text: data.text,
            },
          ],
        };
      },
    };

    export function MyRuntimeProvider({
      children,
    }: Readonly<{
      children: ReactNode;
    }>) {
      const runtime = useLocalRuntime(MyModelAdapter);

      return (
        <AssistantRuntimeProvider runtime={runtime}>
          {children}
        </AssistantRuntimeProvider>
      );
    }
    ```
  </Step>

  <Step>
    ### Wrap your app in `MyRuntimeProvider`

    ```tsx {1,11,17} twoslash title="app/layout.tsx"
    // @include: MyRuntimeProvider
    // @filename: /app/layout.tsx
    // ---cut---
    import type { ReactNode } from "react";
    import { MyRuntimeProvider } from "@/app/MyRuntimeProvider";

    export default function RootLayout({
      children,
    }: Readonly<{
      children: ReactNode;
    }>) {
      return (
        <MyRuntimeProvider>
          <html lang="en">
            <body>{children}</body>
          </html>
        </MyRuntimeProvider>
      );
    }
    ```
  </Step>

  <Step>
    ### Use the Thread component

    ```tsx title="app/page.tsx"
    import { Thread } from "@assistant-ui/react";

    export default function Page() {
      return <Thread />;
    }
    ```
  </Step>
</Steps>

## Streaming Responses

Implement streaming by declaring the `run` function as an `AsyncGenerator`.

```tsx twoslash {2, 11-13} title="app/MyRuntimeProvider.tsx"
import {
  ChatModelAdapter,
  ThreadMessage,
  type ModelContext,
} from "@assistant-ui/react";
import { OpenAI } from "openai";

const openai = new OpenAI();
const backendApi = async ({
  messages,
  abortSignal,
  context,
}: {
  messages: readonly ThreadMessage[];
  abortSignal: AbortSignal;
  context: ModelContext;
}) => {
  return openai.chat.completions.create({
    model: "gpt-4o",
    messages: [{ role: "user", content: "Say this is a test" }],
    stream: true,
  });
};

// ---cut---
const MyModelAdapter: ChatModelAdapter = {
  async *run({ messages, abortSignal, context }) {
    const stream = await backendApi({ messages, abortSignal, context });

    let text = "";
    for await (const part of stream) {
      text += part.choices[0]?.delta?.content || "";

      yield {
        content: [{ type: "text", text }],
      };
    }
  },
};
```

### Streaming with Tool Calls

Handle streaming responses that include function calls:

```tsx
const MyModelAdapter: ChatModelAdapter = {
  async *run({ messages, abortSignal, context }) {
    const stream = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: convertToOpenAIMessages(messages),
      tools: context.tools,
      stream: true,
      signal: abortSignal,
    });

    let content = "";
    const toolCalls: any[] = [];

    for await (const chunk of stream) {
      const delta = chunk.choices[0]?.delta;

      // Handle text content
      if (delta?.content) {
        content += delta.content;
      }

      // Handle tool calls
      if (delta?.tool_calls) {
        for (const toolCall of delta.tool_calls) {
          if (!toolCalls[toolCall.index]) {
            toolCalls[toolCall.index] = {
              id: toolCall.id,
              type: "function",
              function: { name: "", arguments: "" },
            };
          }

          if (toolCall.function?.name) {
            toolCalls[toolCall.index].function.name = toolCall.function.name;
          }

          if (toolCall.function?.arguments) {
            toolCalls[toolCall.index].function.arguments +=
              toolCall.function.arguments;
          }
        }
      }

      // Yield current state
      yield {
        content: [
          ...(content ? [{ type: "text" as const, text: content }] : []),
          ...toolCalls.map((tc) => ({
            type: "tool-call" as const,
            toolCallId: tc.id,
            toolName: tc.function.name,
            args: JSON.parse(tc.function.arguments || "{}"),
          })),
        ],
      };
    }
  },
};
```

## Tool Calling

`LocalRuntime` supports OpenAI-compatible function calling with automatic or human-in-the-loop execution.

### Basic Tool Definition

```tsx
const tools = [
  {
    type: "function",
    function: {
      name: "get_weather",
      description: "Get the current weather in a location",
      parameters: {
        type: "object",
        properties: {
          location: {
            type: "string",
            description: "The city and state, e.g. San Francisco, CA",
          },
          unit: {
            type: "string",
            enum: ["celsius", "fahrenheit"],
          },
        },
        required: ["location"],
      },
    },
  },
];

const runtime = useLocalRuntime(MyModelAdapter, {
  // Tools are passed via context
  context: { tools },
});
```

### Human-in-the-Loop Approval

Require user confirmation before executing certain tools:

```tsx
const runtime = useLocalRuntime(MyModelAdapter, {
  unstable_humanToolNames: ["delete_file", "send_email"],
});
```

### Tool Execution

Tools are executed automatically by the runtime. The model adapter receives tool results in subsequent messages:

```tsx
// Messages will include tool calls and results:
[
  { role: "user", content: "What's the weather in SF?" },
  {
    role: "assistant",
    content: [
      {
        type: "tool-call",
        toolCallId: "call_123",
        toolName: "get_weather",
        args: { location: "San Francisco, CA" },
      },
    ],
  },
  {
    role: "tool",
    content: [
      {
        type: "tool-result",
        toolCallId: "call_123",
        result: { temperature: 72, condition: "sunny" },
      },
    ],
  },
  {
    role: "assistant",
    content: "The weather in San Francisco is sunny and 72F.",
  },
];
```

## Multi-Thread Support

`LocalRuntime` supports multiple conversation threads through two approaches:

### 1. Assistant Cloud Integration

```tsx
import { useLocalRuntime } from "@assistant-ui/react";
import { AssistantCloud } from "assistant-cloud";

const cloud = new AssistantCloud({
  apiKey: process.env.ASSISTANT_CLOUD_API_KEY,
});

const runtime = useLocalRuntime(MyModelAdapter, {
  cloud, // Enables multi-thread support
});
```

With Assistant Cloud, you get:

* Multiple conversation threads
* Thread persistence across sessions
* Thread management (create, switch, rename, archive, delete)
* Automatic synchronization across devices
* Built-in user authentication

### 2. Custom Database with useRemoteThreadListRuntime

For custom thread storage, use `useRemoteThreadListRuntime` with your own adapter:

```tsx
import {
  useLocalThreadRuntime,
  unstable_useRemoteThreadListRuntime as useRemoteThreadListRuntime,
  useThreadListItem,
  RuntimeAdapterProvider,
  AssistantRuntimeProvider,
  type RemoteThreadListAdapter,
  type ThreadHistoryAdapter,
} from "@assistant-ui/react";

// Implement your custom adapter with proper message persistence
const myDatabaseAdapter: RemoteThreadListAdapter = {
  async list() {
    const threads = await db.threads.findAll();
    return {
      threads: threads.map((t) => ({
        status: t.archived ? "archived" : "regular",
        remoteId: t.id,
        title: t.title,
      })),
    };
  },

  async initialize(threadId) {
    const thread = await db.threads.create({ id: threadId });
    return { remoteId: thread.id };
  },

  async rename(remoteId, newTitle) {
    await db.threads.update(remoteId, { title: newTitle });
  },

  async archive(remoteId) {
    await db.threads.update(remoteId, { archived: true });
  },

  async unarchive(remoteId) {
    await db.threads.update(remoteId, { archived: false });
  },

  async delete(remoteId) {
    // Delete thread and its messages
    await db.messages.deleteByThreadId(remoteId);
    await db.threads.delete(remoteId);
  },

  async generateTitle(remoteId, messages) {
    // Generate title from messages using your AI
    const title = await generateTitle(messages);
    await db.threads.update(remoteId, { title });
    return new ReadableStream(); // Return empty stream
  },
};

// Complete implementation with message persistence using Provider pattern
export function MyRuntimeProvider({ children }) {
  const runtime = useRemoteThreadListRuntime({
    runtimeHook: () => {
      return useLocalThreadRuntime(MyModelAdapter);
    },
    adapter: {
      ...myDatabaseAdapter,

      // The Provider component adds thread-specific adapters
      unstable_Provider: ({ children }) => {
        // This runs in the context of each thread
        const threadListItem = useThreadListItem();
        const remoteId = threadListItem.remoteId;

        // Create thread-specific history adapter
        const history = useMemo<ThreadHistoryAdapter>(
          () => ({
            async load() {
              if (!remoteId) return { messages: [] };

              const messages = await db.messages.findByThreadId(remoteId);
              return {
                messages: messages.map((m) => ({
                  role: m.role,
                  content: m.content,
                  id: m.id,
                  createdAt: new Date(m.createdAt),
                })),
              };
            },

            async append(message) {
              if (!remoteId) {
                console.warn("Cannot save message - thread not initialized");
                return;
              }

              await db.messages.create({
                threadId: remoteId,
                role: message.role,
                content: message.content,
                id: message.id,
                createdAt: message.createdAt,
              });
            },
          }),
          [remoteId],
        );

        const adapters = useMemo(() => ({ history }), [history]);

        return (
          <RuntimeAdapterProvider adapters={adapters}>
            {children}
          </RuntimeAdapterProvider>
        );
      },
    },
  });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
}
```

#### Understanding the Architecture

<Callout type="info">
  **Key Insight**: The `unstable_Provider` component in your adapter runs in the
  context of each thread, giving you access to thread-specific information like
  `remoteId`. This is where you add the history adapter for message persistence.
</Callout>

The complete multi-thread implementation requires:

1. **RemoteThreadListAdapter** - Manages thread metadata (list, create, rename, archive, delete)
2. **unstable\_Provider** - Component that provides thread-specific adapters (like history)
3. **ThreadHistoryAdapter** - Persists messages for each thread (load, append)
4. **runtimeHook** - Creates a basic `LocalRuntime` (adapters are added by Provider)

Without the history adapter, threads would have no message persistence, making them effectively useless. The Provider pattern allows you to add thread-specific functionality while keeping the runtime creation simple.

#### Database Schema Example

```typescript
// Example database schema for thread persistence
interface ThreadRecord {
  id: string;
  title: string;
  archived: boolean;
  createdAt: Date;
  updatedAt: Date;
}

interface MessageRecord {
  id: string;
  threadId: string;
  role: "user" | "assistant" | "system";
  content: any; // Store as JSON
  createdAt: Date;
}
```

Both approaches provide full multi-thread support. Choose Assistant Cloud for a managed solution or implement your own adapter for custom storage requirements.

## Adapters

Extend `LocalRuntime` capabilities with adapters. The runtime automatically enables/disables UI features based on which adapters are provided.

### Attachment Adapter

Enable file and image uploads:

```tsx
const attachmentAdapter: AttachmentAdapter = {
  accept: "image/*,application/pdf",
  async add(file) {
    const formData = new FormData();
    formData.append("file", file);

    const response = await fetch("/api/upload", {
      method: "POST",
      body: formData,
    });

    const { id, url } = await response.json();
    return {
      id,
      type: file.type.startsWith("image/") ? "image" : "document",
      name: file.name,
      url,
    };
  },
  async remove(attachment) {
    await fetch(`/api/upload/${attachment.id}`, {
      method: "DELETE",
    });
  },
};

const runtime = useLocalRuntime(MyModelAdapter, {
  adapters: { attachments: attachmentAdapter },
});

// For multiple file types, use CompositeAttachmentAdapter:
const runtime = useLocalRuntime(MyModelAdapter, {
  adapters: {
    attachments: new CompositeAttachmentAdapter([
      new SimpleImageAttachmentAdapter(),
      new SimpleTextAttachmentAdapter(),
      customPDFAdapter,
    ]),
  },
});
```

### Thread History Adapter

Persist and resume conversations:

```tsx
const historyAdapter: ThreadHistoryAdapter = {
  async load() {
    // Load messages from your storage
    const response = await fetch(`/api/thread/current`);
    const { messages } = await response.json();
    return { messages };
  },

  async append(message) {
    // Save new message to storage
    await fetch(`/api/thread/messages`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ message }),
    });
  },

  // Optional: Resume interrupted conversations
  async resume({ messages }) {
    const lastMessage = messages[messages.length - 1];
    if (lastMessage?.role === "user") {
      // Resume generating assistant response
      const response = await fetch("/api/chat/resume", {
        method: "POST",
        body: JSON.stringify({ messages }),
      });
      return response.body; // Return stream
    }
  },
};

const runtime = useLocalRuntime(MyModelAdapter, {
  adapters: { history: historyAdapter },
});
```

<Callout type="info">
  The history adapter handles persistence for the current thread's messages. For
  multi-thread support with custom storage, use either
  `useRemoteThreadListRuntime` with `LocalRuntime` or `ExternalStoreRuntime`
  with a thread list adapter.
</Callout>

### Speech Synthesis Adapter

Add text-to-speech capabilities:

```tsx
const speechAdapter: SpeechSynthesisAdapter = {
  speak(text) {
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.rate = 1.0;
    utterance.pitch = 1.0;
    speechSynthesis.speak(utterance);
  },

  stop() {
    speechSynthesis.cancel();
  },
};

const runtime = useLocalRuntime(MyModelAdapter, {
  adapters: { speech: speechAdapter },
});
```

### Feedback Adapter

Collect user feedback on messages:

```tsx
const feedbackAdapter: FeedbackAdapter = {
  async submit(feedback) {
    await fetch("/api/feedback", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        messageId: feedback.messageId,
        rating: feedback.type, // "positive" or "negative"
      }),
    });
  },
};

const runtime = useLocalRuntime(MyModelAdapter, {
  adapters: { feedback: feedbackAdapter },
});
```

### Suggestion Adapter

Provide follow-up suggestions:

```tsx
const suggestionAdapter: SuggestionAdapter = {
  async *get({ messages }) {
    // Analyze conversation context
    const lastMessage = messages[messages.length - 1];

    // Generate suggestions
    const suggestions = await generateSuggestions(lastMessage);

    yield suggestions.map((text) => ({
      id: crypto.randomUUID(),
      text,
    }));
  },
};

const runtime = useLocalRuntime(MyModelAdapter, {
  adapters: { suggestion: suggestionAdapter },
});
```

## Advanced Features

### Resuming a Run

<Callout type="warning">
  The `unstable_resumeRun` method is experimental and may change in future
  releases.
</Callout>

Resume a conversation with a custom stream:

```tsx
import { useThreadRuntime, type ChatModelRunResult } from "@assistant-ui/react";

// Get the thread runtime
const thread = useThreadRuntime();

// Create a custom stream
async function* createCustomStream(): AsyncGenerator<ChatModelRunResult> {
  let text = "Initial response";
  yield {
    content: [{ type: "text", text }],
  };

  // Simulate delay
  await new Promise((resolve) => setTimeout(resolve, 500));

  text = "Initial response. And here's more content...";
  yield {
    content: [{ type: "text", text }],
  };
}

// Resume a run with the custom stream
thread.unstable_resumeRun({
  parentId: "message-id", // ID of the message to respond to
  stream: createCustomStream(), // The stream to use for resuming
});
```

### Custom Thread Management

Access thread runtime for advanced control with `useThreadRuntime`:

```tsx
import { useThreadRuntime } from "@assistant-ui/react";

function MyComponent() {
  const thread = useThreadRuntime();

  // Cancel current generation
  const handleCancel = () => {
    thread.cancelRun();
  };

  // Switch to a different branch
  const handleSwitchBranch = (messageId: string, branchIndex: number) => {
    thread.switchToBranch(messageId, branchIndex);
  };

  // Reload a message
  const handleReload = (messageId: string) => {
    thread.reload(messageId);
  };

  return (
    // Your UI
  );
}
```

### Custom Runtime Implementation

`useLocalThreadRuntime` provides the core single-thread runtime for building custom implementations:

```tsx
import {
  useLocalThreadRuntime,
  unstable_useRemoteThreadListRuntime as useRemoteThreadListRuntime,
  AssistantRuntimeProvider,
} from "@assistant-ui/react";

// Build your own multi-thread runtime
function MyCustomRuntimeProvider({ children }) {
  const runtime = useRemoteThreadListRuntime({
    runtimeHook: () => useLocalThreadRuntime(MyModelAdapter, options),
    adapter: myCustomThreadListAdapter,
  });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
}
```

<Callout type="info">
  `useLocalRuntime` internally uses `useLocalThreadRuntime` +
  `useRemoteThreadListRuntime` for multi-thread support.
</Callout>

<Callout type="warning">
  **`useThreadRuntime` vs `useLocalThreadRuntime`:**

  * `useThreadRuntime` - Access the current thread's runtime from within components
  * `useLocalThreadRuntime` - Create a new single-thread runtime instance
</Callout>

## Integration Examples

### OpenAI Integration

```tsx
import { OpenAI } from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  dangerouslyAllowBrowser: true, // Use server-side in production
});

const OpenAIAdapter: ChatModelAdapter = {
  async *run({ messages, abortSignal, context }) {
    const stream = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: messages.map((m) => ({
        role: m.role,
        content: m.content
          .filter((c) => c.type === "text")
          .map((c) => c.text)
          .join("\n"),
      })),
      stream: true,
      signal: abortSignal,
    });

    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content;
      if (content) {
        yield {
          content: [{ type: "text", text: content }],
        };
      }
    }
  },
};
```

### Custom REST API Integration

```tsx
const CustomAPIAdapter: ChatModelAdapter = {
  async run({ messages, abortSignal }) {
    const response = await fetch("/api/chat", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        messages: messages.map((m) => ({
          role: m.role,
          content: m.content,
        })),
      }),
      signal: abortSignal,
    });

    if (!response.ok) {
      throw new Error(`API error: ${response.statusText}`);
    }

    const data = await response.json();
    return {
      content: [{ type: "text", text: data.message }],
    };
  },
};
```

## Best Practices

1. **Error Handling** - Always handle API errors gracefully:

   ```tsx
   async *run({ messages, abortSignal }) {
     try {
       const response = await fetchAPI(messages, abortSignal);
       yield response;
     } catch (error) {
       if (error.name === 'AbortError') {
         // User cancelled - this is normal
         return;
       }
       // Re-throw other errors to display in UI
       throw error;
     }
   }
   ```

2. **Abort Signal** - Always pass the abort signal to fetch requests:

   ```tsx
   fetch(url, { signal: abortSignal });
   ```

3. **Memory Management** - For long conversations, consider implementing message limits:

   ```tsx
   const recentMessages = messages.slice(-20); // Keep last 20 messages
   ```

4. **Type Safety** - Use TypeScript for better development experience:
   ```tsx
   import type { ChatModelAdapter, ThreadMessage } from "@assistant-ui/react";
   ```

## Comparison with `ExternalStoreRuntime`

| Feature               | `LocalRuntime`                               | `ExternalStoreRuntime`                           |
| --------------------- | -------------------------------------------- | ------------------------------------------------ |
| State Management      | Built-in                                     | You manage                                       |
| Setup Complexity      | Simple                                       | More complex                                     |
| Flexibility           | Extensible via adapters                      | Full control                                     |
| Message Editing       | Automatic                                    | Requires `onEdit` handler                        |
| Branch Switching      | Automatic                                    | Requires `setMessages` handler                   |
| Multi-Thread Support  | Yes (with Assistant Cloud or custom adapter) | Yes (with thread list adapter)                   |
| Custom Thread Storage | Yes (with useRemoteThreadListRuntime)        | Yes                                              |
| Persistence           | Via history adapter or Assistant Cloud       | Your implementation                              |
| Best For              | Quick prototypes, standard apps, cloud-based | Complex state requirements, custom storage needs |

## Troubleshooting

### Common Issues

<Callout type="error">
  **Messages not appearing**: Ensure your adapter returns the correct format:

  ```tsx
  return {
    content: [{ type: "text", text: "response" }]
  };
  ```
</Callout>

<Callout type="warning">
  **Streaming not working**: Make sure to use `async *run` (note the asterisk):

  ```tsx
  async *run({ messages }) { //  Correct
  async run({ messages }) {  //  Wrong for streaming
  ```
</Callout>

### Debug Tips

1. **Log adapter calls** to trace execution:

   ```tsx
   async *run(options) {
     console.log("Adapter called with:", options);
     // ... rest of implementation
   }
   ```

2. **Check network requests** in browser DevTools

3. **Verify message format** matches ThreadMessage structure

## API Reference

### `ChatModelAdapter`

The main interface for connecting your API to `LocalRuntime`.

<ParametersTable
  type="ChatModelAdapter"
  parameters={[
  {
    name: "run",
    type: "ChatModelRunOptions => ChatModelRunResult | AsyncGenerator<ChatModelRunResult>",
    description:
      "Function that sends messages to your API and returns the response",
    required: true,
  },
]}
/>

### `ChatModelRunOptions`

Parameters passed to the `run` function.

<ParametersTable
  type="ChatModelRunOptions"
  parameters={[
  {
    name: "messages",
    type: "readonly ThreadMessage[]",
    description: "The conversation history to send to your API",
    required: true,
  },
  {
    name: "abortSignal",
    type: "AbortSignal",
    description: "Signal to cancel the request if user interrupts",
    required: true,
  },
  {
    name: "context",
    type: "ModelContext",
    description: "Additional context including configuration and tools",
    required: true,
  },
]}
/>

### `LocalRuntimeOptions`

Configuration options for the `LocalRuntime`.

<ParametersTable
  type="LocalRuntimeOptions"
  parameters={[
  {
    name: "initialMessages",
    type: "readonly ThreadMessage[]",
    description: "Pre-populate the thread with messages",
  },
  {
    name: "maxSteps",
    type: "number",
    description:
      "Maximum number of sequential tool calls before requiring user input",
    default: "5",
  },
  {
    name: "cloud",
    type: "AssistantCloud",
    description:
      "Enable Assistant Cloud integration for multi-thread support and persistence",
  },
  {
    name: "adapters",
    type: "LocalRuntimeAdapters",
    description:
      "Additional capabilities through adapters. Features are automatically enabled based on provided adapters",
    children: [
      {
        type: "adapters",
        parameters: [
          {
            name: "attachments",
            type: "AttachmentAdapter",
            description: "Enable file/image attachments",
          },
          {
            name: "speech",
            type: "SpeechSynthesisAdapter",
            description: "Enable text-to-speech for messages",
          },
          {
            name: "feedback",
            type: "FeedbackAdapter",
            description: "Enable message feedback (thumbs up/down)",
          },
          {
            name: "history",
            type: "ThreadHistoryAdapter",
            description: "Enable thread persistence and resumption",
          },
          {
            name: "suggestions",
            type: "SuggestionAdapter",
            description: "Enable follow-up suggestions",
          },
        ],
      },
    ],
  },
  {
    name: "unstable_humanToolNames",
    type: "string[]",
    description:
      "Tool names that require human approval before execution (experimental API)",
  },
]}
/>

### `RemoteThreadListAdapter`

Interface for implementing custom thread list storage.

<ParametersTable
  type="RemoteThreadListAdapter"
  parameters={[
  {
    name: "list",
    type: "() => Promise<RemoteThreadListResponse>",
    description: "Returns list of all threads (regular and archived)",
    required: true,
  },
  {
    name: "initialize",
    type: "(threadId: string) => Promise<RemoteThreadInitializeResponse>",
    description: "Creates a new thread with the given ID",
    required: true,
  },
  {
    name: "rename",
    type: "(remoteId: string, newTitle: string) => Promise<void>",
    description: "Updates the title of a thread",
    required: true,
  },
  {
    name: "archive",
    type: "(remoteId: string) => Promise<void>",
    description: "Archives a thread",
    required: true,
  },
  {
    name: "unarchive",
    type: "(remoteId: string) => Promise<void>",
    description: "Unarchives a thread",
    required: true,
  },
  {
    name: "delete",
    type: "(remoteId: string) => Promise<void>",
    description: "Deletes a thread permanently",
    required: true,
  },
  {
    name: "generateTitle",
    type: "(remoteId: string, messages: readonly ThreadMessage[]) => Promise<AssistantStream>",
    description: "Generates a title for the thread based on the conversation",
    required: true,
  },
]}
/>

### Related Runtime APIs

* [AssistantRuntime API](/docs/api-reference/runtimes/AssistantRuntime) - Core runtime interface and methods
* [ThreadRuntime API](/docs/api-reference/runtimes/ThreadRuntime) - Thread-specific operations and state management

## Related Resources

* [Runtime Layer Concepts](/docs/concepts/runtime-layer)
* [Pick a Runtime Guide](/docs/runtimes/pick-a-runtime)
* [`ExternalStoreRuntime`](/docs/runtimes/custom/external-store)
* [Examples Repository](https://github.com/assistant-ui/assistant-ui/tree/main/examples)


file: ./content/docs/runtimes/langgraph/index.mdx
# Getting Started


        
## Requirements

You need a LangGraph Cloud API server. You can start a server locally via [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio) or use [LangSmith](https://www.langchain.com/langsmith) for a hosted version.

The state of the graph you are using must have a `messages` key with a list of LangChain-alike messages.

## New project from template

import { Steps, Step } from "fumadocs-ui/components/steps";

<Steps>
  <Step>
    ### Create a new project based on the LangGraph assistant-ui template

    ```sh
    npx create-assistant-ui@latest -t langgraph my-app
    ```
  </Step>

  <Step>
    ### Set environment variables

    Create a `.env.local` file in your project with the following variables:

    ```sh
    # LANGCHAIN_API_KEY=your_api_key # for production
    # LANGGRAPH_API_URL=your_api_url # for production
    NEXT_PUBLIC_LANGGRAPH_API_URL=your_api_url # for development (no api key required)
    NEXT_PUBLIC_LANGGRAPH_ASSISTANT_ID=your_graph_id
    ```
  </Step>
</Steps>

## Installation in existing React project

<Steps>
  <Step>
    ### Install dependencies

    ```sh npm2yarn
    npm install @assistant-ui/react @assistant-ui/react-ui @assistant-ui/react-langgraph @langchain/langgraph-sdk
    ```
  </Step>

  <Step>
    ### Setup a proxy backend endpoint (optional, for production)

    <Callout type="warn">
      This example forwards every request to the LangGraph server directly from the
      browser. For production use-cases, you should limit the API calls to the
      subset of endpoints that you need and perform authorization checks.
    </Callout>

    ```tsx twoslash title="@/api/api/[...path]/route.ts"
    import { NextRequest, NextResponse } from "next/server";

    export const runtime = "edge";

    function getCorsHeaders() {
      return {
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET, POST, PUT, PATCH, DELETE, OPTIONS",
        "Access-Control-Allow-Headers": "*",
      };
    }

    async function handleRequest(req: NextRequest, method: string) {
      try {
        const path = req.nextUrl.pathname.replace(/^\/?api\//, "");
        const url = new URL(req.url);
        const searchParams = new URLSearchParams(url.search);
        searchParams.delete("_path");
        searchParams.delete("nxtP_path");
        const queryString = searchParams.toString()
          ? `?${searchParams.toString()}`
          : "";

        const options: RequestInit = {
          method,
          headers: {
            "x-api-key": process.env["LANGCHAIN_API_KEY"] || "",
          },
        };

        if (["POST", "PUT", "PATCH"].includes(method)) {
          options.body = await req.text();
        }

        const res = await fetch(
          `${process.env["LANGGRAPH_API_URL"]}/${path}${queryString}`,
          options,
        );

        return new NextResponse(res.body, {
          status: res.status,
          statusText: res.statusText,
          headers: {
            ...res.headers,
            ...getCorsHeaders(),
          },
        });
      } catch (e: any) {
        return NextResponse.json({ error: e.message }, { status: e.status ?? 500 });
      }
    }

    export const GET = (req: NextRequest) => handleRequest(req, "GET");
    export const POST = (req: NextRequest) => handleRequest(req, "POST");
    export const PUT = (req: NextRequest) => handleRequest(req, "PUT");
    export const PATCH = (req: NextRequest) => handleRequest(req, "PATCH");
    export const DELETE = (req: NextRequest) => handleRequest(req, "DELETE");

    // Add a new OPTIONS handler
    export const OPTIONS = () => {
      return new NextResponse(null, {
        status: 204,
        headers: {
          ...getCorsHeaders(),
        },
      });
    };
    ```
  </Step>

  <Step>
    ### Setup helper functions

    ```tsx twoslash include chatApi title="@/lib/chatApi.ts"
    // @filename: /lib/chatApi.ts

    // ---cut---
    import { Client } from "@langchain/langgraph-sdk";
    import { LangChainMessage } from "@assistant-ui/react-langgraph";

    const createClient = () => {
      const apiUrl = process.env["NEXT_PUBLIC_LANGGRAPH_API_URL"] || "/api";
      return new Client({
        apiUrl,
      });
    };

    export const createThread = async () => {
      const client = createClient();
      return client.threads.create();
    };

    export const getThreadState = async (
      threadId: string,
    ): Promise<ThreadState<{ messages: LangChainMessage[] }>> => {
      const client = createClient();
      return client.threads.getState(threadId);
    };

    export const sendMessage = async (params: {
      threadId: string;
      messages: LangChainMessage;
    }) => {
      const client = createClient();
      return client.runs.stream(
        params.threadId,
        process.env["NEXT_PUBLIC_LANGGRAPH_ASSISTANT_ID"]!,
        {
          input: {
            messages: params.messages,
          },
          streamMode: "messages",
        },
      );
    };
    ```
  </Step>

  <Step>
    ### Define a `MyAssistant` component

    ```tsx twoslash include MyAssistant title="@/components/MyAssistant.tsx"
    // @filename: /components/MyAssistant.tsx
    // @include: chatApi

    // ---cut---
    "use client";

    import { useRef } from "react";
    import { Thread } from "@/components/assistant-ui";
    import { AssistantRuntimeProvider } from "@assistant-ui/react";
    import { useLangGraphRuntime } from "@assistant-ui/react-langgraph";

    import { createThread, getThreadState, sendMessage } from "@/lib/chatApi";

    export function MyAssistant() {
      const threadIdRef = useRef<string | undefined>();
      const runtime = useLangGraphRuntime({
        threadId: threadIdRef.current,
        stream: async (messages) => {
          if (!threadIdRef.current) {
            const { thread_id } = await createThread();
            threadIdRef.current = thread_id;
          }
          const threadId = threadIdRef.current;
          return sendMessage({
            threadId,
            messages,
          });
        },
        onSwitchToNewThread: async () => {
          const { thread_id } = await createThread();
          threadIdRef.current = thread_id;
        },
        onSwitchToThread: async (threadId) => {
          const state = await getThreadState(threadId);
          threadIdRef.current = threadId;
          return {
            messages: state.values.messages,
            interrupts: state.tasks[0]?.interrupts,
          };
        },
      });

      return (
        <AssistantRuntimeProvider runtime={runtime}>
          <Thread />
        </AssistantRuntimeProvider>
      );
    }
    ```
  </Step>

  <Step>
    ### Use the `MyAssistant` component

    ```tsx twoslash title="@/app/page.tsx" {2,8}
    // @include: MyAssistant
    // @filename: /app/page.tsx
    // ---cut---
    import { MyAssistant } from "@/components/MyAssistant";

    export default function Home() {
      return (
        <main className="h-dvh">
          <MyAssistant />
        </main>
      );
    }
    ```
  </Step>

  <Step>
    ### Setup environment variables

    Create a `.env.local` file in your project with the following variables:

    ```sh
    # LANGCHAIN_API_KEY=your_api_key # for production
    # LANGGRAPH_API_URL=your_api_url # for production
    NEXT_PUBLIC_LANGGRAPH_API_URL=your_api_url # for development (no api key required)
    NEXT_PUBLIC_LANGGRAPH_ASSISTANT_ID=your_graph_id
    ```
  </Step>

  <Step>
    ### Setup UI components

    Follow the [UI Components](/docs/ui/shadcn-ui/Thread) guide to setup the UI components.
  </Step>
</Steps>

## Advanced APIs

### Message Accumulator

The `LangGraphMessageAccumulator` lets you append messages incoming from the server to replicate the messages state client side.

```typescript
import {
  LangGraphMessageAccumulator,
  appendLangChainChunk,
} from "@assistant-ui/react-langgraph";

const accumulator = new LangGraphMessageAccumulator({
  appendMessage: appendLangChainChunk,
});

// Add new chunks from the server
if (event.event === "messages/partial") accumulator.addMessages(event.data);
```

### Message Conversion

Use `convertLangChainMessages` to transform LangChain messages to assistant-ui format:

```typescript
import { convertLangChainMessages } from "@assistant-ui/react-langgraph";

const threadMessage = convertLangChainMessages(langChainMessage);
```

## Interrupt Persistence

LangGraph supports interrupting the execution flow to request user input or handle specific interactions. These interrupts can be persisted and restored when switching between threads. This means that if a user switches away from a thread during an interaction (like waiting for user approval), the interaction state will be preserved when they return to that thread.

To handle interrupts in your application:

1. Make sure your thread state type includes the `interrupts` field
2. Return the interrupts from `onSwitchToThread` along with the messages
3. The runtime will automatically restore the interrupt state when switching threads

This feature is particularly useful for applications that require user approval flows, multi-step forms, or any other interactive elements that might span multiple thread switches.


file: ./content/docs/runtimes/mastra/full-stack-integration.mdx
# Full-Stack Integration


        
import { Step, Steps } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";

Integrate Mastra directly into your Next.js application's API routes. This approach keeps your backend and frontend code within the same project.

<Steps>
  <Step>
    ### Initialize Assistant UI

    Start by setting up Assistant UI in your project. Run one of the following commands:

    ```sh title="New Project"
    npx assistant-ui@latest create
    ```

    ```sh title="Existing Project"
    npx assistant-ui@latest init
    ```

    This command installs necessary dependencies and creates basic configuration files, including a default chat API route.

    <Callout title="Need Help?">
      For detailed setup instructions, including adding API keys, basic
      configuration, and manual setup steps, please refer to the main [Getting
      Started guide](/docs/getting-started).
    </Callout>
  </Step>

  <Step>
    ### Review Initial API Route

    The initialization command creates a basic API route at `app/api/chat/route.ts` (or `src/app/api/chat/route.ts`). It typically looks like this:

    ```typescript title="app/api/chat/route.ts"
    import { openai } from "@ai-sdk/openai";
    import { streamText } from "ai";

    // Allow streaming responses up to 30 seconds
    export const maxDuration = 30;

    export async function POST(req: Request) {
      const { messages } = await req.json();

      const result = streamText({
        model: openai("gpt-4o-mini"),
        messages,
      });

      return result.toDataStreamResponse();
    }
    ```

    This default route uses the Vercel AI SDK directly with OpenAI. In the following steps, we will modify this route to integrate Mastra.
  </Step>

  <Step>
    ### Install Mastra Packages

    Add the Mastra core, memory, the AI SDK OpenAI provider packages to your project:

    ```bash npm2yarn
    npm install @mastra/core@latest @mastra/memory@latest @ai-sdk/openai
    ```
  </Step>

  <Step>
    ### Configure Next.js

    To ensure Next.js correctly bundles your application when using Mastra directly in API routes, you need to configure `serverExternalPackages`.

    Update your `next.config.mjs` (or `next.config.js`) file to include `@mastra/*`:

    ```js title="next.config.mjs"
    /** @type {import('next').NextConfig} */
    const nextConfig = {
      serverExternalPackages: ["@mastra/*"],
      // ... other configurations
    };

    export default nextConfig;
    ```

    This tells Next.js to treat Mastra packages as external dependencies on the server-side.
  </Step>

  <Step>
    ### Create Mastra Files

    Set up the basic folder structure for your Mastra configuration. Create a `mastra` folder (e.g., in your `src` or root directory) with the following structure:

    ```txt title="Project Structure"
    /
     mastra/
        agents/
           chefAgent.ts
        index.ts
     ... (rest of your project)
    ```

    You can create these files and folders manually or use the following commands in your terminal:

    ```bash
    mkdir -p mastra/agents
    touch mastra/index.ts mastra/agents/chefAgent.ts
    ```

    These files will be used in the next steps to define your Mastra agent and configuration.
  </Step>

  <Step>
    ### Define the Agent

    Now, let's define the behavior of our AI agent. Open the `mastra/agents/chefAgent.ts` file and add the following code:

    ```typescript title="mastra/agents/chefAgent.ts"
    import { openai } from "@ai-sdk/openai";
    import { Agent } from "@mastra/core/agent";

    export const chefAgent = new Agent({
      name: "chef-agent",
      instructions:
        "You are Michel, a practical and experienced home chef. " +
        "You help people cook with whatever ingredients they have available.",
      model: openai("gpt-4o-mini"),
    });
    ```

    This code creates a new Mastra `Agent` named `chef-agent`.

    * `instructions`: Defines the agent's persona and primary goal.
    * `model`: Specifies the language model the agent will use (in this case, OpenAI's GPT-4o Mini via the AI SDK).

    Make sure you have set up your OpenAI API key as described in the [Getting Started guide](/docs/getting-started).
  </Step>

  <Step>
    ### Register the Agent

    Next, register the agent with your Mastra instance. Open the `mastra/index.ts` file and add the following code:

    ```typescript title="mastra/index.ts"
    import { Mastra } from "@mastra/core";

    import { chefAgent } from "./agents/chefAgent";

    export const mastra = new Mastra({
      agents: { chefAgent },
    });
    ```

    This code initializes Mastra and makes the `chefAgent` available for use in your application's API routes.
  </Step>

  <Step>
    ### Modify the API Route

    Now, update your API route (`app/api/chat/route.ts`) to use the Mastra agent you just configured. Replace the existing content with the following:

    ```typescript title="app/api/chat/route.ts"
    import { mastra } from "@/mastra"; // Adjust the import path if necessary

    // Allow streaming responses up to 30 seconds
    export const maxDuration = 30;

    export async function POST(req: Request) {
      // Extract the messages from the request body
      const { messages } = await req.json();

      // Get the chefAgent instance from Mastra
      const agent = mastra.getAgent("chefAgent");

      // Stream the response using the agent
      const result = await agent.stream(messages);

      // Return the result as a data stream response
      return result.toDataStreamResponse();
    }
    ```

    Key changes:

    * We import the `mastra` instance created in `mastra/index.ts`. Make sure the import path (`@/mastra`) is correct for your project setup (you might need `~/mastra`, `../../../mastra`, etc., depending on your path aliases and project structure).
    * We retrieve the `chefAgent` using `mastra.getAgent("chefAgent")`.
    * Instead of calling the AI SDK's `streamText` directly, we call `agent.stream(messages)` to process the chat messages using the agent's configuration and model.
    * The result is still returned in a format compatible with Assistant UI using `toDataStreamResponse()`.

    Your API route is now powered by Mastra!
  </Step>

  <Step>
    ### Run the Application

    You're all set! Start your Next.js development server:

    ```bash npm2yarn
    npm run dev
    ```

    Open your browser to `http://localhost:3000` (or the port specified in your terminal). You should now be able to interact with your `chefAgent` through the Assistant UI chat interface. Ask it for cooking advice based on ingredients you have!
  </Step>
</Steps>

Congratulations! You have successfully integrated Mastra into your Next.js application using the full-stack approach. Your Assistant UI frontend now communicates with a Mastra agent running in your Next.js backend API route.

To explore more advanced Mastra features like memory, tools, workflows, and more, please refer to the [official Mastra documentation](https://mastra.ai/docs).


file: ./content/docs/runtimes/mastra/overview.mdx
# Overview


        
Mastra is an open-source TypeScript agent framework designed to provide the essential primitives for building AI applications. It enables developers to create AI agents with memory and tool-calling capabilities, implement deterministic LLM workflows, and leverage RAG for knowledge integration. With features like model routing, workflow graphs, and automated evals, Mastra provides a complete toolkit for developing, testing, and deploying AI applications.

## Integrating with Next.js and Assistant UI

There are two primary ways to integrate Mastra into your Next.js project when using Assistant UI:

1. **Full-Stack Integration**: Integrate Mastra directly into your Next.js application's API routes. This approach keeps your backend and frontend code within the same project.
   [Learn how to set up Full-Stack Integration](./full-stack-integration)

2. **Separate Server Integration**: Run Mastra as a standalone server and connect your Next.js frontend to its API endpoints. This approach separates concerns and allows for independent scaling.
   [Learn how to set up Separate Server Integration](./separate-server-integration)

Choose the guide that best fits your project architecture. Both methods allow seamless integration with the Assistant UI components.


file: ./content/docs/runtimes/mastra/separate-server-integration.mdx
# Separate Server Integration


        
import { Step, Steps } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";

Run Mastra as a standalone server and connect your Next.js frontend (using Assistant UI) to its API endpoints. This approach separates your AI backend from your frontend application, allowing for independent development and scaling.

<Steps>
  <Step>
    ### Create Mastra Server Project

    First, create a dedicated project for your Mastra server. Choose a directory separate from your Next.js/Assistant UI frontend project.

    Navigate to your chosen parent directory in the terminal and run the Mastra create command:

    ```bash
    npx create-mastra@latest
    ```

    This command will launch an interactive wizard to help you scaffold a new Mastra project, including prompting you for a project name and setting up basic configurations. Follow the prompts to create your server project. For more detailed setup instructions, refer to the [official Mastra installation guide](https://mastra.ai/docs/getting-started/installation).

    Once the setup is complete, navigate into your new Mastra project directory (the name you provided during the setup):

    ```bash
    cd your-mastra-server-directory # Replace with the actual directory name
    ```

    You now have a basic Mastra server project ready.

    <Callout title="API Keys">
      Ensure you have configured your environment variables (e.g., `OPENAI_API_KEY`)
      within this Mastra server project, typically in a `.env.development` file, as
      required by the models you use. The `create-mastra` wizard might prompt you
      for some keys, but ensure all necessary keys for your chosen models are
      present.
    </Callout>
  </Step>

  <Step>
    ### Define the Agent

    Next, let's define an agent within your Mastra server project. We'll create a `chefAgent` similar to the one used in the full-stack guide.

    Open or create the agent file (e.g., `src/agents/chefAgent.ts` within your Mastra project) and add the following code:

    ```typescript title="src/agents/chefAgent.ts"
    import { openai } from "@ai-sdk/openai";
    import { Agent } from "@mastra/core/agent";

    export const chefAgent = new Agent({
      name: "chef-agent",
      instructions:
        "You are Michel, a practical and experienced home chef. " +
        "You help people cook with whatever ingredients they have available.",
      model: openai("gpt-4o-mini"),
    });
    ```

    This defines the agent's behavior, but it's not yet active in the Mastra server.
  </Step>

  <Step>
    ### Register the Agent

    Now, you need to register the `chefAgent` with your Mastra instance so the server knows about it. Open your main Mastra configuration file (this is often `src/index.ts` in projects created with `create-mastra`).

    Import the `chefAgent` and add it to the `agents` object when initializing Mastra:

    ```typescript title="src/index.ts"
    import { Mastra } from "@mastra/core";
    import { chefAgent } from "./agents/chefAgent"; // Adjust path if necessary

    export const mastra = new Mastra({
      agents: { chefAgent },
    });
    ```

    Make sure you adapt this code to fit the existing structure of your `src/index.ts` file generated by `create-mastra`. The key is to import your agent and include it in the `agents` configuration object.
  </Step>

  <Step>
    ### Run the Mastra Server

    With the agent defined and registered, start the Mastra development server:

    ```bash npm2yarn
    npm run dev
    ```

    By default, the Mastra server will run on `http://localhost:4111`. Your `chefAgent` should now be accessible via a POST request endpoint, typically `http://localhost:4111/api/agents/chefAgent/stream`. Keep this server running for the next steps where we'll set up the Assistant UI frontend to connect to it.
  </Step>

  <Step>
    ### Initialize Assistant UI Frontend

    Now, set up your frontend application using Assistant UI. Navigate to a **different directory** from your Mastra server project. You can either create a new Next.js project or use an existing one.

    Inside your frontend project directory, run one of the following commands:

    ```sh title="New Project"
    npx assistant-ui@latest create
    ```

    ```sh title="Existing Project"
    npx assistant-ui@latest init
    ```

    This command installs the necessary Assistant UI dependencies and sets up basic configuration files, including a default chat page and an API route (`app/api/chat/route.ts`).

    <Callout title="Need Help?">
      For detailed setup instructions for Assistant UI, including manual setup
      steps, please refer to the main [Getting Started
      guide](/docs/getting-started).
    </Callout>

    In the next step, we will configure this frontend to communicate with the separate Mastra server instead of using the default API route.
  </Step>

  <Step>
    ### Configure Frontend API Endpoint

    The default Assistant UI setup configures the chat runtime to use a local API route (`/api/chat`) within the Next.js project. Since our Mastra agent is running on a separate server, we need to update the frontend to point to that server's endpoint.

    Open the main page file in your Assistant UI frontend project (usually `app/page.tsx` or `src/app/page.tsx`). Find the `useChatRuntime` hook and change the `api` property to the full URL of your Mastra agent's stream endpoint:

    ```tsx {10} title="app/page.tsx"
    "use client";
    import { Thread } from "@/components/assistant-ui/thread";
    import { useChatRuntime } from "@assistant-ui/react-ai-sdk";
    import { AssistantRuntimeProvider } from "@assistant-ui/react";
    import { ThreadList } from "@/components/assistant-ui/thread-list";

    export default function Home() {
      // Point the runtime to the Mastra server endpoint
      const runtime = useChatRuntime({
        api: "http://localhost:4111/api/agents/chefAgent/stream",
      });

      return (
        <AssistantRuntimeProvider runtime={runtime}>
          <main className="grid h-dvh grid-cols-[200px_1fr] gap-x-2 px-4 py-4">
            <ThreadList />
            <Thread />
          </main>
        </AssistantRuntimeProvider>
      );
    }
    ```

    Replace `"http://localhost:4111/api/agents/chefAgent/stream"` with the actual URL if your Mastra server runs on a different port or host, or if your agent has a different name.

    Now, the Assistant UI frontend will send chat requests directly to your running Mastra server.

    <Callout title="Delete Default API Route">
      Since the frontend no longer uses the local `/api/chat` route created by the
      `init` command, you can safely delete the `app/api/chat/route.ts` (or
      `src/app/api/chat/route.ts`) file from your frontend project.
    </Callout>
  </Step>

  <Step>
    ### Run the Frontend Application

    You're ready to connect the pieces! Make sure your separate Mastra server is still running (from Step 4).

    In your Assistant UI frontend project directory, start the Next.js development server:

    ```bash npm2yarn
    npm run dev
    ```

    Open your browser to `http://localhost:3000` (or the port specified in your terminal for the frontend app). You should now be able to interact with your `chefAgent` through the Assistant UI chat interface. The frontend will make requests to your Mastra server running on `http://localhost:4111`.
  </Step>
</Steps>

Congratulations! You have successfully integrated Mastra with Assistant UI using a separate server approach. Your Assistant UI frontend now communicates with a standalone Mastra agent server.

This setup provides a clear separation between your frontend and AI backend. To explore more advanced Mastra features like memory, tools, workflows, and deployment options, please refer to the [official Mastra documentation](https://mastra.ai/docs).


file: ./content/docs/ui/primitives/Thread.mdx
# Thread


        
A conversation between a user and an assistant.

import { ParametersTable } from "@/components/docs";

## Anatomy

```tsx
import { ThreadPrimitive } from "@assistant-ui/react";

const Thread = () => (
  <ThreadPrimitive.Root>
    <ThreadPrimitive.Viewport>
      <ThreadPrimitive.Empty>...</ThreadPrimitive.Empty>
      <ThreadPrimitive.Messages components={...} />
    </ThreadPrimitive.Viewport>
    <Composer />
  </ThreadPrimitive.Root>
);
```

## API Reference

### Root

Contains all parts of the thread.

This primitive renders a `<div>` element unless `asChild` is set.

<ParametersTable
  type="ThreadPrimitiveRootProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### Viewport

The scrollable area containing all messages. Anchors scroll to the bottom as new messages are added.

This primitive renders a `<div>` element unless `asChild` is set.

<ParametersTable
  type="ThreadPrimitiveViewportProps"
  parameters={[
  {
    name: "asChild",
  },
  {
    name: "autoScroll",
    type: "boolean",
    default: "true",
    description:
      "Whether to automatically scroll to the bottom of the viewport when new messages are added while the viewport is was previously scrolled to the bottom.",
  },
]}
/>

### Messages

Renders all messages. This primitive renders a separate component for each message.

<ParametersTable
  type="ThreadPrimitiveMessagesProps"
  parameters={[
  {
    name: "components",
    type: "MessageComponents",
    description: "The component to render for each message.",
    children: [
      {
        type: "MessageComponents",
        parameters: [
          {
            name: "Message",
            type: "ComponentType",
            description: "The component to render for each message.",
          },
          {
            name: "UserMessage",
            type: "ComponentType",
            description: "The component to render for user messages.",
          },
          {
            name: "EditComposer",
            type: "ComponentType",
            description:
              "The component to render for user messages that are being edited.",
          },
          {
            name: "AssistantMessage",
            type: "ComponentType",
            description: "The component to render for assistant messages.",
          },
        ],
      },
    ],
  },
]}
/>

### Empty

Renders children only when there are no messages.

### ScrollToBottom

A button to scroll the viewport to the bottom. Disabled when the viewport is already at bottom.

This primitive renders a `<button>` element unless `asChild` is set.

<ParametersTable
  type="ThreadPrimitiveScrollToBottomProps"
  parameters={[
  {
    name: "asChild",
  },
]}
/>

### `ThreadPrimitive.Suggestion`

Shows a suggestion to the user. When the user clicks on the suggestion, the composer's value is set to the suggestion's prompt.

This primitive renders a `<button>` element unless `asChild` is set.

```tsx
import { ThreadPrimitive } from "@assistant-ui/react";

const Suggestion = () => {
  return (
    <ThreadPrimitive.Suggestion
      prompt="I need help with product search"
      method="replace"
      autoSend
    />
  );
};
```

<ParametersTable
  type="ThreadPrimitiveSuggestionProps"
  parameters={[
  {
    name: "prompt",
    type: "string",
    description: "The suggestion's prompt.",
  },
  {
    name: "method",
    type: "'replace'",
    description:
      "How does the suggestion interact with the composer's existing value.",
  },
  {
    name: "autoSend",
    type: "boolean",
    description:
      "Whether to automatically send the suggestion when the user clicks on it.",
    default: "false",
  },
]}
/>

### If

Renders children if a condition is met.

<ParametersTable
  type="ThreadPrimitiveIfProps"
  parameters={[
  {
    name: "empty",
    type: "boolean | undefined",
    description: "Render children if the thread is empty.",
  },
  {
    name: "running",
    type: "boolean | undefined",
    description: "Render children if the thread is running.",
  },
]}
/>

```tsx
<Thread.If empty>
  {/* equivalent to <Thread.Empty> */}
</Thread.If>
<Thread.If empty={false}>
  {/* rendered if thread is not empty */}
</Thread.If>
```


file: ./content/docs/runtimes/langgraph/tutorial/index.mdx
# Introduction


        
import { redirect } from "next/navigation";

<>
  {redirect(
      "/docs/runtimes/langgraph/tutorial/introduction",
    )}
</>


file: ./content/docs/runtimes/langgraph/tutorial/introduction.mdx
# Introduction


        
In this tutorial, we will build a stockbroker assistant using LangChain.js, LangGraph.js and assistant-ui.

We will go through the necessary steps to integrate assistant-ui with a LangGraph Cloud endpoint.
Code snippets focus on the setup of the frontend, but we will highlight relevant sections of the backend code as well.

This agent leverages the following features:

*  Streaming of messages from LangGraph state to assistant-ui
*  Rich text rendering using Markdown
*  Generative UI: Mapping tool calls to tool UIs
*  Approval UI: Confirming tool calls before execution (human-in-the-loop)

## Prerequisites

* Node.js 18.x or higher

## Final Result

* Demo: [https://assistant-ui-stockbroker.vercel.app/](https://assistant-ui-stockbroker.vercel.app/)
* Source Code: [https://github.com/assistant-ui/assistant-ui-stockbroker](https://github.com/assistant-ui/assistant-ui-stockbroker)

## Get Started

Begin Part 1 of the tutorial by [setting up the frontend](/docs/runtimes/langgraph/tutorial/part-1).


file: ./content/docs/runtimes/langgraph/tutorial/part-1.mdx
# Part 1: Setup frontend


        
## Create a new project

Run the following command to create a new Next.js project with the LangGraph assistant-ui template:

```sh
npx create-assistant-ui@latest -t langgraph my-app
cd my-app
```

You should see the following files in your project:

import { File, Folder, Files } from "fumadocs-ui/components/files";

<Files>
  <Folder name="my-app" defaultOpen>
    <Folder name="app" defaultOpen>
      <Folder name="api" defaultOpen>
        <Folder name="[...path]" defaultOpen>
          <File name="route.ts" />
        </Folder>
      </Folder>

      <File name="globals.css" />

      <File name="layout.tsx" />

      <File name="MyRuntimeProvider.tsx" />

      <File name="page.tsx" />
    </Folder>

    <Folder name="lib">
      <File name="chatApi.ts" />
    </Folder>

    <File name="next.config.ts" />

    <File name="package.json" />

    <File name="postcss.config.mjs" />

    <File name="tailwind.config.ts" />

    <File name="tsconfig.json" />
  </Folder>
</Files>

### Setup environment variables

Create a `.env.local` file in your project with the following variables:

```sh title="@/.env.local"
LANGGRAPH_API_URL=https://assistant-ui-stockbroker.vercel.app/api
NEXT_PUBLIC_LANGGRAPH_ASSISTANT_ID=stockbroker
```

This connects the frontend to a LangGraph Cloud endpoint running under\
`https://assistant-ui-stockbroker.vercel.app/api`.\
This endpoint is running the LangGraph agent defined [in this repository](https://github.com/assistant-ui/assistant-ui-stockbroker/blob/main/backend).

### Start the server

You can start the server by running the following command:

```sh
npm run dev
```

The server will start and you can view the frontend by opening a browser tab to [http://localhost:3000](http://localhost:3000).

You should be able to chat with the assistant and see LLM responses streaming in real-time.

## Explore features

### Streaming

Streaming message support is enabled by default. The LangGraph integration includes sophisticated message handling that efficiently manages streaming responses:

* Messages are accumulated and updated in real-time using `LangGraphMessageAccumulator`
* Partial message chunks are automatically merged using `appendLangChainChunk`
* The runtime handles all the complexity of managing streaming state

This means you'll see tokens appear smoothly as they're generated by the LLM, with proper handling of both text content and tool calls.

### Markdown support

Rich text rendering using Markdown is enabled by default.

## Add conversation starter messages

In order to help users understand what the assistant can do, we can add some conversation starter messages.

import Image from "next/image";
import starter from "./images/conversation-starters.png";

<Image src={starter} alt="Conversation starters" width={600} className="mx-auto rounded-lg border shadow" />

```tsx title="@/app/page.tsx" {5-17}
export default function Home() {
  return (
    <div className="flex h-full flex-col">
      <Thread
        welcome={{
          suggestions: [
            {
              prompt: "How much revenue did Apple make last year?",
            },
            {
              prompt: "Is McDonald's profitable?",
            },
            {
              prompt: "What's the current stock price of Tesla?",
            },
          ],
        }}
        assistantMessage={{ components: { Text: MarkdownText } }}
      />
    </div>
  );
}
```


file: ./content/docs/runtimes/langgraph/tutorial/part-2.mdx
# Part 2: Generative UI


        
In the previous step, we set up the frontend to connect to a LangGraph Cloud endpoint.

In this step, we will set up a component to display stock ticker information.

import Image from "next/image";
import price from "./images/acme-price.png";

<Image src={price} alt="Price snapshot" width={600} className="mx-auto rounded-lg border shadow" />

For reference, this the corresponding code in the backend:

[https://github.com/assistant-ui/assistant-ui-stockbroker/blob/main/backend/src/tools.ts#L193C1-L216C3](https://github.com/assistant-ui/assistant-ui-stockbroker/blob/main/backend/src/tools.ts#L193C1-L216C3)

```ts title="assistant-ui-stockbroker/backend/tools/PriceSnapshotTool.ts"
export const priceSnapshotTool = tool(
  async (input) => {
    const data = await callFinancialDatasetAPI<SnapshotResponse>({
      endpoint: "/prices/snapshot",
      params: {
        ticker: input.ticker,
      },
    });
    return JSON.stringify(data, null);
  },
  {
    name: "price_snapshot",
    description:
      "Retrieves the current stock price and related market data for a given company.",
    schema: z.object({
      ticker: z.string().describe("The ticker of the company. Example: 'AAPL'"),
    }),
  },
);
```

## PriceSnapshotTool

We create a new file under `/components/tools/price-snapshot/PriceSnapshotTool.tsx` to define the tool.

First, we define the tool arguments and result types:

```ts title="@/components/tools/price-snapshot/PriceSnapshotTool.tsx"
type PriceSnapshotToolArgs = {
  ticker: string;
};

type PriceSnapshotToolResult = {
  snapshot: {
    price: number;
    day_change: number;
    day_change_percent: number;
    time: string;
  };
};
```

Then, we use `makeAssistantToolUI` to define the tool UI:

```tsx title="@/components/tools/price-snapshot/PriceSnapshotTool.tsx"
"use client";

import { makeAssistantToolUI } from "@assistant-ui/react";

export const PriceSnapshotTool = makeAssistantToolUI<
  PriceSnapshotToolArgs,
  string
>({
  toolName: "price_snapshot",
  render: function PriceSnapshotUI({ args, result }) {
    return (
      <div className="mb-4 flex flex-col items-center">
        <pre className="whitespace-pre-wrap break-all text-center">
          price_snapshot({JSON.stringify(args)})
        </pre>
      </div>
    );
  },
});
```

This simply displays the tool name and arguments passed to it, but not the result.

### Bind tool UI

```tsx title="@/app/page.tsx" {1,8}
import { PriceSnapshotTool } from "@/components/tools/price-snapshot/PriceSnapshotTool";

export default function Home() {
  return (
    <div className="flex h-full flex-col">
      <Thread
        ...
        tools={[PriceSnapshotTool]}
      />
    </div>
  );
}
```

### Try it out!

Ask the assistant for the current stock price of Tesla. You should see the following text appear:

```
price_snapshot({ticker: "TSLA"})
```

Next, we will visualize the function's result.

## Visualizing tool results

### Install dependencies

The tool result component relies on shadcn/ui's `Card` component. We will install it as a dependency.

```sh
npx shadcn@latest add card
```

You will be prompted to setup a `components.json` file, after this step, a `card` UI component will be installed in your project.

### Add `PriceSnapshot`

We create a new file under `/components/tools/price-snapshot/price-snapshot.tsx` to define the new tool result UI.

```tsx title="@/components/tools/price-snapshot/price-snapshot.tsx"
"use client";

import { ArrowDownIcon, ArrowUpIcon } from "lucide-react";

import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card";

type PriceSnapshotToolArgs = {
  ticker: string;
};

type PriceSnapshotToolResult = {
  price: number;
  day_change: number;
  day_change_percent: number;
  time: string;
};

export function PriceSnapshot({
  ticker,
  price,
  day_change,
  day_change_percent,
  time,
}: PriceSnapshotToolArgs & PriceSnapshotToolResult) {
  const isPositiveChange = day_change >= 0;
  const changeColor = isPositiveChange ? "text-green-600" : "text-red-600";
  const ArrowIcon = isPositiveChange ? ArrowUpIcon : ArrowDownIcon;

  return (
    <Card className="mx-auto w-full max-w-md">
      <CardHeader>
        <CardTitle className="text-2xl font-bold">{ticker}</CardTitle>
      </CardHeader>
      <CardContent>
        <div className="grid grid-cols-2 gap-4">
          <div className="col-span-2">
            <p className="text-3xl font-semibold">${price?.toFixed(2)}</p>
          </div>
          <div>
            <p className="text-muted-foreground text-sm">Day Change</p>
            <p
              className={`flex items-center text-lg font-medium ${changeColor}`}
            >
              <ArrowIcon className="mr-1 h-4 w-4" />$
              {Math.abs(day_change)?.toFixed(2)} (
              {Math.abs(day_change_percent)?.toFixed(2)}%)
            </p>
          </div>
          <div>
            <p className="text-muted-foreground text-sm">Last Updated</p>
            <p className="text-lg font-medium">
              {new Date(time).toLocaleTimeString()}
            </p>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}
```

### Update `PriceSnapshotTool`

We will import the new `<PriceSnapshot />` component and use it in the `render` function whenever a tool result is available.

```tsx title="@/components/tools/price-snapshot/PriceSnapshotTool.tsx" {3,25-30,37-42}
"use client";

import { PriceSnapshot } from "./price-snapshot";
import { makeAssistantToolUI } from "@assistant-ui/react";

type PriceSnapshotToolArgs = {
  ticker: string;
};

type PriceSnapshotToolResult = {
  snapshot: {
    price: number;
    day_change: number;
    day_change_percent: number;
    time: string;
  };
};

export const PriceSnapshotTool = makeAssistantToolUI<
  PriceSnapshotToolArgs,
  string
>({
  toolName: "price_snapshot",
  render: function PriceSnapshotUI({ args, result }) {
    let resultObj: PriceSnapshotToolResult | { error: string };
    try {
      resultObj = result ? JSON.parse(result) : {};
    } catch (e) {
      resultObj = { error: result! };
    }

    return (
      <div className="mb-4 flex flex-col items-center gap-2">
        <pre className="whitespace-pre-wrap break-all text-center">
          price_snapshot({JSON.stringify(args)})
        </pre>
        {"snapshot" in resultObj && (
          <PriceSnapshot ticker={args.ticker} {...resultObj.snapshot} />
        )}
        {"error" in resultObj && (
          <p className="text-red-500">{resultObj.error}</p>
        )}
      </div>
    );
  },
});
```

### Try it out!

Ask the assistant for the current stock price of Tesla. You should see the tool result appear:

import price2 from "./images/tsla-price.png";

<Image src={price2} alt="Price snapshot result" width={600} className="mx-auto rounded-lg border shadow" />

## Fallback tool UI

Instead of defining a custom tool UI for every tool, we can also define a fallback UI for all tools that are not explicitly defined.

This requires shadcn/ui's `Button` component. We will install it as a dependency.

```sh
npx shadcn@latest add button
```

Then create a new file under `/components/tools/ToolFallback.tsx` to define the fallback UI.

```tsx title="@/components/tools/ToolFallback.tsx"
import { ToolCallContentPartComponent } from "@assistant-ui/react";
import { CheckIcon, ChevronDownIcon, ChevronUpIcon } from "lucide-react";
import { useState } from "react";
import { Button } from "../ui/button";

export const ToolFallback: ToolCallContentPartComponent = ({
  toolName,
  argsText,
  result,
}) => {
  const [isCollapsed, setIsCollapsed] = useState(true);
  return (
    <div className="mb-4 flex w-full flex-col gap-3 rounded-lg border py-3">
      <div className="flex items-center gap-2 px-4">
        <CheckIcon className="size-4" />
        <p className="">
          Used tool: <b>{toolName}</b>
        </p>
        <div className="flex-grow" />
        <Button onClick={() => setIsCollapsed(!isCollapsed)}>
          {isCollapsed ? <ChevronUpIcon /> : <ChevronDownIcon />}
        </Button>
      </div>
      {!isCollapsed && (
        <div className="flex flex-col gap-2 border-t pt-2">
          <div className="px-4">
            <pre className="whitespace-pre-wrap">{argsText}</pre>
          </div>
          {result !== undefined && (
            <div className="border-t border-dashed px-4 pt-2">
              <p className="font-semibold">Result:</p>
              <pre className="whitespace-pre-wrap">
                {typeof result === "string"
                  ? result
                  : JSON.stringify(result, null, 2)}
              </pre>
            </div>
          )}
        </div>
      )}
    </div>
  );
};
```

### Bind fallback UI

```tsx title="@/app/page.tsx" {1,8}
import { ToolFallback } from "@/components/tools/ToolFallback";

export default function Home() {
  return (
    <div className="flex h-full flex-col">
      <Thread
        ...
        assistantMessage={{ components: { Text: MarkdownText, ToolFallback } }}
      />
    </div>
  );
}
```


file: ./content/docs/runtimes/langgraph/tutorial/part-3.mdx
# Part 3: Approval UI


        
## Background: LangGraph implementation details

import Image from "next/image";
import approval from "./images/stockbroker-langgraph.png";

<Image src={approval} alt="LangChain LangGraph" width={600} className="mx-auto rounded-lg border shadow" />

Our LangGraph backend interrupts the `purchase_stock` tool execution in order to ensure the user confirms the purchase. The user confirms the purchase by submitting a tool message with the `approve` field set to `true`.

```ts title="assistant-ui-stockbroker/backend/src/index.ts" {6,18-19,32-35}
const purchaseApproval = async (state: typeof GraphAnnotation.State) => {
  const { messages } = state;
  const lastMessage = messages[messages.length - 1];
  if (!(lastMessage instanceof ToolMessage)) {
    // Interrupt the node to request permission to execute the purchase.
    throw new NodeInterrupt("Please confirm the purchase before executing.");
  }
};

const shouldExecutePurchase = (state: typeof GraphAnnotation.State) => {
  const { messages } = state;
  const lastMessage = messages[messages.length - 1];
  if (!(lastMessage instanceof ToolMessage)) {
    // Interrupt the node to request permission to execute the purchase.
    throw new NodeInterrupt("Please confirm the purchase before executing.");
  }

  const { approve } = JSON.parse(lastMessage.content as string);
  return approve ? "execute_purchase" : "agent";
};

const workflow = new StateGraph(GraphAnnotation)
  .addNode("agent", callModel)
  .addEdge(START, "agent")
  .addNode("tools", toolNode)
  .addNode("prepare_purchase_details", preparePurchaseDetails)
  .addNode("purchase_approval", purchaseApproval)
  .addNode("execute_purchase", executePurchase)
  .addEdge("prepare_purchase_details", "purchase_approval")
  .addEdge("execute_purchase", END)
  .addEdge("tools", "agent")
  .addConditionalEdges("purchase_approval", shouldExecutePurchase, [
    "agent",
    "execute_purchase",
  ])
  .addConditionalEdges("agent", shouldContinue, [
    "tools",
    END,
    "prepare_purchase_details",
  ]);
```

## Add approval UI

We create a new file under `/components/tools/purchase-stock/PurchaseStockTool.tsx` to define the tool.

First, we define the tool arguments and result types:

```ts title="@/components/tools/purchase-stock/PurchaseStockTool.tsx"
type PurchaseStockArgs = {
  ticker: string;
  companyName: string;
  quantity: number;
  maxPurchasePrice: number;
};

type PurchaseStockResult = {
  approve?: boolean;
  cancelled?: boolean;
  error?: string;
};
```

Then we use `makeAssistantToolUI` to define the tool UI:

```tsx title="@/components/tools/purchase-stock/PurchaseStockTool.tsx"
"use client";

import { TransactionConfirmationPending } from "./transaction-confirmation-pending";
import { TransactionConfirmationFinal } from "./transaction-confirmation-final";
import { makeAssistantToolUI } from "@assistant-ui/react";
import { updateState } from "@/lib/chatApi";

export const PurchaseStockTool = makeAssistantToolUI<PurchaseStockArgs, string>(
  {
    toolName: "purchase_stock",
    render: function PurchaseStockUI({ args, result, status, addResult }) {
      const handleReject = async () => {
        addResult({ approve: false });
      };

      const handleConfirm = async () => {
        addResult({ approve: true });
      };

      return (
        <div className="mb-4 flex flex-col items-center gap-2">
          <div>
            <pre className="whitespace-pre-wrap break-all text-center">
              purchase_stock({JSON.stringify(args)})
            </pre>
          </div>
          {!result && status.type !== "running" && (
            <TransactionConfirmationPending
              {...args}
              onConfirm={handleConfirm}
              onReject={handleReject}
            />
          )}
        </div>
      );
    },
  },
);
```

Finally, we add a `TransactionConfirmationPending` component to ask for approval.

This requires shadcn/ui's `Card` and `Button` components. We will install them as a dependency.

```sh
npx shadcn@latest add card button
```

Then create a new file under `/components/tools/purchase-stock/transaction-confirmation-pending.tsx` to define the approval UI.

```tsx title="@/components/tools/purchase-stock/transaction-confirmation-pending.tsx"
"use client";

import { CheckIcon, XIcon } from "lucide-react";

import { Button } from "@/components/ui/button";
import {
  Card,
  CardContent,
  CardFooter,
  CardHeader,
  CardTitle,
} from "@/components/ui/card";

type TransactionConfirmation = {
  ticker: string;
  companyName: string;
  quantity: number;
  maxPurchasePrice: number;
  onConfirm: () => void;
  onReject: () => void;
};

export function TransactionConfirmationPending(props: TransactionConfirmation) {
  const {
    ticker,
    companyName,
    quantity,
    maxPurchasePrice,
    onConfirm,
    onReject,
  } = props;

  return (
    <Card className="mx-auto w-full max-w-md">
      <CardHeader>
        <CardTitle className="text-2xl font-bold">
          Confirm Transaction
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-4">
        <div className="grid grid-cols-2 gap-2">
          <p className="text-muted-foreground text-sm font-medium">Ticker:</p>
          <p className="text-sm font-bold">{ticker}</p>
          <p className="text-muted-foreground text-sm font-medium">Company:</p>
          <p className="text-sm">{companyName}</p>
          <p className="text-muted-foreground text-sm font-medium">Quantity:</p>
          <p className="text-sm">{quantity} shares</p>
          <p className="text-muted-foreground text-sm font-medium">
            Max Purchase Price:
          </p>
          <p className="text-sm">${maxPurchasePrice?.toFixed(2)}</p>
        </div>
        <div className="bg-muted rounded-md p-3">
          <p className="text-sm font-medium">Total Maximum Cost:</p>
          <p className="text-lg font-bold">
            ${(quantity * maxPurchasePrice)?.toFixed(2)}
          </p>
        </div>
      </CardContent>
      <CardFooter className="flex justify-end">
        <Button variant="outline" onClick={onReject}>
          <XIcon className="mr-2 h-4 w-4" />
          Reject
        </Button>
        <Button onClick={onConfirm}>
          <CheckIcon className="mr-2 h-4 w-4" />
          Confirm
        </Button>
      </CardFooter>
    </Card>
  );
}
```

### Bind approval UI

```tsx title="@/app/page.tsx" {1,8}
import { PurchaseStockTool } from "@/components/tools/purchase-stock/PurchaseStockTool";

export default function Home() {
  return (
    <div className="flex h-full flex-col">
      <Thread
        ...
        tools={[PriceSnapshotTool, PurchaseStockTool]}
      />
    </div>
  );
}
```

### Try it out!

Ask the assistant to buy 5 shares of Tesla. You should see the following appear:

import purchase from "./images/acme-approve.png";

<Image src={purchase} alt="Approval UI" width={600} className="mx-auto rounded-lg border shadow" />

## Add `TransactionConfirmationFinal` to show approval result

We will add a component to display the approval result.

```ts title="@/components/tools/purchase-stock/transaction-confirmation-final.tsx"
"use client";

import { CheckCircle } from "lucide-react";

import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card";

type TransactionConfirmation = {
  ticker: string;
  companyName: string;
  quantity: number;
  maxPurchasePrice: number;
};

export function TransactionConfirmationFinal(props: TransactionConfirmation) {
  const { ticker, companyName, quantity, maxPurchasePrice } = props;

  return (
    <Card className="mx-auto w-full max-w-md">
      <CardHeader className="text-center">
        <CheckCircle className="mx-auto mb-4 h-16 w-16 text-green-500" />
        <CardTitle className="text-2xl font-bold text-green-700">
          Transaction Confirmed
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-4">
        <div className="rounded-md border border-green-200 bg-green-50 p-4">
          <h3 className="mb-2 text-lg font-semibold text-green-800">
            Purchase Summary
          </h3>
          <div className="grid grid-cols-2 gap-2 text-sm">
            <p className="font-medium text-green-700">Ticker:</p>
            <p className="font-bold text-green-900">{ticker}</p>
            <p className="font-medium text-green-700">Company:</p>
            <p className="text-green-900">{companyName}</p>
            <p className="font-medium text-green-700">Quantity:</p>
            <p className="text-green-900">{quantity} shares</p>
            <p className="font-medium text-green-700">Price per Share:</p>
            <p className="text-green-900">${maxPurchasePrice?.toFixed(2)}</p>
          </div>
        </div>
        <div className="rounded-md border border-green-300 bg-green-100 p-4">
          <p className="text-lg font-semibold text-green-800">Total Cost:</p>
          <p className="text-2xl font-bold text-green-900">
            ${(quantity * maxPurchasePrice)?.toFixed(2)}
          </p>
        </div>
        <p className="text-center text-sm text-green-600">
          Your purchase of {quantity} shares of {companyName} ({ticker}) has
          been successfully processed.
        </p>
      </CardContent>
    </Card>
  );
}
```

### Update `PurchaseStockTool`

We will import the new `<TransactionConfirmationFinal />` component and use it in the `render` function whenever an approval result is available.

```tsx title="@/components/tools/purchase-stock/PurchaseStockTool.tsx" {3,25-30,37-42}
"use client";

import { TransactionConfirmationPending } from "./transaction-confirmation-pending";
import { TransactionConfirmationFinal } from "./transaction-confirmation-final";
import { makeAssistantToolUI } from "@assistant-ui/react";
import { updateState } from "@/lib/chatApi";

type PurchaseStockArgs = {
  ticker: string;
  companyName: string;
  quantity: number;
  maxPurchasePrice: number;
};

type PurchaseStockResult = {
  approve?: boolean;
  cancelled?: boolean;
  error?: string;
};

export const PurchaseStockTool = makeAssistantToolUI<PurchaseStockArgs, string>(
  {
    toolName: "purchase_stock",
    render: function PurchaseStockUI({ args, result, status, addResult }) {
      let resultObj: PurchaseStockResult;
      try {
        resultObj = result ? JSON.parse(result) : {};
      } catch (e) {
        resultObj = { error: result! };
      }

      const handleReject = () => {
        addResult({ cancelled: true });
      };

      const handleConfirm = async () => {
        addResult({ approve: true });
      };

      return (
        <div className="mb-4 flex flex-col items-center gap-2">
          <div>
            <pre className="whitespace-pre-wrap break-all text-center">
              purchase_stock({JSON.stringify(args)})
            </pre>
          </div>
          {!result && status.type !== "running" && (
            <TransactionConfirmationPending
              {...args}
              onConfirm={handleConfirm}
              onReject={handleReject}
            />
          )}
          {resultObj.approve && <TransactionConfirmationFinal {...args} />}
          {resultObj.approve === false && (
            <pre className="font-bold text-red-600">User rejected purchase</pre>
          )}
          {resultObj.cancelled && (
            <pre className="font-bold text-red-600">Cancelled</pre>
          )}
        </div>
      );
    },
  },
);
```

### Try it out!

Confirm the purchase of shares. You should see the approval confimration UI appear.

import purchase2 from "./images/acme-confirmed.png";

<Image src={purchase2} alt="Approval result" width={600} className="mx-auto rounded-lg border shadow" />